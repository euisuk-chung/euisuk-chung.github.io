---
title: "[ê°•ì˜ë…¸íŠ¸] RAG From Scratch : Query Translation"
date: "2024-09-14"
tags:
  - "rag"
  - "ê°•ì˜ë…¸íŠ¸"
year: "2024"
---

# [ê°•ì˜ë…¸íŠ¸] RAG From Scratch : Query Translation

![](https://velog.velcdn.com/images/euisuk-chung/post/e2749238-5885-4d38-8441-d29c7180d541/image.png)

* í•´ë‹¹ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ëŠ” [RAG From Scratch : Coursework](https://velog.io/@euisuk-chung/LLM-RAG-From-Scratch) ê°•ì˜ íŒŒíŠ¸ 5 - 9 ë‚´ìš©ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.

| **ë¹„ë””ì˜¤** | **ìš”ì•½** | **ê°•ì˜ ë§í¬** | **ìŠ¬ë¼ì´ë“œ** |
| --- | --- | --- | --- |
| **Part 5 (ë‹¤ì¤‘ ì¿¼ë¦¬)** | ë‹¤ì–‘í•œ ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•´ ì¿¼ë¦¬ ì¬ì‘ì„± ê¸°ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. | ğŸ“Œ [ê°•ì˜](https://www.youtube.com/watch?v=JChPi0CRnDY&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=5&pp=iAQB) | ğŸ“– [ìŠ¬ë¼ì´ë“œ](https://docs.google.com/presentation/d/15pWydIszbQG3Ipur9COfTduutTZm6ULdkkyX-MNry8I/edit?usp=sharing) |
| **Part 6 (RAG Fusion)** | ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ í–¥ìƒëœ ë­í‚¹ì„ ì œê³µí•˜ëŠ” RAG Fusionì„ ì†Œê°œí•©ë‹ˆë‹¤. | ğŸ“Œ [ê°•ì˜](https://www.youtube.com/watch?v=JChPi0CRnDY&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=6&pp=iAQB) | ğŸ“– [ìŠ¬ë¼ì´ë“œ](https://docs.google.com/presentation/d/1EwykmdVSQqlh6XpGt8APOMYp4q1CZqqeclAx61pUcjI/edit?usp=sharing) |
| **Part 7 (ë¶„í•´)** | ë³µì¡í•œ ì§ˆë¬¸ì„ ì„¸ë¶„í™”ëœ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ë°©ë²•ì„ ë…¼ì˜í•©ë‹ˆë‹¤. | ğŸ“Œ [ê°•ì˜](https://www.youtube.com/watch?v=JChPi0CRnDY&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=7&pp=iAQB) | ğŸ“– [ìŠ¬ë¼ì´ë“œ](https://docs.google.com/presentation/d/1O97KYrsmYEmhpQ6nkvOVAqQYMJvIaZulGFGmz4cuuVE/edit?usp=sharing) |
| **Part 8 (ë‹¨ê³„ì  í›„í‡´)** | ê·¼ë³¸ì ì¸ ì´í•´ë¥¼ ì´ëŒì–´ë‚´ëŠ” ì¶”ìƒì  ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë‹¨ê³„ì  í›„í‡´ í”„ë¡¬í”„íŒ…ì„ íƒêµ¬í•©ë‹ˆë‹¤. | ğŸ“Œ [ê°•ì˜](https://www.youtube.com/watch?v=JChPi0CRnDY&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=8&pp=iAQB) | ğŸ“– [ìŠ¬ë¼ì´ë“œ](https://docs.google.com/presentation/d/1L0MRGVDxYA1eLOR0L_6Ze1l2YV8AhN1QKUtmNA-fJlU/edit?usp=sharing) |
| **Part 9 (HyDE)** | ì¸ë±ìŠ¤ ë¬¸ì„œì™€ ë” ì˜ ì¼ì¹˜í•˜ë„ë¡ ê°€ì„¤ì  ë¬¸ì„œë¥¼ ìƒì„±í•˜ëŠ” HyDE ê¸°ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. | ğŸ“Œ [ê°•ì˜](https://www.youtube.com/watch?v=JChPi0CRnDY&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=9&pp=iAQB) | ğŸ“– [ìŠ¬ë¼ì´ë“œ](https://docs.google.com/presentation/d/10MmB_QEiS4m00xdyu-92muY-8jC3CdaMpMXbXjzQXsM/edit?usp=sharing) |

---

### Part 5 (ë‹¤ì¤‘ ì¿¼ë¦¬)

* í•´ë‹¹ ê°•ì˜ëŠ” RAG(Retrieval-Augmented Generation) íŒŒì´í”„ë¼ì¸ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ì¸ "Query Translation(ì¿¼ë¦¬ ë³€í™˜)"ì— ëŒ€í•´ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/174b70ec-f1c6-4707-b23c-a8f419e1ff26/image.png)

* **Query Translation**: ì‚¬ìš©ìê°€ ì‘ì„±í•œ ì§ˆë¬¸ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ì œëŒ€ë¡œ êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ê²½ìš°, ë¬¸ì„œì—ì„œ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ê³¼ì •ì—ì„œ ì›í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **ì§ˆë¬¸ì„ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì¬ì‘ì„±**í•˜ì—¬ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë°©ë²•ì´ í•„ìš”í•©ë‹ˆë‹¤. ![](https://velog.velcdn.com/images/euisuk-chung/post/f29ce306-0905-4801-a5e1-bbe549047192/image.png)
  + ì•„ë˜ 3ê°€ì§€ ê¸°ë²•ì€ ëŒ€í‘œì ì¸ **Query Translation**ì˜ 3ê°€ì§€ ê¸°ë²•ìœ¼ë¡œ ì´ë“¤ì€ ê°ê° ë‹¤ë¥´ê²Œ ì§ˆë¬¸ì„ ë³€í˜•í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ë²•ìœ¼ë¡œ, ê¸°ë³¸ì ìœ¼ë¡œ ì›ë˜ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•˜ê±°ë‚˜ ë³€í˜•í•˜ëŠ” ë°©ì‹ì´ë¼ëŠ” ê³µí†µì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
    1. **Query Rewriting(ì¿¼ë¦¬ ì¬ì‘ì„±)**: ì§ˆë¬¸ì„ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ë‹¤ì‹œ ì‘ì„±í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ì¤‘ ì¿¼ë¦¬(multi-query) ê¸°ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸ì„ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‹¤ì–‘ì„±ê³¼ ì •í™•ì„±ì„ ë†’ì´ë ¤ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
    2. **Sub-questions(í•˜ìœ„ ì§ˆë¬¸ ìƒì„±)**: ë³µì¡í•˜ê±°ë‚˜ ì¶”ìƒì ì¸ ì§ˆë¬¸ì„ ë” ì‘ê³  êµ¬ì²´ì ì¸ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë” ì •í™•í•˜ê³  ì„¸ë¶€ì ì¸ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Googleì˜ "least-to-most" ê¸°ë²•ì€ ë³µì¡í•œ ì§ˆë¬¸ì„ ë” ì‘ì€ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ í•´ê²°í•˜ëŠ” ëŒ€í‘œì ì¸ ë°©ì‹ì…ë‹ˆë‹¤.
    3. **Abstract Query(ì¶”ìƒì ì¸ ì§ˆë¬¸ ìƒì„±)**: ì§ˆë¬¸ì„ ë” ë†’ì€ ìˆ˜ì¤€ìœ¼ë¡œ ì¶”ìƒí™”í•˜ì—¬, ì¼ë°˜ì ì´ê±°ë‚˜ ê´‘ë²”ìœ„í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. "Stepback prompting" ê¸°ë²•ì€ ì§ˆë¬¸ì„ í•œ ë‹¨ê³„ ë” ë†’ì€ ì¶”ìƒí™” ìˆ˜ì¤€ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë³´ë‹¤ ë„“ì€ ë²”ìœ„ì˜ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

* ë³¸ ê°•ì˜ëŠ” **â€œ1. Query Rewriting(ì¿¼ë¦¬ ì¬ì‘ì„±)â€** ê¸°ë²• ì¤‘ í•˜ë‚˜ì— ì†í•˜ëŠ” `Multi-query(ë‹¤ì¤‘ ì¿¼ë¦¬)`ì— ì¤‘ì ì„ ë‘ê³  ì„¤ëª…í•©ë‹ˆë‹¤.
  + ì—¬ê¸°ì„œ ë‹¤ë£¨ëŠ” í•µì‹¬ ê°œë…ì€ **ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ ì„±ëŠ¥ì„ ê°œì„ **í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/15507479-50cb-4ddc-b8e6-7ac397810dfa/image.png)

* **Multi-Query ì ‘ê·¼ ë°©ì‹**

![](https://velog.velcdn.com/images/euisuk-chung/post/8e24f2c9-8065-4312-be8a-4c018548f5aa/image.png)

* ë‹¤ì¤‘ ì¿¼ë¦¬ ë°©ì‹ì˜ ê¸°ë³¸ì ì¸ ì§ê´€ì€ **ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê°€ì§€ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
* ì´ëŠ” ë¬¸ì„œì™€ ì§ˆë¬¸ì´ ê³ ì°¨ì› ì„ë² ë”© ê³µê°„ì—ì„œ ì˜ ì •ë ¬ë˜ì§€ ì•Šì„ ê²½ìš°, ì§ˆë¬¸ì„ ì¬ì‘ì„±í•˜ì—¬ í•´ë‹¹ ë¬¸ì„œë¥¼ ë” ì˜ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.
* ì¦‰, ì§ˆë¬¸ì„ ì—¬ëŸ¬ ë°©ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•¨ìœ¼ë¡œì¨ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

**ì½”ë“œ ì‹œì—°**

* ì´ ë°©ì‹ì€ **ì—¬ëŸ¬ ì¬ì‘ì„±ëœ ì§ˆë¬¸ì„ ë…ë¦½ì ìœ¼ë¡œ ê²€ìƒ‰**í•œ í›„, ê° ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ë” ì‹ ë¢°ì„± ìˆëŠ” ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

1. **ë¸”ë¡œê·¸ ë¬¸ì„œ ë¡œë“œ ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±/ê²€ìƒ‰ ì¤€ë¹„**

   ```
   import bs4
   from langchain_community.document_loaders import WebBaseLoader
   from langchain.text_splitter import RecursiveCharacterTextSplitter
   from langchain_openai import OpenAIEmbeddings
   from langchain_community.vectorstores import Chroma

   loader = WebBaseLoader(
       web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
       bs_kwargs=dict(
           parse_only=bs4.SoupStrainer(
               class_=("post-content", "post-title", "post-header")
           )
       ),
   )

   blog_docs = loader.load()

   text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
       chunk_size=300,
       chunk_overlap=50
   )

   splits = text_splitter.split_documents(blog_docs)

   vectorstore = Chroma.from_documents(documents=splits,
                                       embedding=OpenAIEmbeddings())

   retriever = vectorstore.as_retriever()
   ```

   * ë¸”ë¡œê·¸ ë°ì´í„°ë¥¼ ì›¹ì—ì„œ ê°€ì ¸ì™€ `bs4`ë¥¼ ì´ìš©í•´ íŒŒì‹±í•œ í›„, í•´ë‹¹ ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ì— ì¸ë±ì‹±í•©ë‹ˆë‹¤.
   * ë¶„í• ëœ ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•˜ê³ , ê²€ìƒ‰ì„ ìœ„í•œ ì„¤ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

2. **ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì •ì˜**:

```
from langchain.prompts import ChatPromptTemplate

template = """
You are an AI language model assistant. 
Your task is to generate five different versions of the given user question to retrieve relevant documents from a vector database. 
    
By generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search.

Provide these alternative questions separated by newlines. 
    
Original question: {question}
"""
    
prompt_perspectives = ChatPromptTemplate.from_template(template)
```

* ì§ˆë¬¸ì„ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•˜ëŠ” ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
  + (í•´ì„) ë‹¹ì‹ ì€ AI ì–¸ì–´ ëª¨ë¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì‚¬ìš©ì ì§ˆë¬¸ì˜ ë‹¤ì„¯ ê°€ì§€ ë²„ì „ì„ ìƒì„±í•˜ì—¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ê²ƒì´ ì‘ì—…ì˜ ëª©í‘œì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì—¬ëŸ¬ ê´€ì ì„ ìƒì„±í•¨ìœ¼ë¡œì¨ ì‚¬ìš©ìê°€ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ì„± ê²€ìƒ‰ì˜ í•œê³„ë¥¼ ê·¹ë³µí•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. ìƒˆ ì¤„ë¡œ êµ¬ë¶„í•˜ì—¬ ë‹¤ìŒ ëŒ€ì²´ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.

3. **ë‹¤ì¤‘ ì¿¼ë¦¬ë¥¼ ì´ìš©í•œ ê²€ìƒ‰ ë° ë¬¸ì„œ í†µí•©**:

```
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from langchain.load import dumps, loads

generate_queries = (
    prompt_perspectives
    | ChatOpenAI(temperature=0)
    | StrOutputParser()
    | (lambda x: x.split("\n"))
)

def get_unique_union(documents: list[list]):
    """ Unique union of retrieved docs """
    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]
    unique_docs = list(set(flattened_docs))
    return [loads(doc) for doc in unique_docs]

retrieval_chain = generate_queries | retriever.map() | get_unique_union

question = "What is task decomposition for LLM agents?"
docs = retrieval_chain.invoke({"question":question})

len(docs)
```

* ìƒì„±ëœ ì—¬ëŸ¬ ì§ˆë¬¸ì„ ì´ìš©í•´ ë…ë¦½ì ì¸ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

  1. **generate\_queries**: ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•´ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  
     a. ChatOpenAI ëª¨ë¸ì„ í†µí•´ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.  
     b. StrOutputParserë¡œ ëª¨ë¸ì˜ ì¶œë ¥ì„ íŒŒì‹±í•©ë‹ˆë‹¤.  
     c. ê²°ê³¼ë¥¼ ê°œí–‰ ë¬¸ì(\n)ë¡œ ë¶„í• í•˜ì—¬ ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ ë§Œë“­ë‹ˆë‹¤.  
     ![](https://velog.velcdn.com/images/euisuk-chung/post/01b67473-aa52-4e93-acfb-fff027d487c8/image.png)
  2. **retriever**: ìƒì„±ëœ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.  
     a. **`retriever.map()`**ì„ ì‚¬ìš©í•˜ì—¬ ê° ìƒì„±ëœ ì¿¼ë¦¬ì— ëŒ€í•´ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.  
     ![](https://velog.velcdn.com/images/euisuk-chung/post/cd277842-c886-4857-b471-48dec0ab2bb1/image.png)

     ```

     ```
  3. **get\_unique\_union**: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ ì¤‘ ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.

     a. **`get_unique_union`**Â í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ëœ ëª¨ë“  ë¬¸ì„œì—ì„œ ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.

     + `unique_docs = list(set(flattened_docs))` : ì§‘í•©(set)ì„ ì‚¬ìš©í•´ ì¤‘ë³µì„ ì œê±°í•œ í›„, ë‹¤ì‹œ ì›ë˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

     b. **`dumps`**ì™€Â **`loads`**ë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨, Document ê°ì²´ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë³µì„ ì œê±°í•˜ê³ , ë‹¤ì‹œ ì›ë˜ì˜ ê°ì²´ í˜•íƒœë¡œ ë³µì›í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

     + ì´ëŠ” íŠ¹íˆ ë³µì¡í•œ ê°ì²´ êµ¬ì¡°ë¥¼ ê°€ì§„ Document í´ë˜ìŠ¤ë¥¼ ë‹¤ë£° ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

4. **ìµœì¢… RAG(ì§ˆë¬¸ + ë¬¸ì„œ)**:

```
from operator import itemgetter
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnablePassthrough

template = """
Answer the following question based on this context:
{context}

Question: 
{question}
"""

prompt = ChatPromptTemplate.from_template(template)
llm = ChatOpenAI(temperature=0)

# retrieval_chain = generate_queries | retriever.map() | get_unique_union
final_rag_chain = (
    {"context": retrieval_chain,
     "question": itemgetter("question")}
    | prompt
    | llm
    | StrOutputParser()
)

final_rag_chain.invoke({"question":question})
```

* ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ìƒì„±í•˜ëŠ” ìµœì¢… RAG ì²´ì¸ì„ ì •ì˜í•©ë‹ˆë‹¤.
  1. **`retrieval_chain`**ì´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
  2. **`itemgetter("question")`**ê°€ ì…ë ¥ì—ì„œ ì§ˆë¬¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
  3. ì´ ë‘ ìš”ì†Œê°€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì‚½ì…ë©ë‹ˆë‹¤.
  4. ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ê°€ LLMì— ì „ë‹¬ë˜ì–´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

> **ğŸ’¡ `itemgetter` í•¨ìˆ˜ì— ëŒ€í•´ì„œ ë” ì•Œì•„ë³´ì**

1. `itemgetter` í•¨ìˆ˜:
   * `operator` ëª¨ë“ˆì˜ `itemgetter`ëŠ” ë”•ì…”ë„ˆë¦¬ë‚˜ ì‹œí€€ìŠ¤ì—ì„œ íŠ¹ì • í‚¤ë‚˜ ì¸ë±ìŠ¤ì˜ ê°’ì„ ì¶”ì¶œí•˜ëŠ” callable ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
   * ì—¬ê¸°ì„œëŠ” `itemgetter("question")`ì´ ì‚¬ìš©ë˜ì–´, ì…ë ¥ ë”•ì…”ë„ˆë¦¬ì—ì„œ "question" í‚¤ì˜ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
2. `itemgetter`ì™€ `.invoke`ì˜ ìƒí˜¸ì‘ìš©:
   * `final_rag_chain.invoke({"question": question})`ê°€ í˜¸ì¶œë  ë•Œ, `itemgetter("question")`ëŠ” ì´ ì…ë ¥ ë”•ì…”ë„ˆë¦¬ì—ì„œ "question" í‚¤ì˜ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
   * ì´ ì¶”ì¶œëœ ê°’ì€ ì²´ì¸ì˜ "question" ë¶€ë¶„ì— ì „ë‹¬ë©ë‹ˆë‹¤.
3. ì²´ì¸ ë‚´ì—ì„œì˜ ì—­í• :
   * `{"context": retrieval_chain, "question": itemgetter("question")}`ì—ì„œ "question" í‚¤ì— `itemgetter("question")`ì´ í• ë‹¹ë©ë‹ˆë‹¤.
   * ì´ëŠ” ì…ë ¥ ë”•ì…”ë„ˆë¦¬ì˜ "question" ê°’ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
4. ì „ì²´ ê³¼ì •:
   * `.invoke({"question": question})`ê°€ í˜¸ì¶œë˜ë©´, ì´ ë”•ì…”ë„ˆë¦¬ê°€ ì²´ì¸ì— ì…ë ¥ë©ë‹ˆë‹¤.
   * `itemgetter("question")`ëŠ” ì´ ë”•ì…”ë„ˆë¦¬ì—ì„œ "question" ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
   * ì¶”ì¶œëœ ê°’ì€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì˜ {question} ë¶€ë¶„ì„ ì±„ìš°ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.

---

### Part 6 (RAG Fusion)

* ì´ ê°•ì˜ëŠ” RAG(Retrieval-Augmented Generation) íŒŒì´í”„ë¼ì¸ì˜ "Query Translation(ì¿¼ë¦¬ ë³€í™˜)" ë‘ ë²ˆì§¸ ë°©ë²•ì¸ **RAG Fusion**ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/1403eb4f-ab2c-4bf7-837b-26d6c45a103f/image.png)

* RAG Fusionì€ **ë‹¤ì¤‘ ì¿¼ë¦¬ì™€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©**í•˜ëŠ” ê³¼ì •ì—ì„œ ì¤‘ìš”í•œ ê¸°ë²•ìœ¼ë¡œ, **Reciprocal Rank Fusion(RRF)**ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ **ì¬ì •ë ¬**í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
  + ì´ì „ì— ì±•í„° 5ì—ì„œ ì„¤ëª…í•œ ë‹¤ì¤‘ ì¿¼ë¦¬ ë°©ë²•ì—ì„œëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ í˜•íƒœë¡œ ë³€í™˜í•œ í›„, ê° ë³€í™˜ëœ ì§ˆë¬¸ìœ¼ë¡œ ë…ë¦½ì ì¸ ê²€ìƒ‰ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.
  + RAG Fusionë„ ê¸°ë³¸ì ìœ¼ë¡œ ê°™ì€ êµ¬ì¡°ë¥¼ ë”°ë¥´ì§€ë§Œ, **Reciprocal Rank Fusion(RRF)**ì´ë¼ëŠ” ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ë‹¤ **íš¨ìœ¨ì ìœ¼ë¡œ ê²°í•©**í•˜ê³  **ì¬ì •ë ¬**í•©ë‹ˆë‹¤.
  + **RRF**ì˜ í•µì‹¬ ê°œë…ì€ ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° ë¬¸ì„œì˜ ë­í‚¹ì„ ê³„ì‚°í•˜ê³ , **ìƒí˜¸ ìˆœìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì„œë“¤ì˜ ìµœì¢… ìˆœìœ„ë¥¼ ê²°ì •**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

**RAG Fusionì˜ ì§ê´€**

RAG Fusionì˜ ê¸°ë³¸ ì›ë¦¬ëŠ” ë‹¤ì¤‘ ì¿¼ë¦¬ ë°©ë²•ê³¼ ìœ ì‚¬í•˜ê²Œ **ì—¬ëŸ¬ ë²ˆì˜ ê²€ìƒ‰ì„ í†µí•´ ê° ì§ˆë¬¸ì— ëŒ€í•œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±**í•œ í›„, RRF ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ **ê° ë¬¸ì„œì˜ ìˆœìœ„ë¥¼ í•©ì‚°**í•˜ì—¬ ìµœì¢… ìˆœìœ„ê°€ ë†’ì€ ë¬¸ì„œë¥¼ ì„ íƒí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ **ê°ê°ì˜ ë…ë¦½ì ì¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìµœì í™”í•˜ì—¬ ìµœì¢… ë¬¸ì„œë¥¼ êµ¬ì„±**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. **ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±**: í•˜ë‚˜ì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì—¬ëŸ¬ ë³€í˜•ëœ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, "ì¸ê³µì§€ëŠ¥ì˜ ë°œì „"ì´ë¼ëŠ” ì§ˆë¬¸ì— ëŒ€í•´ "AIì˜ ë¯¸ë˜", "ê¸°ê³„ í•™ìŠµì˜ ì—­ì‚¬" ë“± ë‹¤ì–‘í•œ ì¿¼ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **ê°œë³„ ê²€ìƒ‰ ìˆ˜í–‰**: ê° ë³€í˜•ëœ ì¿¼ë¦¬ë¡œ ë…ë¦½ì ì¸ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì¦‰, í•˜ë‚˜ì˜ ì¿¼ë¦¬ê°€ ì•„ë‹ˆë¼ ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ì„ ì§„í–‰í•˜ì—¬ ë” ë‹¤ì–‘í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.
3. **RRF ì ìš©**: ì´ë ‡ê²Œ ì–»ì€ ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ RRF ë°©ì‹ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤. ê° ë¬¸ì„œì˜ ìˆœìœ„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³ , ìƒìœ„ ë¬¸ì„œì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ë©´ì„œ ìµœì¢… ìˆœìœ„ë¥¼ ì¬ì •ë ¬í•©ë‹ˆë‹¤.
4. **ê²°ê³¼ í†µí•©**: ì¬ì •ë ¬ëœ ë¬¸ì„œë“¤ì„ ìµœì¢… ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ LLMì— ì…ë ¥í•©ë‹ˆë‹¤. LLMì€ ì´ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

**Reciprocal Rank Fusion (RRF)**

1. **ìˆœìœ„ ê¸°ë°˜ ì ‘ê·¼ (Ranking-based Approach)**

RRFëŠ” ê²€ìƒ‰ ê²°ê³¼ë¥¼ "ì ìˆ˜"ê°€ ì•„ë‹Œ "ìˆœìœ„"ì— ê¸°ë°˜í•´ í†µí•©í•©ë‹ˆë‹¤. ì´ëŠ” ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê° ë¬¸ì„œê°€ ëª‡ ë²ˆì§¸ë¡œ ì¤‘ìš”í•œì§€(ìˆœìœ„)ë¥¼ ë§¤ê¸°ê³ , ì´ë¥¼ í™œìš©í•´ ìµœì¢…ì ìœ¼ë¡œ ì–´ë–¤ ë¬¸ì„œê°€ ë” ì¤‘ìš”í•œì§€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.

* **ì™œ ìˆœìœ„ê°€ ì¤‘ìš”í•œê°€?**
  + ì¼ë°˜ì ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ëŠ” ì ìˆ˜(í•´ë‹¹ ë¬¸ì„œê°€ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ë†’ì€ì§€ í‰ê°€í•œ ê°’)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‚˜ì—´ë˜ëŠ”ë°, ë¬¸ì œëŠ” ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ë§ˆë‹¤ ì´ ì ìˆ˜ ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.
  + ì˜ˆë¥¼ ë“¤ì–´, í•˜ë‚˜ì˜ ê²€ìƒ‰ ì—”ì§„ì€ 0ì—ì„œ 1ê¹Œì§€ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³ , ë‹¤ë¥¸ ì—”ì§„ì€ 0ì—ì„œ 100ê¹Œì§€ ì ìˆ˜ë¥¼ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥´ë©´ ë‹¨ìˆœíˆ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.
  + ë°˜ë©´, ìˆœìœ„ëŠ” ê° ê²€ìƒ‰ ì—”ì§„ì—ì„œ ë§¤ê²¨ì§„ ìˆœì„œ ê·¸ëŒ€ë¡œ í™œìš©í•˜ê¸° ë•Œë¬¸ì— ìŠ¤ì¼€ì¼ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

2. **RRF ì ìˆ˜ ê³„ì‚° ë°©ì‹**

* RRFì—ì„œ ê° ë¬¸ì„œì˜ ì ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ë©ë‹ˆë‹¤:

  score=âˆ‘1k+rank(d)score = \sum \frac{1}{k + rank(d)}score=âˆ‘k+rank(d)1â€‹
* ì—¬ê¸°ì„œ **k**ëŠ” ì‘ì€ ìƒìˆ˜(ì¼ë°˜ì ìœ¼ë¡œ 60 ì •ë„), `rank(d)`ëŠ” ë¬¸ì„œ **d**ê°€ ê° ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì°¨ì§€í•œ ìˆœìœ„ì…ë‹ˆë‹¤. ìˆœìœ„ê°€ ë†’ì„ìˆ˜ë¡, ì¦‰ ë” ìƒìœ„ì— ë­í¬ëœ ë¬¸ì„œì¼ìˆ˜ë¡ ì ìˆ˜ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤.
* ì´ ê³µì‹ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì˜ˆë¥¼ ë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤:

  + ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì–´ë–¤ ë¬¸ì„œê°€ ì²« ë²ˆì§¸ ìˆœìœ„ì— ìˆìœ¼ë©´, ì ìˆ˜ëŠ” 160+1\frac{1}{60 + 1}60+11â€‹ , ì¦‰ ì•½ 0.016ì…ë‹ˆë‹¤.
  + ë‘ ë²ˆì§¸ ìˆœìœ„ë¼ë©´, ì ìˆ˜ëŠ”160+2\frac{1}{60 + 2}60+21â€‹ , ì¦‰ ì•½ 0.0157ì´ ë©ë‹ˆë‹¤.
  + ì´ì²˜ëŸ¼ ìˆœìœ„ê°€ ë‚®ì•„ì§ˆìˆ˜ë¡ ì ìˆ˜ê°€ ì¤„ì–´ë“œëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ìƒìœ„ì— ë­í¬ëœ ë¬¸ì„œê°€ ë” í° ì˜í–¥ì„ ë¯¸ì¹˜ê²Œ ë©ë‹ˆë‹¤.

**ì½”ë“œ ì‹œì—°**

**1. RAG Fusionìš© í”„ë¡¬í”„íŠ¸ ì •ì˜ ë° ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±**

```
from langchain.prompts import ChatPromptTemplate

template = """
You are a helpful assistant that generates multiple search queries based on a single input query. \n
Generate multiple search queries related to: {question} \n

Output (4 queries):
"""

prompt_rag_fusion = ChatPromptTemplate.from_template(template)

from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

generate_queries = (
    prompt_rag_fusion
    | ChatOpenAI(temperature=0)
    | StrOutputParser()
    | (lambda x: x.split("\n"))
)
```

1. ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±:
   * ChatPromptTemplateì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì—¬ëŸ¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.
2. ì²´ì¸ êµ¬ì„±:
   * prompt\_rag\_fusion | ChatOpenAI | StrOutputParser() ìˆœìœ¼ë¡œ ì²´ì¸ì„ êµ¬ì„±í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰, LLM ì‘ë‹µ ìƒì„±, ë¬¸ìì—´ íŒŒì‹±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
3. ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜:
   * **`(lambda x: x.split("\n"))`**Â ë¶€ë¶„ì´ LLMì˜ ì¶œë ¥ì„ ì¤„ë°”ê¿ˆì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.

**2. Reciprocal Rank Fusion (RRF) í•¨ìˆ˜ ì •ì˜ ë° ê²€ìƒ‰ ìˆ˜í–‰**

```
from langchain.load import dumps, loads

def reciprocal_rank_fusion(results: list[list], k=60):
    """ Reciprocal_rank_fusion that takes multiple lists of ranked documents 
        and an optional parameter k used in the RRF formula """
    
    # Initialize a dictionary to hold fused scores for each unique document
    fused_scores = {}

    # Iterate through each list of ranked documents
    for docs in results:
        # Iterate through each document in the list, with its rank (position in the list)
        for rank, doc in enumerate(docs):
            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)
            doc_str = dumps(doc)
            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0
            if doc_str not in fused_scores:
                fused_scores[doc_str] = 0
            # Retrieve the current score of the document, if any
            previous_score = fused_scores[doc_str]
            # Update the score of the document using the RRF formula: 1 / (rank + k)
            fused_scores[doc_str] = previous_score + 1 / (rank + k)

    # Sort the documents based on their fused scores in descending order to get the final reranked results
    reranked_results = [
        (loads(doc), score)
        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)
    ]

    # Return the reranked results as a list of tuples, each containing the document and its fused score
    return reranked_results

retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion
docs = retrieval_chain_rag_fusion.invoke({"question": question})
len(docs)
```

* RRF ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•˜ì—¬, ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë¬¸ì„œë¥¼ í†µí•©í•˜ê³  ìˆœìœ„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
  + ì´ì¤‘ for ë¬¸ì„ í†µí•´ ê°ê° resultì™€ docsë¥¼ ëŒë©´ì„œ ë“±ì¥í•˜ëŠ” ë¬¸ì„œì˜ ìˆœì„œì— ë”°ë¼ ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
  + (ì°¸ê³ ) ì´ì „ì— ê°œë…ì—ì„œ ì‚´í´ë´£ë˜ ê²ƒì²˜ëŸ¼ RRFì˜ scoreëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
    - score=âˆ‘1k+rank(d)score = \sum \frac{1}{k + rank(d)}score=âˆ‘k+rank(d)1â€‹
  + ì¬ ë“±ì¥í•œ ë¬¸ì„œì— ëŒ€í•´ì„œëŠ” ì´ì „ score(previous score)ì— í˜„ì¬ ìŠ¤ì½”ì–´(current score)ë¥¼ ë”í•´ì£¼ëŠ” í˜•íƒœë¡œ ì§„í–‰í•©ë‹ˆë‹¤
* ìƒì„±ëœ ì¿¼ë¦¬ë¥¼ í†µí•´ ë…ë¦½ì ì¸ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ RRF ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì¬ì •ë ¬í•©ë‹ˆë‹¤.

**3. ìµœì¢… RAG ì²´ì¸ ì •ì˜**

```
from langchain_core.runnables import RunnablePassthrough

template = """Answer the following question based on this context:

{context}

Question: {question}
"""

prompt = ChatPromptTemplate.from_template(template)

final_rag_chain = (
    {"context": retrieval_chain_rag_fusion,
     "question": itemgetter("question")}
    | prompt
    | llm
    | StrOutputParser()
)

final_rag_chain.invoke({"question":question})
```

* ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ìƒì„±í•˜ëŠ” ìµœì¢… RAG ì²´ì¸ì„ ì •ì˜í•©ë‹ˆë‹¤.

**ìš”ì•½**

* **RAG Fusion**ì€ ë‹¤ì¤‘ ì¿¼ë¦¬ë¥¼ ì´ìš©í•´ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ **Reciprocal Rank Fusion(RRF)** ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ **ì¬ì •ë ¬**í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
* RRFëŠ” **ë‹¤ì–‘í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í†µí•©**í•˜ì—¬, ê° ë¬¸ì„œì˜ ì¤‘ìš”ë„ë¥¼ ìˆœìœ„ë¡œ í™˜ì‚°í•˜ê³  **ìµœì ì˜ ë¬¸ì„œë¥¼ ì„ íƒ**í•˜ëŠ” ë° ìœ ë¦¬í•œ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.
* ì´ ë°©ë²•ì€ íŠ¹íˆ **ì—¬ëŸ¬ ê°œì˜ ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ë™ì‹œì— ê²€ìƒ‰**í•˜ê±°ë‚˜, **ë‹¤ì–‘í•œ í˜•íƒœì˜ ì§ˆë¬¸**ì— ëŒ€í•´ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ë•Œ ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

**ì¤‘ê°„ ì •ë¦¬**

* ì§€ê¸ˆê¹Œì§€ `ë©€í‹°ì¿¼ë¦¬ ê¸°ë²•` ê³¼ `RAG Fusion`ì— ëŒ€í•´ì„œ ì‚´í´ë´¤ëŠ”ë°ìš”. í•œë²ˆ ì •ë¦¬í•˜ê³  ë„˜ì–´ê°€ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.
* ë‘ ê¸°ë²• ëª¨ë‘ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° íš¨ê³¼ì ì´ì§€ë§Œ, RAG Fusionì€ ê²°ê³¼ì˜ í’ˆì§ˆ ê°œì„ ì— ë” ì¤‘ì ì„ ë‘ëŠ” ë°˜ë©´, ë©€í‹°ì¿¼ë¦¬ ê¸°ë²•ì€ ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€ì— ë” ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.
* ìƒí™©ì— ë”°ë¼ ì ì ˆí•œ ê¸°ë²•ì„ ì„ íƒí•˜ê±°ë‚˜ ë‘ ê¸°ë²•ì„ ê²°í•©í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

RAG Fusion

* **ì¿¼ë¦¬ ìƒì„±:** ì›ë³¸ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì„ ì‚¬ìš©í•´ ì—¬ëŸ¬ ê°œì˜ ê´€ë ¨ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
* **ê²€ìƒ‰ ê³¼ì •:** ìƒì„±ëœ ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ ê°ê° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
* **ê²°ê³¼ í†µí•©:** Reciprocal Rank Fusion (RRF) ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•˜ê³  ì¬ì •ë ¬í•©ë‹ˆë‹¤.
* **ì¥ì :** ë‹¤ì–‘í•œ ê´€ì ì˜ ì¿¼ë¦¬ë¥¼ í†µí•´ ë” í¬ê´„ì ì¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìœ¼ë©°, RRFë¥¼ í†µí•´ ê²°ê³¼ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

ë©€í‹°ì¿¼ë¦¬ ê¸°ë²• (Multi-Query Retriever)

* **ì¿¼ë¦¬ ìƒì„±:** ì›ë³¸ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì„ ì‚¬ìš©í•´ ì—¬ëŸ¬ ê°œì˜ ê´€ë ¨ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
* **ê²€ìƒ‰ ê³¼ì •:** ìƒì„±ëœ ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ ê°ê° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
* **ê²°ê³¼ í†µí•©:** ê²€ìƒ‰ëœ ëª¨ë“  ë¬¸ì„œë¥¼ ë‹¨ìˆœíˆ í•©ì¹˜ê±°ë‚˜, ì¤‘ë³µì„ ì œê±°í•˜ì—¬ í†µí•©í•©ë‹ˆë‹¤.
* **ì¥ì :** ë‹¨ì¼ ì¿¼ë¦¬ë³´ë‹¤ ë” ë‹¤ì–‘í•œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆì–´ recallì´ í–¥ìƒë©ë‹ˆë‹¤.

---

### Part 7 (ë¶„í•´)

* ì´ ê°•ì˜ëŠ” RAG(Retrieval-Augmented Generation) íŒŒì´í”„ë¼ì¸ì˜ "Query Translation(ì¿¼ë¦¬ ë³€í™˜)" ì¤‘ ì„¸ ë²ˆì§¸ ë°©ë²•ì¸ **Decomposition(ì§ˆë¬¸ ë¶„í•´)**ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.

ë¬¸ì œ ì •ì˜ ë° ì ‘ê·¼ ë°©ë²•

* **Decomposition(ì§ˆë¬¸ ë¶„í•´)**ëŠ” **ë³µì¡í•œ ì§ˆë¬¸ì„ ì—¬ëŸ¬ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê°ê°ì„ ë…ë¦½ì ìœ¼ë¡œ í•´ê²°**í•œ í›„, ìµœì¢…ì ìœ¼ë¡œ í†µí•©í•˜ì—¬ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
* ì´ì „ ë°©ë²•ë“¤ì¸ ë‹¤ì¤‘ ì¿¼ë¦¬(Multi-query)ì™€ RAG Fusionì—ì„œëŠ” ì§ˆë¬¸ì„ ì—¬ëŸ¬ ë°©ì‹ìœ¼ë¡œ ë³€í™˜(rewrite-question)í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ ê°œì„ í•˜ë ¤ í–ˆìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/779bcaba-9fde-4f97-a2a0-80238d30d4f3/image.png)

* **Decomposition** ë°©ì‹, ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œëŠ” sub-questionë°©ì‹ì€ ê¸°ì¡´ ì§ˆë¬¸ì„ **í•˜ìœ„ ë¬¸ì œë¡œ ë¶„í•´í•˜ì—¬ ê° ë¬¸ì œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í•´ê²°**í•˜ëŠ” ì ‘ê·¼ì…ë‹ˆë‹¤.
  + ì´ ë°©ë²•ì€ ì£¼ë¡œ ë³µì¡í•œ ë¬¸ì œë‚˜ ì§ˆë¬¸ì„ í•´ê²°í•  ë•Œ ìœ ìš©í•˜ë©°, **ê°ê°ì˜ í•˜ìœ„ ì§ˆë¬¸ì„ ë…ë¦½ì ìœ¼ë¡œ í•´ê²°**í•˜ë©´ì„œ ì´ì „ ì§ˆë¬¸ì˜ ë‹µì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ í•´ê²°í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
  + ì£¼ìš” ì—°êµ¬ ë° ë°©ë²•ë¡ ìœ¼ë¡œëŠ” â€œLeast-to-Mostâ€ì™€ â€œIT-CoTâ€ê¸°ë²•ì´ ìˆìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/c1ae8545-b610-422e-919f-1e6b857b72a9/image.png)

* **ë…¼ë¬¸: Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**
  + ìµœì†Œ-ìµœëŒ€ í”„ë¡¬í”„íŒ…(Least-to-Most Prompting)ì€ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë¬¸ì œë¥¼ ë” ì‘ì€ í•˜ìœ„ ë¬¸ì œë¡œ ë‚˜ëˆˆ í›„, ê° í•˜ìœ„ ë¬¸ì œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
  + ì´ì „ í•˜ìœ„ ë¬¸ì œì˜ ë‹µì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í•˜ìœ„ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì´ ì–´ë ¤ìš´ ë¬¸ì œë¥¼ ë” ì‰½ê²Œ í•´ê²°í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
  + Chain-of-Thought(ì—°ì‡„ì  ì‚¬ê³  í”„ë¡¬í”„íŒ…)ì™€ ê°™ì€ ê¸°ì¡´ ê¸°ë²•ì€ ë” ì–´ë ¤ìš´ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° í•œê³„ê°€ ìˆì—ˆìœ¼ë‚˜, ìµœì†Œ-ìµœëŒ€ í”„ë¡¬í”„íŒ…ì€ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

  

* **ë…¼ë¬¸: Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions**
  + IRCoTëŠ” ë‹¤ë‹¨ê³„ ì§ˆë¬¸ì— ë‹µí•  ë•Œ, ì •ë³´ ê²€ìƒ‰ê³¼ Chain-of-Thought(COT) ì¶”ë¡ ì„ ìƒí˜¸ ë³´ì™„ì ìœ¼ë¡œ ê²°í•©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
  + ëª¨ë¸ì´ ë‹µì„ ë„ì¶œí•˜ëŠ” ì¤‘ê°„ ë‹¨ê³„ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ì§€ì†ì ìœ¼ë¡œ ê²€ìƒ‰í•´ ì˜¤ê³ , ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ CoT ë‹¨ê³„ë¥¼ ìƒì„±í•˜ì—¬ ì´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤.
  + ë‹¨ê³„ë³„ë¡œ í•„ìš”í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì¶”ë¡  ê³¼ì •ì„ í†µí•´ ì–»ì€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ê°€ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ê°œì„ í•©ë‹ˆë‹¤.

  

* ì´ëŸ¬í•œ ê°œë…ë“¤ì„ ì¢…í•©í•´ì„œ ì•„ë˜ì™€ ê°™ì decomposition ì»¨ì…‰ì„ ê·¸ë ¤ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

![](https://velog.velcdn.com/images/euisuk-chung/post/9d42e0ae-f97d-48e2-87ed-3075e20c34a1/image.png)

**Decomposition ë°©ì‹ì˜ ì§ê´€**

* Decomposition ë°©ì‹ì—ì„œëŠ” ì§ˆë¬¸ì„ ì‘ê²Œ ë‚˜ëˆ„ì–´ **ë” ì‰½ê²Œ í•´ê²°í•  ìˆ˜ ìˆëŠ” í•˜ìœ„ ë¬¸ì œë¡œ ë¶„í•´**í•˜ê³ , ê°ê°ì˜ ë¬¸ì œì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ê²€ìƒ‰ ë° ë‹µë³€ì„ ì§„í–‰í•©ë‹ˆë‹¤.
* ì´ ê³¼ì •ì—ì„œ **ì´ì „ ì§ˆë¬¸ì˜ ë‹µë³€ì„ ë‹¤ìŒ ì§ˆë¬¸ì— ì‚¬ìš©**í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´, ë³µì¡í•œ ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì½”ë“œ ì‹œì—°**

**1. Decompositionìš© í”„ë¡¬í”„íŠ¸ ì •ì˜ / LLMì„ ì´ìš©í•œ í•˜ìœ„ ì§ˆë¬¸ ìƒì„±**

```
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# prompt template for decomposition
template = """
You are a helpful assistant that generates multiple sub-questions related to an input question. \n

The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \n

Generate multiple search queries related to: {question} \n

Output (3 queries):
"""

prompt_decomposition = ChatPromptTemplate.from_template(template)

llm = ChatOpenAI(temperature=0)

generate_queries_decomposition = (
    prompt_decomposition 
    | llm 
    | StrOutputParser() 
    | (lambda x: x.split("\n"))
)

# ì˜ˆì‹œ ì§ˆë¬¸
question = "What are the main components of an LLM-powered autonomous agent system?"

questions = generate_queries_decomposition.invoke({"question":question})
```

* ì…ë ¥ëœ ì§ˆë¬¸ì„ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
* í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ëœ ì§ˆë¬¸ì„ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•˜ê³ , ì´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/38cb1bea-0454-4826-abdf-be7fff84d181/image.png)

* ìœ„ ì˜ˆì‹œë¥¼ ë³´ë©´, generate\_queries\_decompositionë¥¼ í†µí•´ì„œ â€œ**LLM ê¸°ë°˜ ììœ¨ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?**â€ ì´ë¼ëŠ” ì§ˆë¬¸ì´ ì•„ë˜ì™€ ê°™ì´ 3ê°€ì§€ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

  + '1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ í•µì‹¬ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?
  + '2. ììœ¨ ì—ì´ì „íŠ¸ëŠ” ì–´ë–»ê²Œ LLMì„ ì•„í‚¤í…ì²˜ì— í†µí•©í•˜ë‚˜ìš”?'
  + '3. LLM ê¸°ë°˜ ììœ¨ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?'

**2. í•˜ìœ„ ì§ˆë¬¸ë³„ë¡œ ë‹µë³€ ìƒì„± ë° ì—°ì†ì ì¸ ì²˜ë¦¬**

```
from operator import itemgetter
from langchain_core.output_parsers import StrOutputParser

# prompt template for RAG
template = """
Here is the question you need to answer:

\n --- \n {question} \n --- \n

Here is any available background question + answer pairs:

\n --- \n {q_a_pairs} \n --- \n

Here is additional context relevant to the question: 

\n --- \n {context} \n --- \n

Use the above context and any background question + answer pairs to answer the question: \n {question}
"""

decomposition_prompt = ChatPromptTemplate.from_template(template)

def format_qa_pair(question, answer):
    """
    Format question and answer pairs for inclusion in the prompt
    """
    formatted_string = ""
    formatted_string += f"Question: {question}\nAnswer: {answer}\n\n"
    return formatted_string.strip()

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

# Initialize an empty string to accumulate question-answer pairs
q_a_pairs = ""

for q in questions:
    rag_chain = (
        {
            "context": itemgetter("question") | retriever, 
            "question": itemgetter("question"),
            "q_a_pairs": itemgetter("q_a_pairs")
        } 
        | decomposition_prompt
        | llm
        | StrOutputParser()
    )
    
    answer = rag_chain.invoke({"question": q, "q_a_pairs": q_a_pairs})
    q_a_pair = format_qa_pair(q, answer)
    q_a_pairs = q_a_pairs + "\n---\n" + q_a_pair
```

* ìœ„ì—ì„œ ìƒì„±ëœ 3ê°œì˜ í•˜ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³ , **ì´ì „ ì§ˆë¬¸ì˜ ë‹µë³€ì„ ë‹¤ìŒ ì§ˆë¬¸ì— í™œìš©**í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ í•´ê²°í•´ ë‚˜ê°‘ë‹ˆë‹¤.

  + `q_a_pair = format_qa_pair(q, answer)` ë¥¼ í†µí•´ ì´ì „ ë‹µë³€ì„ ê°ì‹¸ê³ , rag\_chain.invoke({"question": q, "q\_a\_pairs": `q_a_pairs`}) ì‹œì— ë„£ì–´ì¤Œìœ¼ë¡œì¨ ì´ì „ ë‹µë³€ì„ í˜„ì¬ ë‹µë³€ì„ í•´ì¤„ë•Œ ì°¸ê³ í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.
* (ì˜ˆì‹œ) 2ë²ˆì§¸ í”„ë¡¬í”„íŠ¸ Input

  ```
  # 2ë²ˆ ì§ˆë¬¸ì˜ ë‹µë³€ì„ ìœ„í•´ q_a_pairë¡œ 1ë²ˆ Questionê³¼ Answerë¥¼ ì°¸ê³ í•˜ê³  ìˆìŒ
  {
    "question": 
  "2. How do autonomous agents integrate LLMs into their architecture?",

    "q_a_pairs": 
  "\n---\nQuestion: 1. What are the core elements of a large language model (LLM)?\n
  Answer: The core elements of a large language model (LLM) include:\n\n1. **Architecture**: The foundational design of the LLM, typically involving layers of neural networks such as transformers. This architecture determines how the model processes and generates language.\n\n2. **Training Data**: The corpus of text data used to train the model. This data is crucial for the model to learn language patterns, grammar, facts, and even some reasoning capabilities.\n\n3. **Training Process**: The method by which the model learns from the training data, often involving techniques like supervised learning, unsupervised learning, or reinforcement learning. This process includes fine-tuning and adjusting the model's parameters to improve its performance.\n\n4. **Tokenization**: The process of breaking down text into smaller units (tokens) that the model can understand and process. Tokenization is essential for handling different languages, special characters, and various text structures.\n\n5. **Context Handling**: The mechanism by which the model understands and maintains the context of a conversation or text. This includes managing the finite context length and using techniques like attention mechanisms to focus on relevant parts of the input.\n\n6. **Memory**: Systems that allow the model to store and recall information beyond the immediate context window. This can involve techniques like vector stores and retrieval systems to access a larger knowledge pool.\n\n7. **Inference Mechanism**: The process by which the model generates responses based on the input it receives. This includes the model's ability to perform tasks like text generation, translation, summarization, and more.\n\n8. **Optimization and Planning**: For advanced applications, LLMs may include components for planning, breaking down tasks into subgoals, and refining actions based on self-reflection and feedback.\n\nThese elements work together to enable the LLM to perform a wide range of language-related tasks effectively."
  }
  ```
* **ìµœì¢… ë‹µë³€**: 1 â†’ 2 â†’ 3ì— ëŒ€í•´ì„œ ìˆœì°¨ì ìœ¼ë¡œ ë‹µë³€ í•´ê°€ë©´ì„œ ê³ ë„í™”í•´ê°„ ë‹µë³€ì…ë‹ˆë‹¤.

  + ë‚´ìš©ì„ ë³´ë‹ˆ ì–¼ì¶” ë§ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.

    ```
    The essential technologies supporting an LLM-powered autonomous agent include:
    ```
  1. Large Language Models (LLMs):

     + Natural Language Interface: LLMs serve as the core controller or "brain" of the system, enabling the agent to understand, generate, and parse instructions and responses through natural language interactions. This interface facilitates communication between the LLM and external components such as memory systems, planning modules, and tools.
  2. Planning Technologies:

     + Task Decomposition: Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) are used to break down complex tasks into smaller, manageable subgoals. This helps the agent plan and execute tasks step-by-step.
     + Reflection and Refinement: The agent performs self-criticism and self-reflection to learn from past actions, refine strategies, and improve the quality and efficiency of its outputs.
  3. Memory Systems:

     + Finite Context Length Handling: Due to the finite context length limitation of LLMs, mechanisms such as vector stores and retrieval are employed to access a larger knowledge pool and overcome context capacity constraints.
     + Retrieval Models: These models surface relevant context based on factors like recency, importance, and relevance to inform the agent's behavior and decision-making processes.
     + Reflection Mechanism: This involves synthesizing memories into higher-level inferences that guide future behavior, generating summaries of past events for better decision-making.
  4. Inter-Agent Communication:

     + The LLM generates natural language statements to facilitate communication between different agents within the system, triggering new actions and responses based on the shared information.
  5. Environment Interaction:

     + The LLM translates reflections and environmental information into actionable plans, considering relationships between agents and observations to optimize both immediate and long-term actions.
  6. Proof-of-Concept Implementations:

     + Examples like AutoGPT, GPT-Engineer, and BabyAGI demonstrate the potential of LLM-powered autonomous agents, highlighting the integration of LLMs with other system components to handle complex tasks and improve over time through continuous learning and refinement.

     Together, these technologies enable LLM-powered autonomous agents to plan, learn, adapt, and interact effectively, supporting their function as powerful general problem solvers.

**3. í•˜ìœ„ ì§ˆë¬¸ë³„ë¡œ ë‹µë³€ ìƒì„± ë° ì—°ì†ì ì¸ ì²˜ë¦¬**

* (ê³ ì§‘) í•˜ì§€ë§Œ, ì›ë³¸ ì§ˆë¬¸ì€ Key componentsë¥¼ ë¬»ëŠ”ê±°ì˜€ìœ¼ë¯€ë¡œ, essential technologiesë¼ê³  ë‹µí•˜ëŠ” ê²ƒì€ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•ŠìŠµë‹ˆë‹¤.
  + ì´ì— í•œë²ˆ ë” ì›ë³¸ ì§ˆë¬¸ì„ ì°¸ì¡°í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ì„œ í˜¸ì¶œí•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/a82cb9ad-ff70-4376-8b76-c2beffc101a8/image.png)

```
# After processing sub-questions and accumulating q_a_pairs
final_prompt_template = """
You are a knowledgeable assistant.

Here is the original question:

{original_question}

Here are the relevant question and answer pairs that may help you:

{q_a_pairs}

Using the information above, please provide a detailed and comprehensive answer to the original question.
"""

final_prompt = ChatPromptTemplate.from_template(final_prompt_template)

# Reuse or initialize the LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

# Create the chain
final_chain = (
    final_prompt
    | llm
    | StrOutputParser()
)

# Invoke the chain to get the final answer
final_answer = final_chain.invoke({"original_question": question, "q_a_pairs": q_a_pairs})
print("Final Answer:\n", final_answer)
```

**ë‹µë³€:**

```
Final Answer:
# Main Components of an LLM-Powered Autonomous Agent System

- An LLM-powered autonomous agent system integrates a variety of technologies and modules to enable the agent to plan, learn, adapt, and interact with its environment and other agents effectively. Below are the main components of such a system:

## 1. Large Language Models (LLMs)
- Core Controller: The LLM acts as the brain of the system, driving the core functionalities. It understands, generates, and parses instructions and responses through natural language interactions.
  
## 2. Natural Language Interface
- Communication: This interface allows for natural language interactions between the LLM and external components such as memory systems and planning modules. It facilitates effective communication and information exchange within the system.

## 3. Planning
- Task Decomposition: Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) are used to break down complex tasks into smaller, manageable subgoals. This helps in planning and executing tasks step-by-step.
- Reflection and Refinement: The agent can perform self-criticism and self-reflection over past actions, learning from mistakes, and refining its approach for future tasks. This continuous improvement enhances the quality and efficiency of the agent's outputs.

## 4. Memory Systems
- Finite Context Length Handling: Due to the finite context length limitation of LLMs, mechanisms such as vector stores and retrieval models are employed to access a larger knowledge pool.
- Retrieval Models: These models surface relevant context based on factors like recency, importance, and relevance to inform the agent's behavior and decision-making processes.
- Reflection Mechanism: This involves synthesizing memories into higher-level inferences that guide future behavior. It generates summaries of past events and uses them for better decision-making.

## 5. Inter-Agent Communication
- Natural Language Statements: The LLM generates natural language statements to facilitate communication between different agents within the system. This enables the sharing of information, triggering new actions and responses.

## 6. Environment Interaction
- Actionable Plans: The LLM translates reflections and environmental information into actionable plans. It takes into account the relationships between agents and observations to optimize both immediate and long-term actions.

## 7. Proof-of-Concept Implementations
- Examples: Implementations like AutoGPT, GPT-Engineer, and BabyAGI demonstrate the potential and capabilities of LLM-powered autonomous agents. These examples highlight the integration of LLMs with other system components to handle complex tasks and improve over time through continuous learning and refinement.

# Summary
An LLM-powered autonomous agent system is composed of several key components that work together to enable sophisticated functionalities. The Large Language Model (LLM) serves as the core controller, interfacing with other modules through a natural language interface. The planning module uses techniques like Task Decomposition and Reflection and Refinement to manage tasks efficiently. Memory systems overcome the finite context length of LLMs by employing vector stores and retrieval models, aiding in better decision-making. Inter-agent communication and environment interaction modules ensure seamless information exchange and actionable planning. Proof-of-concept implementations illustrate the practical applications and continuous improvement potential of these systems. Together, these components create a robust framework for autonomous agents capable of complex problem-solving and adaptive learning.
```

**(ì°¸ê³ ) ëª¨ë“  í•˜ìœ„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬**

![](https://velog.velcdn.com/images/euisuk-chung/post/6560d9f9-3c93-458c-a8d9-67b371080571/image.png)

* ìœ„ì—ì„œëŠ” ìˆœì°¨ì ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ë‹µë³€ì„ ê° í•˜ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ **ìˆœì°¨ì ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±**í•˜ê³  ì´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
* ë°˜ë©´ì— í•´ë‹¹ ì˜ˆì‹œëŠ” ê°**ê° í•˜ìœ„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„± í›„ ì´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±**í•©ë‹ˆë‹¤.

```
from langchain import hub
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

# RAG í”„ë¡¬í”„íŠ¸
prompt_rag = hub.pull("rlm/rag-prompt")

def retrieve_and_rag(question, prompt_rag, sub_question_generator_chain):
    """í•˜ìœ„ ì§ˆë¬¸ì— ëŒ€í•œ RAG ìˆ˜í–‰"""
    sub_questions = sub_question_generator_chain.invoke({"question":question})
    rag_results = []

    for sub_question in sub_questions:
        retrieved_docs = retriever.get_relevant_documents(sub_question)
        answer = (prompt_rag | llm | StrOutputParser()).invoke({"context": retrieved_docs,
                                                                "question": sub_question})
        rag_results.append(answer)

    return rag_results, sub_questions

answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries_decomposition)

def format_qa_pairs(questions, answers):
    """ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í¬ë§·íŒ…"""
    formatted_string = ""
    for i, (question, answer) in enumerate(zip(questions, answers), start=1):
        formatted_string += f"Question {i}: {question}\nAnswer {i}: {answer}\n\n"
    return formatted_string.strip()

context = format_qa_pairs(questions, answers)

# ìµœì¢… RAG í”„ë¡¬í”„íŠ¸
template = """Here is a set of Q+A pairs:

{context}

Use these to synthesize an answer to the question: {question}
"""

prompt = ChatPromptTemplate.from_template(template)

final_rag_chain = (
    prompt
    | llm
    | StrOutputParser()
)

final_rag_chain.invoke({"context":context,"question":question})
```

**ë‹µë³€:** ê´€ì ì´ ë‹¤ë¥´ê²Œ ë‹µí•˜ì§€ë§Œ ì „ ì´ì „ ë²„ì „ì˜ ëŒ€ë‹µì´ ì¢€ ë” ì œ ì·¨í–¥ì¸ê±¸ë¡œğŸ˜

```
Question: 'What are the main components of an LLM-powered autonomous agent system?'

Answer:
An LLM-powered autonomous agent system is composed of several key components that work together to enable the agent's functionality. These include:

1. Hardware Components: The primary hardware components consist of the large language model (LLM) itself, memory storage for managing historical data and interactions, and processing units capable of handling the intensive computational demands required for planning and task decomposition.
2. Software Frameworks: Essential software frameworks for building such a system include AutoGPT, GPT-Engineer, and BabyAGI. These frameworks are proof-of-concept demos that illustrate how LLMs can serve as the core controller of autonomous agents, handling tasks such as planning, task decomposition, and self-reflection to continually improve their performance.
3. Natural Language Processing (NLP) Modules: NLP modules act as the interface between the LLM and other external components like memory and tools. They enable the agent to parse and understand model outputs, which is crucial for effective task decomposition, planning, and interaction with other system components. However, managing the reliability of these outputs is critical, as errors can impact the agent's performance.

Together, these hardware and software components form a cohesive system that supports the complex functionalities required for an autonomous agent to operate effectively.
```

**ìš”ì•½**

* **Decomposition** ë°©ì‹ì€ ë³µì¡í•œ ì§ˆë¬¸ì„ ì—¬ëŸ¬ í•˜ìœ„ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ ê°ê°ì„ ë…ë¦½ì ìœ¼ë¡œ í•´ê²°í•œ í›„, ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
* ì´ ê³¼ì •ì—ì„œ ì´ì „ ì§ˆë¬¸ì˜ ë‹µë³€ì„ ë‹¤ìŒ ì§ˆë¬¸ì— í™œìš©í•˜ì—¬ **ì ì§„ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°**í•˜ëŠ” ë°©ì‹ì´ í•µì‹¬ì…ë‹ˆë‹¤.
* ì´ë¥¼ í†µí•´ ë³µì¡í•œ ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í•˜ê³ , **ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒ**ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

### Part 8 (ë‹¨ê³„ì  í›„í‡´)

* ì´ ê°•ì˜ëŠ” RAG(Retrieval-Augmented Generation) íŒŒì´í”„ë¼ì¸ì˜ "Query Translation(ì¿¼ë¦¬ ë³€í™˜)" ì¤‘ ë„¤ ë²ˆì§¸ ë°©ë²•ì¸ **Step Back(ìŠ¤í…ë°±) í”„ë¡¬í”„íŒ…**ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.
* Step Back ê¸°ë²•ì€ ì§ˆë¬¸ì„ ë” **ì¶”ìƒì ì¸ ìˆ˜ì¤€ìœ¼ë¡œ ë³€í™˜**í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

**ë¬¸ì œ ì •ì˜ ë° ì ‘ê·¼ ë°©ë²•**

* ì´ì „ ê¸°ë²•ë“¤ì¸ **Multi-query**ì™€ **RAG Fusion**ì€ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ì—ì„œ ë‹¤ì‹œ ì“°ê±°ë‚˜, ì§ˆë¬¸ì„ í•˜ìœ„ ë¬¸ì œë¡œ ë¶„í•´í•˜ì—¬ ê°ê°ì„ í•´ê²°í•˜ëŠ” ë°©ë²•ì— ì¤‘ì ì„ ë‘ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ **Step Back** ë°©ì‹ì€ ì§ˆë¬¸ì„ **ë” ì¶”ìƒì ì¸ ì§ˆë¬¸**ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê³ ì°¨ì›ì ì¸ ê°œë…ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤.
* ë…¼ë¬¸ "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models"ì—ì„œëŠ” ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ê¸°ë²•ì¸ Step-Back Promptingì„ ì œì•ˆí•©ë‹ˆë‹¤.
  + `ì¶”ìƒí™”ë¥¼ í†µí•œ ì¶”ë¡  ê°œì„ `: Step-Back Promptingì€ ëª¨ë¸ì´ ë¬¸ì œë¥¼ ì§ì ‘ í•´ê²°í•˜ê¸° ì „ì—, ë¨¼ì € ë¬¸ì œë¥¼ í•œ ë‹¨ê³„ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„œ ì¶”ìƒí™”ëœ ê³ ìˆ˜ì¤€ ê°œë…ì´ë‚˜ ì›ë¦¬ë¥¼ ë„ì¶œí•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¶”ìƒí™” ë‹¨ê³„ëŠ” ëª¨ë¸ì´ ë³µì¡í•œ ë¬¸ì œì—ì„œ ì„¸ë¶€ì ì¸ ì˜¤ë¥˜ë¥¼ ì¤„ì´ê³  ë” ë†’ì€ ì •í™•ë„ë¡œ ì¶”ë¡ í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
  + `ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì˜ ì ìš©`: ì´ ê¸°ë²•ì€ ë¬¼ë¦¬í•™, í™”í•™, ì‹œê°„ ì§€ì‹ ì§ˆë¬¸(TimeQA), ë‹¤ë‹¨ê³„ ì¶”ë¡ (Multi-Hop Reasoning) ë“± ë‹¤ì–‘í•œ ì‘ì—…ì— ì ìš© ê°€ëŠ¥í•˜ë©°, ì´ë¥¼ í†µí•´ í•™ìŠµëœ ì›ë¦¬ë¥¼ ë‹¤ì–‘í•œ ìƒí™©ì— ì‘ìš©í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
  + `ì„±ëŠ¥ ë¹„êµ`: Step-Back Promptingì€ ë‹¤ë¥¸ ê¸°ë²•ë“¤, íŠ¹íˆ Chain-of-Thought(CoT)ë‚˜ Take-a-Deep-Breath(TDB) í”„ë¡¬í”„íŠ¸ì™€ ë¹„êµí•˜ì—¬, ì¶”ë¡  ì‘ì—…ì—ì„œ ì¼ê´€ë˜ê²Œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/4aa3d9e3-ebfd-49b1-9db9-4c9845a24dc4/image.png)

* Figure 2ëŠ” ë‘ ê°€ì§€ ì‘ì—…(ë¬¼ë¦¬í•™ ë¬¸ì œì™€ ì‹œê°„ ê¸°ë°˜ ì§ˆë¬¸)ì— ëŒ€í•´ Step-Back Promptingì„ ì–´ë–»ê²Œ ì ìš©í•˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê°ê°ì˜ ì˜ˆì‹œì—ì„œ ëª¨ë¸ì€ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ "Step-Back" ì§ˆë¬¸ì„ ìƒì„±í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤.

  1. ë¬¼ë¦¬í•™ ë¬¸ì œ (MMLU ë¬¼ë¦¬í•™ ì˜ˆì‹œ)

     **ë¬¸ì œ**: "ì´ìƒ ê¸°ì²´ì˜ ì••ë ¥ PëŠ” ì˜¨ë„ê°€ 2ë°°ë¡œ ì¦ê°€í•˜ê³  ë¶€í”¼ê°€ 8ë°°ë¡œ ì¦ê°€í•˜ë©´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ê°€?"

     + **ì›ë˜ ì ‘ê·¼ ë°©ì‹**: ëª¨ë¸ì´ ì²˜ìŒì— ë¬¸ì œë¥¼ ì§ê´€ì ìœ¼ë¡œ í’€ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ Chain-of-Thought(CoT) ë°©ì‹ìœ¼ë¡œ ì¤‘ê°„ ë‹¨ê³„ì—ì„œ ëª‡ ê°€ì§€ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
     + **Step-Back Promptingì˜ ì ìš©**: Step-Back Promptingì€ ë¨¼ì € "**â‘  ì´ ë¬¸ì œì˜ ê¸°ë³¸ ë¬¼ë¦¬ ë²•ì¹™ì€ ë¬´ì—‡ì¸ê°€?**"ë¼ëŠ” ì¶”ìƒì ì¸ ì§ˆë¬¸ì„ í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
       - ì´ ì§ˆë¬¸ì„ í†µí•´ ëª¨ë¸ì€ **â‘¡ ì´ìƒ ê¸°ì²´ ë²•ì¹™ (Ideal gas law, PV=nRT)ì„ íšŒìƒ**í•˜ê²Œ ë˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê³¼ì •ì„ ì´ì–´ê°‘ë‹ˆë‹¤.
         1. **ì¶”ìƒí™” ë‹¨ê³„**: "ì´ìƒ ê¸°ì²´ ë²•ì¹™"ì´ë¼ëŠ” ë¬¼ë¦¬í•™ì˜ ê¸°ë³¸ ì›ë¦¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
         2. **ì¶”ë¡  ë‹¨ê³„**: ì´ìƒ ê¸°ì²´ ë²•ì¹™ì„ ì ìš©í•˜ì—¬, ì˜¨ë„ì™€ ë¶€í”¼ ë³€í™”ì— ë”°ë¥¸ ì••ë ¥ ë³€í™”ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì••ë ¥ì€ 16ë¶„ì˜ 1ë¡œ ì¤„ì–´ë“­ë‹ˆë‹¤.

     ì´ ê³¼ì •ì—ì„œ Step-Back Promptingì„ í†µí•´ ëª¨ë¸ì€ ì„¸ë¶€ì ì¸ ê³„ì‚°ì—ì„œ ì˜¤ë¥˜ë¥¼ í”¼í•˜ê³ , ì¶”ìƒì ì¸ ì›ë¦¬ë¡œë¶€í„° ì˜¬ë°”ë¥¸ ë‹µì„ ë„ì¶œí•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.
  2. ì‹œê°„ ê¸°ë°˜ ì§ˆë¬¸ (TimeQA ì˜ˆì‹œ)

     **ë¬¸ì œ**: "Estella LeopoldëŠ” 1954ë…„ 8ì›”ì—ì„œ 11ì›” ì‚¬ì´ì— ì–´ëŠ í•™êµì— ë‹¤ë…”ëŠ”ê°€?"

     + **ì›ë˜ ì ‘ê·¼ ë°©ì‹**: ëª¨ë¸ì€ ì£¼ì–´ì§„ íŠ¹ì • ì‹œê°„ ë²”ìœ„ ë‚´ì—ì„œ Estella Leopoldì˜ êµìœ¡ ê¸°ë¡ì„ ë°”ë¡œ ì°¾ìœ¼ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤. CoT ë°©ì‹ìœ¼ë¡œ ì¤‘ê°„ ë‹¨ê³„ì—ì„œ ì‹œê°„ ë²”ìœ„ ì œí•œìœ¼ë¡œ ì¸í•´ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
     + **Step-Back Promptingì˜ ì ìš©**: Step-Back Promptingì€ ë¨¼ì € "Estella Leopoldì˜ êµìœ¡ ê¸°ë¡ì€ ë¬´ì—‡ì¸ê°€?"ë¼ëŠ” ë³´ë‹¤ ì¶”ìƒì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ ê·¸ë…€ì˜ ì „ë°˜ì ì¸ êµìœ¡ ê¸°ë¡ì„ íšŒìƒí•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¹ì • ì‹œê°„ ë²”ìœ„ì— ëŒ€í•œ ì •ë‹µì„ ì¶”ë¡ í•©ë‹ˆë‹¤.
       1. **ì¶”ìƒí™” ë‹¨ê³„**: "Estella Leopoldì˜ ì „ë°˜ì ì¸ êµìœ¡ ì´ë ¥"ì´ë¼ëŠ” ê³ ìˆ˜ì¤€ ê°œë…ì„ ë„ì¶œí•©ë‹ˆë‹¤.
       2. **ì¶”ë¡  ë‹¨ê³„**: ì´ ì¶”ìƒí™”ëœ êµìœ¡ ì´ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ, 1954ë…„ 8ì›”ë¶€í„° 11ì›”ê¹Œì§€ ê·¸ë…€ê°€ Yale Universityì—ì„œ ë°•ì‚¬ ê³¼ì •ì„ ë°Ÿê³  ìˆì—ˆë‹¤ëŠ” ê²°ë¡ ì„ ë„ì¶œí•©ë‹ˆë‹¤.

     ì´ ì˜ˆì‹œì—ì„œ Step-Back Promptingì€ ì„¸ë¶€ì ì¸ ì‹œê°„ ì œí•œì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì˜¤ë¥˜ë¥¼ í”¼í•˜ê³ , ë³´ë‹¤ ë„“ì€ ê´€ì ì—ì„œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.

**Step Back ê¸°ë²•ì˜ ì§ê´€**

* Step Back ë°©ì‹ì—ì„œëŠ” **ê¸°ì¡´ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë” ì¶”ìƒì ì¸ ì§ˆë¬¸**ì„ ìƒì„±í•˜ì—¬, ë‘ ê°€ì§€ ì§ˆë¬¸(ì›ë˜ ì§ˆë¬¸ê³¼ ì¶”ìƒí™”ëœ ì§ˆë¬¸)ì„ ë™ì‹œì— ê²€ìƒ‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ë„ì¶œí•©ë‹ˆë‹¤.
* ì´ëŠ” íŠ¹íˆ **ê°œë…ì ì¸ ì§€ì‹**ì„ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰í•´ì•¼ í•˜ëŠ” ë„ë©”ì¸ì—ì„œ ìœ ìš©í•˜ë©°, ë¬¸ì„œì˜ ë‚´ìš©ì´ íŠ¹ì • ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì§ì ‘ ì œê³µí•˜ì§€ ì•Šì„ ê²½ìš° ë” ì¼ë°˜ì ì¸ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ ë³´ì™„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì½”ë“œ ì‹œì—°**

**1. Few-shot ì˜ˆì‹œ ìƒì„±**

```
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate

# fewshot
examples = [
    {
        "input": "Could the members of The Police perform lawful arrests?",
        "output": "What can the members of The Police do?",
    },
    {
        "input": "Jan Sindelâ€™s was born in what country?",
        "output": "What is Jan Sindelâ€™s personal history?",
    },
]

example_prompt = ChatPromptTemplate.from_messages(
    [
        ("human", "{input}"),
        ("ai", "{output}"),
    ]
)

few_shot_prompt = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt,
    examples=examples,
)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. 
            Here are a few examples:
            """,
        ),
        few_shot_prompt,
        ("user", "{question}"),
    ]
)

generate_queries_step_back = prompt | ChatOpenAI(temperature=0) | StrOutputParser()
```

* Step Back í”„ë¡¬í”„íŒ…ì„ ìœ„í•œ ì˜ˆì‹œ(few-shot examples)ë¥¼ ì œê³µí•˜ì—¬, ëª¨ë¸ì´ ì›ë˜ ì§ˆë¬¸ì„ ì–´ë–»ê²Œ ì¶”ìƒì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜í• ì§€ í•™ìŠµì‹œí‚µë‹ˆë‹¤.
* ì›ë˜ ì§ˆë¬¸(original question)ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ìƒì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” í”„ë¡¬í”„íŠ¸(\*ë…¼ë¬¸ ì‚¬ìš© í”„ë¡¬í”„íŠ¸)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/2226c176-e7d1-499e-99a6-308351d68144/image.png)

**2. Step Back ì§ˆë¬¸ ìƒì„± ë° ê²€ìƒ‰ & ë‹µë³€ ìƒì„±**

```
question = "What is task decomposition for LLM agents?"
generate_queries_step_back.invoke({"question": question})
```

* "What is task decomposition for LLM agents?"ë¼ëŠ” questionì˜ step-back questionìœ¼ë¡œ ë‹¤ìŒ ë‹µë³€ì´ ë‚˜ì˜´.
  + `'How do LLM agents handle complex tasks?'`
  + ì´ ì§ˆë¬¸ì„ í†µí•´ LLM ì—ì´ì „íŠ¸ê°€ ë³µì¡í•œ ì‘ì—…ì„ í•´ê²°í•˜ëŠ” ì „ë°˜ì ì¸ ì „ëµì´ë‚˜ ë°©ì‹ì„ ë¬»ê³ , **êµ¬ì²´ì ì¸ ì„¸ë¶€ ì‚¬í•­ë³´ë‹¤ëŠ” ê³ ìˆ˜ì¤€ì˜ ê°œë…ì„ ì´í•´í•˜ë ¤ëŠ” ëª©ì **ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.
  + ì´ ë°©ì‹ìœ¼ë¡œ Step-Back ì§ˆë¬¸ì„ ì ìš©í•˜ë©´ ì„¸ë¶€ì ì¸ ì‘ì—… ë¶„í•´(task decomposition)ì˜ êµ¬ì²´ì ì¸ ë°©ë²•ë³´ë‹¤ëŠ”, ì „ì²´ì ì¸ ì‘ì—… ì²˜ë¦¬ ë°©ì‹ì— ëŒ€í•œ ë‹µë³€ì„ ë„ì¶œí•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.

```
response_prompt_template = """
You are an expert of world knowledge. I am going to ask you a question. 
Your response should be comprehensive and not contradicted with the following context if they are relevant. 
Otherwise, ignore them if they are not relevant.

# {normal_context}
# {step_back_context}

# Original Question: {question}
# Answer:
"""

response_prompt = ChatPromptTemplate.from_template(response_prompt_template)

chain = (
    {
        # ì›ë˜ ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰
        "normal_context": RunnableLambda(lambda x: x["question"]) | retriever,
        # Step Back ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰
        "step_back_context": generate_queries_step_back | retriever,
        "question": lambda x: x["question"],
    }
    | response_prompt
    | ChatOpenAI(temperature=0)
    | StrOutputParser()
)

chain.invoke({"question": question})
```

* ì›ë˜ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ **ì¶”ìƒì ì¸ ì§ˆë¬¸**ì„ ìƒì„±í•œ í›„, ê·¸ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
* ì›ë˜ ì§ˆë¬¸ê³¼ Step Back ì§ˆë¬¸ì„ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ê°ê°ì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•©ì¹˜ê³ , ìµœì¢… ë‹µë³€ì„ ë„ì¶œí•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

**ìš”ì•½**

* **Step Back(ìŠ¤í…ë°±)** ë°©ì‹ì€ ì›ë˜ ì§ˆë¬¸ì„ **ë” ì¶”ìƒì ì¸ ìˆ˜ì¤€**ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
* ì´ ê¸°ë²•ì€ ì›ë˜ ì§ˆë¬¸ì´ ë„ˆë¬´ êµ¬ì²´ì ì¼ ë•Œ, ë” ì¼ë°˜ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ì—¬ **ë” ë„“ì€ ë²”ìœ„ì˜ ì •ë³´ë¥¼ ê²€ìƒ‰**í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ **ìµœì¢… ë‹µë³€ì„ ìƒì„±**í•©ë‹ˆë‹¤.
* íŠ¹íˆ, ê°œë…ì ì¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ì´ í•„ìš”í•œ ë„ë©”ì¸ì—ì„œ ìœ ìš©í•˜ë©°, **ë¬¸ì„œì˜ êµ¬ì¡°ê°€ ê°œë…ì  ë‚´ìš©ê³¼ êµ¬ì²´ì  ë‚´ìš©ìœ¼ë¡œ ë‚˜ë‰˜ëŠ” ê²½ìš°** íš¨ê³¼ì ì…ë‹ˆë‹¤.

---

### Part 9 (HyDE)

* ì´ ê°•ì˜ëŠ” RAG(Retrieval-Augmented Generation) íŒŒì´í”„ë¼ì¸ì˜ "Query Translation(ì¿¼ë¦¬ ë³€í™˜)" ì¤‘ ë‹¤ì„¯ ë²ˆì§¸ ë°©ë²•ì¸ **HyDE (Hypothetical Document Embeddings)**ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/836ba89a-f58f-4bab-9318-a29e60ca0e62/image.png)

* í•´ë‹¹ ë…¼ë¬¸ì€ â€œPrecise Zero-Shot Dense Retrieval without Relevance Labelsâ€ë¼ëŠ” ì œëª©ì„ ê°€ì§„ ë…¼ë¬¸ìœ¼ë¡œ, í•µì‹¬ì ìœ¼ë¡œ **Hypothetical Document Embeddings (HyDE)** ê¸°ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.
  + **HyDE**ëŠ” **ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ "ê°€ìƒ ë¬¸ì„œ(Hypothetical Document)"ë¥¼ ìƒì„±í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•**ì…ë‹ˆë‹¤. ì´ ê°€ìƒ ë¬¸ì„œëŠ” ì‹¤ì œë¡œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¬¸ì„œë¡œ, í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸(ì˜ˆ: InstructGPT)ì„ í†µí•´ ìƒì„±ë©ë‹ˆë‹¤.
* HyDEì˜ ì£¼ìš” ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
  1. `ê°€ìƒ ë¬¸ì„œ ìƒì„±`: ì¿¼ë¦¬ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì–¸ì–´ ëª¨ë¸ì´ í•´ë‹¹ ì¿¼ë¦¬ì— ë‹µë³€í•˜ëŠ” ê°€ìƒì˜ ë¬¸ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ì´ ê°€ìƒ ë¬¸ì„œëŠ” ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë‚´ìš©ì„ ë‹´ê³  ìˆì§€ë§Œ, ì‚¬ì‹¤ì´ ì•„ë‹ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
  2. `ë¬¸ì„œ ì„ë² ë”©`: ê°€ìƒ ë¬¸ì„œëŠ” ëŒ€ì¡° í•™ìŠµì„ ê±°ì¹œ ì¸ì½”ë”(ì˜ˆ: Contriever)ë¥¼ í†µí•´ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤. ì´ ì„ë² ë”© ë²¡í„°ëŠ” ê°€ìƒ ë¬¸ì„œì—ì„œ ë¶ˆí•„ìš”í•œ ì„¸ë¶€ ì‚¬í•­ì„ ê±¸ëŸ¬ë‚´ê³ , ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ì‹¤ì œ ë¬¸ì„œë“¤ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.
  3. `ë¬¸ì„œ ê²€ìƒ‰`: ìµœì¢…ì ìœ¼ë¡œ, ì„ë² ë”© ë²¡í„°ë¥¼ ì´ìš©í•´ ì½”í¼ìŠ¤ ë‚´ì˜ ì‹¤ì œ ë¬¸ì„œë“¤ê³¼ì˜ ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê³ , ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

**ë¬¸ì œ ì •ì˜ ë° ì ‘ê·¼ ë°©ë²•**

* RAGì˜ ê¸°ë³¸ íë¦„ì—ì„œëŠ” ì§ˆë¬¸ê³¼ ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ì—¬ **ì„ë² ë”© ê³µê°„ì—ì„œì˜ ìœ ì‚¬ì„±**ì„ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
  + í•˜ì§€ë§Œ ì§ˆë¬¸ê³¼ ë¬¸ì„œëŠ” ë§¤ìš° ë‹¤ë¥¸ ìœ í˜•ì˜ í…ìŠ¤íŠ¸ ê°ì²´ì…ë‹ˆë‹¤.
    - Why â‡’ ? ë¬¸ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ê¸¸ê³  ë°€ë„ê°€ ë†’ì€ ì •ë³´ë¡œ êµ¬ì„±ëœ ë°˜ë©´, ì§ˆë¬¸ì€ ì§§ê³  ì‚¬ìš©ìì— ì˜í•´ ë¹„êµ¬ì¡°ì ìœ¼ë¡œ ì‘ì„±ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **HyDE**ì˜ í•µì‹¬ ì•„ì´ë””ì–´ëŠ” **ì§ˆë¬¸ì„ ê°€ìƒì˜ ë¬¸ì„œë¡œ ë³€í™˜í•˜ì—¬ ë¬¸ì„œ ì„ë² ë”© ê³µê°„ì— ë§¤í•‘**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. (ì•„ë˜ ê·¸ë¦¼ ì°¸ê³ )

![](https://velog.velcdn.com/images/euisuk-chung/post/bb292396-1cc6-4c76-a120-b01ecd37a665/image.png)

* ì¦‰, ê¸°ì¡´ì²˜ëŸ¼ ì§ˆë¬¸ì„ ë°”ë¡œ ì„ë°°ë”©ì„ ì‹œì¼œì„œ ê²€ìƒ‰í•˜ëŠ” ëŒ€ì‹ , **ê°€ìƒì˜ ë¬¸ì„œ**ë¥¼ ìƒì„±í•˜ì—¬ ê²€ìƒ‰ì— í™œìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
  + ì´ ë°©ë²•ì„ í†µí•´ ì§ˆë¬¸ì˜ ì„ë² ë”©ì´ ë¶€ì¡±í•  ìˆ˜ ìˆëŠ” ê²½ìš°ì—ë„ ê°€ìƒì˜ ë¬¸ì„œê°€ **ë” ìœ ì‚¬í•œ ì‹¤ì œ ë¬¸ì„œ**ì™€ ì˜ ì¼ì¹˜í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
  + **ì™œ ê°€ìƒì˜ ë¬¸ì„œê°€ ì§ˆë¬¸ë³´ë‹¤ ë” ì›ë³¸ ë¬¸ì„œì™€ ê°€ê¹Œì›Œì§ˆ ìˆ˜ ìˆëŠ”ê°€**?
    - ê°€ìƒì˜ ë¬¸ì„œëŠ” ì›ë˜ ì§ˆë¬¸ë³´ë‹¤ ë” ë§ì€ ì •ë³´ì™€ ë§¥ë½ì„ í¬í•¨í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ê´€ë ¨ëœ ì‹¤ì œ ë¬¸ì„œì™€ ë” ê°€ê¹Œìš´ ë²¡í„° ê³µê°„ì— ìœ„ì¹˜í•˜ê²Œ ë©ë‹ˆë‹¤.
    - ì´ëŠ” ê°€ìƒ ë¬¸ì„œê°€ ì§ˆë¬¸ì—ì„œ ë¶€ì¡±í•œ ë¶€ë¶„ì„ ë³´ì™„í•˜ê³ , ì–¸ì–´ ëª¨ë¸ì˜ í•™ìŠµëœ íŒ¨í„´ì„ í™œìš©í•´ ë” í’ë¶€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ìƒì„±í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
    - ì´ë¡œ ì¸í•´ ê°€ìƒ ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì›ë˜ ì§ˆë¬¸ì„ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ë‚˜ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.

**ì½”ë“œ ì‹œì—°**

**1. HyDEë¥¼ ìœ„í•œ ë¬¸ì„œ ìƒì„± í”„ë¡¬í”„íŠ¸ ì •ì˜ ë° ìƒì„±**

```
from langchain.prompts import ChatPromptTemplate

template = """
Please write a scientific paper passage to answer the question
Question: {question}
Passage:
"""

prompt_hyde = ChatPromptTemplate.from_template(template)

from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

generate_docs_for_retrieval = (
    prompt_hyde | ChatOpenAI(temperature=0) | StrOutputParser()
)

# ì˜ˆì‹œ ì§ˆë¬¸
question = "What is task decomposition for LLM agents?"

generate_docs_for_retrieval.invoke({"question":question})
```

* ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ **ê°€ìƒì˜ ê³¼í•™ì  ë¬¸ì„œ**ë¥¼ ìƒì„±í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
* ì›ë˜ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ìƒì˜ ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì—„ì²­ ê·¸ëŸ´ ë“¯í•˜ê²Œ ë…¼ë¬¸ êµ¬ì¡°ë¡œ ì‘ì„±ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
Title: Task Decomposition for Large Language Model (LLM) Agents

Abstract:
Task decomposition for Large Language Model (LLM) agents refers to the systematic process of breaking down complex tasks into smaller, more manageable subtasks, which can be sequentially or concurrently addressed by the model. This methodology aims to enhance the efficiency, accuracy, and overall performance of LLMs when faced with multifaceted queries or tasks. This passage explores the principles, methodologies, and implications of task decomposition in the context of LLM agents.

Introduction:
Large Language Models (LLMs), such as GPT-4, have demonstrated remarkable capabilities in natural language understanding, generation, and various other language-related tasks. However, their performance can be significantly improved through the strategic application of task decomposition. By dividing a complex task into discrete, manageable components, LLM agents can process information more effectively, reduce cognitive load, and minimize errors.

Principles of Task Decomposition:
Task decomposition is grounded in several key principles:

1. Modularity: Breaking down a task into independent or semi-independent modules allows for parallel processing and simplifies error identification and correction.
2. Hierarchy: Establishing a hierarchical structure where higher-level tasks are decomposed into lower-level subtasks ensures a coherent and organized approach to problem-solving.
3. Sequential Dependency: Understanding the dependencies between subtasks enables the LLM to process them in the correct order, ensuring that intermediate results are correctly utilized in subsequent steps.

Methodologies:
There are various methodologies for task decomposition, each tailored to specific types of tasks and LLM capabilities:

1. Top-Down Decomposition: This approach begins with the overarching task and progressively breaks it down into smaller subtasks. For example, answering a complex question might involve identifying key concepts, gathering relevant information, synthesizing data, and constructing a coherent response.
2. Bottom-Up Decomposition: Conversely, this method starts with identifying fundamental subtasks and gradually combines them to form a solution to the larger task. This can be useful in tasks where the basic components are well understood, but their integration is complex.
3. Hybrid Decomposition: Combining top-down and bottom-up approaches can provide a balanced strategy, leveraging the strengths of both methods to handle diverse tasks effectively.

Implications for LLM Performance:
The adoption of task decomposition has several implications for the performance of LLM agents:

1. Enhanced Accuracy: By focusing on smaller, more manageable subtasks, LLMs can provide more precise and accurate responses, reducing the likelihood of errors that may occur when tackling complex tasks holistically.
2. Improved Efficiency: Decomposing tasks allows for parallel processing, which can significantly speed up task completion and optimize resource utilization.
3. Scalability: Task decomposition facilitates the scaling of LLM applications to handle increasingly complex and diverse tasks, making them more versatile and robust.

Conclusion:
Task decomposition is a vital strategy for optimizing the performance of LLM agents. By breaking down complex tasks into smaller, manageable components, LLMs can improve their accuracy, efficiency, and scalability. As LLM technology continues to evolve, the principles and methodologies of task decomposition will play an increasingly important role in harnessing the full potential of these powerful models.

Keywords: Task decomposition, Large Language Models, LLM agents, modularity, hierarchical structure, sequential dependency, top-down decomposition, bottom-up decomposition, hybrid decomposition.
```

**2. ìƒì„±ëœ ê°€ìƒ ë¬¸ì„œë¥¼ ì‚¬ìš©í•œ ë¬¸ì„œ ê²€ìƒ‰**

```
# ê²€ìƒ‰ ì²´ì¸
retrieval_chain = generate_docs_for_retrieval | retriever
retireved_docs = retrieval_chain.invoke({"question":question})
retireved_docs
```

* ìƒì„±ëœ ê°€ìƒì˜ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ë¬¸ì„œì™€ ê´€ë ¨ì´ ë†’ì€ ë¬¸ì„œë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/b0d0986c-3541-42e3-8782-d0da2eb24ad1/image.png)

**3. ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±**

```
# RAG í”„ë¡¬í”„íŠ¸
template = """Answer the following question based on this context:

{context}

Question: {question}
"""

prompt = ChatPromptTemplate.from_template(template)

final_rag_chain = (
    prompt
    | llm
    | StrOutputParser()
)

# ìµœì¢… RAG ì²´ì¸ ì‹¤í–‰
final_rag_chain.invoke({"context":retireved_docs,"question":question})
```

* ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì›ë˜ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/4a27b6d8-0bde-4986-a779-e0fa6eaccbdb/image.png)

**ìš”ì•½**

* HyDE(Hypothetical Document Embeddings)ëŠ” ì§ˆë¬¸ì„ **ê°€ìƒì˜ ë¬¸ì„œ**ë¡œ ë³€í™˜í•œ í›„, í•´ë‹¹ ë¬¸ì„œë¥¼ ì´ìš©í•´ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
* ì§ˆë¬¸ì´ ì§ì ‘ ê²€ìƒ‰ì— ì í•©í•˜ì§€ ì•Šì„ ë•Œ, **ê°€ìƒì˜ ë¬¸ì„œ**ê°€ ë¬¸ì„œ ì„ë² ë”© ê³µê°„ì—ì„œ ë” ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ì´ ë°©ì‹ì€ íŠ¹íˆ ì§ˆë¬¸ì´ ì§§ê±°ë‚˜ êµ¬ì¡°ê°€ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°ì— ìœ ìš©í•˜ë©°, **ë„ë©”ì¸ì— ë§ê²Œ ê°€ìƒ ë¬¸ì„œ ìƒì„± í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •**í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.

---