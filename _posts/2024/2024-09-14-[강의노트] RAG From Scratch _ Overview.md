---
title: "[ê°•ì˜ë…¸íŠ¸] RAG From Scratch : Overview"
date: "2024-09-14"
tags:
  - "rag"
  - "ê°•ì˜ë…¸íŠ¸"
year: "2024"
---

# [ê°•ì˜ë…¸íŠ¸] RAG From Scratch : Overview

* í•´ë‹¹ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ëŠ” [RAG From Scratch : Coursework](https://velog.io/@euisuk-chung/LLM-RAG-From-Scratch) ê°•ì˜ íŒŒíŠ¸ 1 - 4 ë‚´ìš©ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.

| **ë¹„ë””ì˜¤** | **ìš”ì•½** | **ê°•ì˜ ë§í¬** | **ìŠ¬ë¼ì´ë“œ** |
| --- | --- | --- | --- |
| **Part 1 (ê°œìš”)** | RAGë¥¼ ì†Œê°œí•˜ë©°, ì‹œë¦¬ì¦ˆê°€ ê¸°ë³¸ ê°œë…ë¶€í„° ê³ ê¸‰ ê¸°ìˆ ê¹Œì§€ ë‹¤ë£° ê²ƒì„ì„ ì„¤ëª…í•©ë‹ˆë‹¤. | ğŸ“Œ [ê°•ì˜](https://www.youtube.com/watch?v=wd7TZ4w1mSw&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=1&pp=iAQB) | ğŸ“– [ìŠ¬ë¼ì´ë“œ](https://docs.google.com/presentation/d/1C9IaAwHoWcc4RSTqo-pCoN3h0nCgqV2JEYZUJunv_9Q/edit?usp=sharing) |
| **Part 2 (ì¸ë±ì‹±)** | ê²€ìƒ‰ì˜ ì •í™•ì„±ê³¼ ì†ë„ì— ì¤‘ìš”í•œ ì¸ë±ì‹± ê³¼ì •ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤. | ğŸ“Œ [ê°•ì˜](https://www.youtube.com/watch?v=bjb_EMsTDKI&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=2&pp=iAQB) | ğŸ“– [ìŠ¬ë¼ì´ë“œ](https://docs.google.com/presentation/d/1MhsCqZs7wTX6P19TFnA9qRSlxH3u-1-0gWkhBiDG9lQ/edit?usp=sharing) |
| **Part 3 (ê²€ìƒ‰)** | ê²€ìƒ‰ì˜ ì •ë°€ì„±ì„ ìœ„í•´ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•œ ë¬¸ì„œ ê²€ìƒ‰ì„ ë‹¤ë£¹ë‹ˆë‹¤. | ğŸ“Œ [ê°•ì˜](https://www.youtube.com/watch?v=LxNVgdIz9sU&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=3&pp=iAQB) | ğŸ“– [ìŠ¬ë¼ì´ë“œ](https://docs.google.com/presentation/d/124I8jlBRCbb0LAUhdmDwbn4nREqxSxZU1RF_eTGXUGc/edit?usp=sharing) |
| **Part 4 (ìƒì„±)** | LLMì„ í†µí•œ ë‹µë³€ ìƒì„±ì„ ìœ„í•œ RAG í”„ë¡¬í”„íŠ¸ êµ¬ì„±ì„ íƒêµ¬í•©ë‹ˆë‹¤. | ğŸ“Œ [ê°•ì˜](https://www.youtube.com/watch?v=JChPi0CRnDY&list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x&index=4&pp=iAQB) | ğŸ“– [ìŠ¬ë¼ì´ë“œ](https://docs.google.com/presentation/d/1eRJwzbdSv71e9Ou9yeqziZrz1UagwX8B1kL4TbL5_Gc/edit?usp=sharing) |

### Part 1 (ê°œìš”)

* **RAGì˜ ê¸°ë³¸ ê°œë… ì†Œê°œ**:
  + ì´ ë¹„ë””ì˜¤ ì‹œë¦¬ì¦ˆëŠ” RAG(Retrieval-Augmented Generation)ì˜ ê¸°ë³¸ ì›ì¹™ì„ ë‹¤ë£¨ê³ , ê³ ê¸‰ ì£¼ì œê¹Œì§€ í™•ì¥í•´ ë‚˜ê°€ëŠ” ê³¼ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
  + RAGì˜ ì£¼ìš” ë™ê¸°ëŠ” **ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)**ì´ ëª¨ë“  ë°ì´í„°ë¥¼ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, **ê°œì¸ ë°ì´í„°**ë‚˜ **ìµœê·¼ ë°ì´í„°**ëŠ” LLMì˜ ì‚¬ì „ í•™ìŠµì— í¬í•¨ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.![](https://velog.velcdn.com/images/euisuk-chung/post/49d9e3d7-bbb3-416f-938b-657ad9f04fe5/image.png)
  + ë˜í•œ, LLMì€ **ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°**(context windows)ë¼ëŠ” ì œí•œì´ ìˆìŠµë‹ˆë‹¤. ìµœê·¼ì—ëŠ” ì´ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ê°€ ì ì  ë” ì»¤ì§€ê³  ìˆì§€ë§Œ, ì—¬ì „íˆ ì™¸ë¶€ ì†ŒìŠ¤ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì—°ê²°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.![](https://velog.velcdn.com/images/euisuk-chung/post/0e5737e6-872d-421d-b835-fc6b4c343fb1/image.png)
* **RAGì˜ ì„¸ ê°€ì§€ ì£¼ìš” ë‹¨ê³„**:
  + **ì¸ë±ì‹±(Indexing)**: ì™¸ë¶€ ë¬¸ì„œë¥¼ ì¸ë±ì‹±í•˜ì—¬ ì…ë ¥ ì¿¼ë¦¬ì— ë”°ë¼ ì‰½ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
  + **ê²€ìƒ‰(Retrieval)**: ì§ˆë¬¸ì— ëŒ€í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ ë¬¸ì„œë¥¼ LLMì— ì…ë ¥í•©ë‹ˆë‹¤.
  + **ìƒì„±(Generation)**: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/34a5cf38-7e40-4884-878f-e6b81b6e3350/image.png)

**ì½”ë“œ ì‹œì—°**

**1. Install Packages**

* í•„ìˆ˜ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```
pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain bs4
```

* ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤:

```
import bs4
from langchain import hub
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import Chroma
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
```

* API KEY ë° ì£¼ìš” í™˜ê²½ ë³€ìˆ˜ë¥¼ ì…‹íŒ…í•´ì¤ë‹ˆë‹¤:

```
# OPEN_AI CHATGPT KEY ì„¤ì •
os.environ['OPENAI_API_KEY'] = <your-api-key>
```

```
# langsmithìš© í‚¤ ì„¤ì •
# <https://docs.smith.langchain.com/>
import os
os.environ['LANGCHAIN_TRACING_V2'] = 'true'
os.environ['LANGCHAIN_ENDPOINT'] = '<https://api.smith.langchain.com>'
os.environ['LANGCHAIN_API_KEY'] = <your-api-key>
```

> **(ì°¸ê³ ) LangSmith API Key ë°œê¸‰ ë°©ë²•**
>
> * ë§í¬ : <https://smith.langchain.com/>
> * ìœ„ ë§í¬ì—ì„œ Personal > Setting > Creating API Keyì—ì„œ ë°œê¸‰ ê°€ëŠ¥  
>   ![](https://velog.velcdn.com/images/euisuk-chung/post/3d1f08b6-c007-47a7-b1ae-6aea64205f93/image.png)

> **ğŸ’¡ LangChain & LangSmith?**
>
> * `LangChain`ê³¼ `LangSmith`ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê°œë°œì„ ì§€ì›í•˜ëŠ” ë‘ ê°€ì§€ ê°•ë ¥í•œ ë„êµ¬ë¡œ, ê°ê°ì˜ ëª©ì ê³¼ ì‚¬ìš© ì‚¬ë¡€ê°€ ë‹¤ë¦…ë‹ˆë‹¤. - ì´ ë‘ ë„êµ¬ë¥¼ ì˜ ì´í•´í•˜ëŠ” ê²ƒì€ LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê°œë°œí•˜ê³  ìš´ì˜í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.

> **LangChain â›“ï¸**
>
> * **LangChain**ì€ ì£¼ë¡œ LLMì„ í™œìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹ ì†í•˜ê²Œ ê°œë°œí•˜ê³  í”„ë¡œí† íƒ€ì…ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. Pythonìœ¼ë¡œ ì œê³µë˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ íŒ¨í‚¤ì§€ë¡œ, ë‹¤ì–‘í•œ LLMì„ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ì–¸ì–´ ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LangChainì€ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:
>   + **ì²´ì¸ê³¼ ì—ì´ì „íŠ¸**: LangChainì€ ì—¬ëŸ¬ ì‘ì—…ì„ ì²´ì¸(Chain) í˜•íƒœë¡œ ì—°ê²°í•˜ê±°ë‚˜, ë³µì¡í•œ ì˜ì‚¬ ê²°ì • ê³¼ì •ì„ ì—ì´ì „íŠ¸(Agent)ë¡œ êµ¬í˜„í•˜ì—¬ ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>   + **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**: íŠ¹ì • ì‘ì—…ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‰½ê²Œ ì •ì˜í•˜ê³  í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>   + **ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ**: ì‘ì—…ì˜ ìƒíƒœë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> **LangSmith âš’ï¸**
>
> * **LangSmith**ëŠ” LangChain ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê°œë°œ, í…ŒìŠ¤íŠ¸, ëª¨ë‹ˆí„°ë§, ê·¸ë¦¬ê³  ë°°í¬ë¥¼ ìœ„í•œ ì¢…í•©ì ì¸ DevOps í”Œë«í¼ì…ë‹ˆë‹¤. ì´ëŠ” ëŒ€ê·œëª¨ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê´€ë¦¬í•˜ê³  ìµœì í™”í•˜ëŠ” ë° í•„ìš”í•œ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, íŠ¹íˆ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì´ ë‹ë³´ì…ë‹ˆë‹¤:
>   + **ë””ë²„ê¹…**: ëª¨ë¸ì˜ ëª¨ë“  ë‹¨ê³„ì—ì„œ ì…ë ¥ê³¼ ì¶œë ¥ì„ ì¶”ì í•  ìˆ˜ ìˆì–´, ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼ë‚˜ ì˜¤ë¥˜ë¥¼ ì‰½ê²Œ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>   + **í…ŒìŠ¤íŠ¸**: ìƒˆë¡œìš´ ì²´ì¸ê³¼ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‹¤í—˜í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì œê³µí•˜ì—¬, ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>   + **ëª¨ë‹ˆí„°ë§**: ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì§€ì—° ì‹œê°„ê³¼ í† í° ì‚¬ìš©ëŸ‰ì„ ì¶”ì í•˜ì—¬ ë¬¸ì œë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆëŠ” í˜¸ì¶œì„ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>   + **í‰ê°€**: ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ ì²´ì¸ì„ í‰ê°€í•˜ê³ , ì„±ëŠ¥ì„ ìµœì í™”í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
>   + **í”„ë¡œì íŠ¸ ë¶„ì„**: ì‹¤í–‰ ì¹´ìš´íŠ¸, ì˜¤ë¥˜ ë°œìƒë¥ , í† í° ì‚¬ìš©ëŸ‰ ë“±ì„ í”„ë¡œì íŠ¸ ë‹¨ìœ„ë¡œ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> **(ì°¸ê³ ) Langfuse ğŸ§¬**
>
> * **Langfuse**ëŠ” LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸) ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ ê´€ì¸¡ì„± ë° ë¶„ì„ í”Œë«í¼ìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
>   + **ê´€ì¸¡ì„±**: ë³µì¡í•œ LLM ì•± ì‹¤í–‰ì„ ì‹œê°ì  UIë¥¼ í†µí•´ íƒìƒ‰í•˜ê³  ë””ë²„ê¹…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŒ€ê¸° ì‹œê°„, ë¹„ìš©, ì„±ëŠ¥ ì ìˆ˜ ë“±ì˜ ìƒì„¸ ì •ë³´ë¥¼ í¬í•¨í•œ ì¤‘ì²©ëœ ë·°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
>   + **ë¶„ì„**: ë¹„ìš©, ì§€ì—° ì‹œê°„, ì‘ë‹µ í’ˆì§ˆì„ ì¸¡ì •í•˜ê³  ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ë³„ í† í° ì‚¬ìš©ëŸ‰, í‰ê°€ ì ìˆ˜ ë“±ì„ ë¦¬í¬íŠ¸ë¡œ ì œê³µí•©ë‹ˆë‹¤.
>   + **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬**: Langfuse ë‚´ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ê´€ë¦¬, ë²„ì „ ê´€ë¦¬, ë°°í¬í•  ìˆ˜ ìˆì–´ íš¨ìœ¨ì ì¸ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
>   + **í‰ê°€**: LLM ì™„ì„±ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ìˆ˜ì§‘í•˜ê³  ê³„ì‚°í•©ë‹ˆë‹¤. ëª¨ë¸ ê¸°ë°˜ í‰ê°€, ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘, ìˆ˜ë™ ì ìˆ˜ ë§¤ê¸°ê¸° ë“± ë‹¤ì–‘í•œ í‰ê°€ ë°©ë²•ì„ ì§€ì›í•©ë‹ˆë‹¤.
>   + **ì‹¤í—˜ ë° í…ŒìŠ¤íŠ¸**: ìƒˆ ë²„ì „ì„ ë°°í¬í•˜ê¸° ì „ì— ì•± ë™ì‘ì„ ì¶”ì í•˜ê³  í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆìƒ ì…ì¶œë ¥ ìŒì„ í…ŒìŠ¤íŠ¸í•˜ê³  ì„±ëŠ¥ì„ ë²¤ì¹˜ë§ˆí¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>   + **í†µí•©**: LlamaIndex, Langchain ë“± ì£¼ìš” LLM í”„ë ˆì„ì›Œí¬ì™€ì˜ í†µí•©ì„ ì œê³µí•˜ì—¬ ë‹¤ì–‘í•œ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**2. Indexing**

* ì´ì œ í•„ìš”í•œ í™˜ê²½ ì„¤ì •ì€ ë‹¤í–ˆìœ¼ë‹ˆ, Indexing ì½”ë“œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

```
#### INDEXING ####

# Load Documents
loader = WebBaseLoader(
    web_paths=("<https://velog.io/@euisuk-chung/ê¿€íŒ-Velog-ê¸€ì”¨ë¥¼-ë‚´-ë§ˆìŒëŒ€ë¡œ-ìƒ‰ìƒ-í˜•ê´‘íœ>",),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")
        )
    ),
)

docs = loader.load()

# Split
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)

# Embed
vectorstore = Chroma.from_documents(documents=splits,
                                    embedding=OpenAIEmbeddings())

retriever = vectorstore.as_retriever()
```

* ìœ„ ì½”ë“œì—ì„œ `Chroma`ëŠ” vectorstoreì˜ í•œ ì¢…ë¥˜ë¡œ, LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” êµ¬í˜„ì²´ì…ë‹ˆë‹¤.
* **Vectorstore**ë¥¼ ì‚¬ìš©í•˜ë©´ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œ íš¨ìœ¨ì ì¸ ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì–´, ìì—°ì–´ ì²˜ë¦¬ë‚˜ ê¸°ê³„í•™ìŠµ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ë„ë¦¬ í™œìš©ë©ë‹ˆë‹¤.

  + Chroma, Pinecone, Faiss ë“± ë‹¤ì–‘í•œ êµ¬í˜„ì²´ê°€ ìˆìŠµë‹ˆë‹¤.
* ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

  + ê³ ì°¨ì› ë²¡í„° ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
  + í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“±ì˜ ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
  + ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ë¹ ë¥´ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆì–´ ì¶”ì²œ ì‹œìŠ¤í…œ, ì´ë¯¸ì§€ ê²€ìƒ‰ ë“±ì— í™œìš©ë©ë‹ˆë‹¤.

**3. Retreive and Generate**

* Indexingì´ ëë‚œ ë’¤, **ê²€ìƒ‰ê¸°(retriever)**ë¥¼ ì •ì˜í•˜ê³ , ê²€ìƒ‰ëœ ë¬¸ì„œì™€ í•¨ê»˜ ì§ˆë¬¸ì„ LLMì— ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ **ìƒì„±(generate)**í•©ë‹ˆë‹¤.

```
#### RETRIEVAL and GENERATION ####
# Prompt
prompt = hub.pull("rlm/rag-prompt")

# LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

# Post-processing
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# Chain
rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
# Question
rag_chain.invoke("What is Task Decomposition?")


## Answer Returned
'Task Decomposition is a technique used to break down complex tasks into smaller, more manageable steps.
It involves methods like Chain of Thought (CoT) and Tree of Thoughts, which guide models to think step by step and explore multiple reasoning possibilities.
This approach enhances model performance by simplifying and structuring tasks systematically.'
```

* **langsmith** íˆ´ì„ ì‚¬ìš©í•˜ë©´ ì‚¬ì´íŠ¸ > í”„ë¡œì íŠ¸ë¡œ ì ‘ì†í•˜ì—¬ ì•„ë˜ì™€ ê°™ì´ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œ, ê·¸ë¦¬ê³  ìƒì„±ëœ ë‹µë³€ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/bd88afb8-274b-4c44-8b0e-fcd05eb28488/image.png)

---

### Part 2 (ì¸ë±ì‹±)

* ì´ë²ˆ ì˜ìƒì€ RAG(Retrieval-Augmented Generation) íŒŒì´í”„ë¼ì¸ì˜ ë‘ ë²ˆì§¸ íŒŒíŠ¸ë¡œ, 'ì¸ë±ì‹±(Indexing)'ì— ëŒ€í•´ ë‹¤ë£¹ë‹ˆë‹¤.
* ì´ì „ ì˜ìƒì—ì„œëŠ” RAG íŒŒì´í”„ë¼ì¸ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œ(ì¸ë±ì‹±, ê²€ìƒ‰, ìƒì„±)ì— ëŒ€í•´ ê°œê´„ì ìœ¼ë¡œ ì„¤ëª…í–ˆìœ¼ë©°, ì´ë²ˆ ì˜ìƒì—ì„œëŠ” ê·¸ ì¤‘ ì¸ë±ì‹±ì— ëŒ€í•´ ì‹¬ë„ ìˆê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.
* **ì¸ë±ì‹±ì˜ ì—­í• **: ì¸ë±ì‹±ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” ì™¸ë¶€ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì´ë¥¼ 'ë¦¬íŠ¸ë¦¬ë²„(Retriever)'ì— ë„£ëŠ” ê²ƒì…ë‹ˆë‹¤.

  + **ë¦¬íŠ¸ë¦¬ë²„(Retriever)**ì˜ ëª©í‘œëŠ” ì…ë ¥ëœ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ë‚´ëŠ” ê²ƒì…ë‹ˆë‹¤.  
    ![](https://velog.velcdn.com/images/euisuk-chung/post/a6a67430-00a0-4b30-aa27-64e5138df98b/image.png)

    âœï¸ ì‚¬ì „ì  ì˜ë¯¸ë¡œ `retrieve`ë€ **"íšŒìˆ˜í•˜ë‹¤"ë¼ëŠ” ëœ»ìœ¼ë¡œ, \_"ìš°ë¦¬ê°€ ì§ˆë¬¸í•œ ì§ˆì˜ë¬¸ê³¼ ìœ ì‚¬í•œ ë‚´ìš©ì˜ ë¬¸ì„œë¥¼ ì €ì¥í•´ë‘” VectorDBì—ì„œ íšŒìˆ˜í•´ ì˜¨ë‹¤"**\_ë¼ê³  ì§ì—­í•´ë³¼ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/adce1590-22da-4c3b-9dfd-157fe1ad5a1e/image.png)

* ê´€ê³„(ìœ ì‚¬ì„±)ì„ í™•ë¦½í•˜ëŠ” ë°©ë²•ì€ ì£¼ë¡œ **ë¬¸ì„œì˜ ìˆ˜ì¹˜ì  í‘œí˜„(numerical representation)**ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ììœ  í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë³´ë‹¤ëŠ” ë²¡í„° ë¹„êµê°€ í›¨ì”¬ ì‰½ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.![](https://velog.velcdn.com/images/euisuk-chung/post/5757187c-6a4a-4466-9031-869e5ca93716/image.png)
  + **ë²¡í„° í‘œí˜„ ë°©ë²•**:  
    ![](https://velog.velcdn.com/images/euisuk-chung/post/ca6be400-4488-4178-974b-fce200428c9e/image.png)

    - **Sparse Vectors**: ê³¼ê±°ì—ëŠ” êµ¬ê¸€ ë“±ì—ì„œ ë¬¸ì„œì˜ ë‹¨ì–´ ë¹ˆë„ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” í¬ì†Œ ë²¡í„°(sparse vectors)ë¥¼ ìƒì„±í•˜ëŠ” í†µê³„ì  ë°©ë²•ì´ ë§ì´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë²¡í„°ì˜ ê° ìœ„ì¹˜ëŠ” í° ì–´íœ˜ ì§‘í•© ì¤‘ íŠ¹ì • ë‹¨ì–´ì˜ ë°œìƒ íšŸìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ë©°, ë¬¸ì„œì— í¬í•¨ë˜ì§€ ì•Šì€ ë‹¨ì–´ì˜ ê²½ìš° ê°’ì´ 0ì´ ë©ë‹ˆë‹¤.
    - **Embedding Methods**: ìµœê·¼ì—ëŠ” ë¬¸ì„œë¥¼ ê³ ì •ëœ ê¸¸ì´ì˜ ë²¡í„°ë¡œ ì••ì¶•í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì„ë² ë”©(embedding) ë°©ë²•ì´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ë¬¸ì„œì˜ ì˜ë¯¸ì  ë‚´ìš©ì„ ë²¡í„°ì— ì••ì¶•í•´ ë‹´ì•„ë‚´ë©°, ì´ëŸ¬í•œ ë²¡í„°ëŠ” ê²€ìƒ‰ì— ë§¤ìš° íš¨ê³¼ì ì…ë‹ˆë‹¤.
  + **ë¬¸ì„œ ë¶„í•  ë° ì„ë² ë”©**:  
    ![](https://velog.velcdn.com/images/euisuk-chung/post/48aec6af-d410-4bd1-9156-9a48ba6410b9/image.png)

    - ë¬¸ì„œëŠ” ì„ë² ë”© ëª¨ë¸ì˜ ì œí•œëœ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°(512~8000 í† í°) ë•Œë¬¸ì— ë¶„í• ë©ë‹ˆë‹¤. ê° ë¬¸ì„œ ì¡°ê°ì€ ë²¡í„°ë¡œ ì••ì¶•ë˜ë©°, ì´ ë²¡í„°ëŠ” ë¬¸ì„œì˜ ì˜ë¯¸ì  ì˜ë¯¸ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.
    - ì§ˆë¬¸ë„ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì„ë² ë”©ë˜ë©°, ì´ë ‡ê²Œ ìƒì„±ëœ ë²¡í„°ë“¤ì„ ë¹„êµí•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê²Œ ë©ë‹ˆë‹¤.

**ì½”ë“œ ì‹œì—°**

**1. `tiktoken` íŒ¨í‚¤ì§€ì™€ í† í° ê°œìˆ˜ ê³„ì‚°**

```
import tiktoken

def num_tokens_from_string(string: str, encoding_name: str) -> int:
    """Returns the number of tokens in a text string."""
    encoding = tiktoken.get_encoding(encoding_name)
    num_tokens = len(encoding.encode(string))
    return num_tokens

num_tokens_from_string(question, "cl100k_base")
```

**ì„¤ëª…:**

* `tiktoken` íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ìì—´ì˜ í† í° ê°œìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ "í† í°"ì€ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•˜ëŠ” ì‘ì€ ë‹¨ìœ„ë¡œ, ì¼ë°˜ì ìœ¼ë¡œ ë‹¨ì–´ ë˜ëŠ” ë‹¨ì–´ì˜ ì¼ë¶€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
* `num_tokens_from_string` í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ë¬¸ìì—´ê³¼ ì¸ì½”ë”© ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ë¬¸ìì—´ì˜ í† í° ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
* `tiktoken.get_encoding(encoding_name)`ì€ ì§€ì •ëœ ì¸ì½”ë”© ë°©ì‹ì„ ë¶ˆëŸ¬ì˜¤ê³ , `encoding.encode(string)`ì€ ë¬¸ìì—´ì„ í† í°ìœ¼ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤.
* ë§ˆì§€ë§‰ìœ¼ë¡œ `len(encoding.encode(string))`ì€ ì¸ì½”ë”©ëœ í† í° ë¦¬ìŠ¤íŠ¸ì˜ ê¸¸ì´(í† í° ê°œìˆ˜)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

> tiktoken íŒ¨í‚¤ì§€ ì„¤ëª…:
>
> * `tiktoken`ì€ ì£¼ë¡œ OpenAIì˜ ëª¨ë¸ë“¤(ì˜ˆ: GPT-3.5, GPT-4 ë“±)ì—ì„œ ì‚¬ìš©ë˜ëŠ” í† í°í™”(tokenization) ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ì´ íŒ¨í‚¤ì§€ëŠ” í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ì´ëŸ¬í•œ í† í°ì´ ëª¨ë¸ì— ì…ë ¥ë  ë•Œì˜ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ê° í† í°ì€ ì•½ 4ì ì •ë„ë¡œ êµ¬ì„±ëœ ë‹¨ìœ„ì´ë©°, ì´ëŠ” ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ë•Œì˜ ê¸°ë³¸ì ì¸ ë‹¨ìœ„ê°€ ë©ë‹ˆë‹¤.

**2. í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸**

```
from langchain_openai import OpenAIEmbeddings
embd = OpenAIEmbeddings()
query_result = embd.embed_query(question)
document_result = embd.embed_query(document)
len(query_result)
```

**ì„¤ëª…:**

* ì´ ì½”ë“œ ë¸”ë¡ì—ì„œëŠ” `langchain_openai` íŒ¨í‚¤ì§€ì˜ `OpenAIEmbeddings`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ë¬¸ì„œë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤.
* ì„ë² ë”©(embedding)ì´ë€ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ ë²¡í„°ë“¤ì€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë“¤ì´ ì„œë¡œ ê°€ê¹Œì´ ìœ„ì¹˜í•˜ë„ë¡ í•˜ì—¬, í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
* `embed_query` ë©”ì„œë“œëŠ” ì£¼ì–´ì§„ í…ìŠ¤íŠ¸(ì§ˆë¬¸ì´ë‚˜ ë¬¸ì„œ)ë¥¼ ì„ë² ë”©í•˜ì—¬ ë²¡í„° í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
* ê²°ê³¼ì ìœ¼ë¡œ `query_result`ì™€ `document_result`ëŠ” ê°ê° ì§ˆë¬¸ê³¼ ë¬¸ì„œì˜ ì„ë² ë”© ë²¡í„°ê°€ ë©ë‹ˆë‹¤.(printë¡œ ê¸¸ì´ ì¶œë ¥ ì‹œ ë™ì¼ ê¸¸ì´ì˜ ì„ë°°ë”© ë²¡í„°ê°€ ìƒì„±ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ)

![](https://velog.velcdn.com/images/euisuk-chung/post/43cd61e9-a852-4066-9a81-27f89f3c3cf5/image.png)

**3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°**

```
import numpy as np

def cosine_similarity(vec1, vec2):
    dot_product = np.dot(vec1, vec2)
    norm_vec1 = np.linalg.norm(vec1)
    norm_vec2 = np.linalg.norm(vec2)
    return dot_product / (norm_vec1 * norm_vec2)

similarity = cosine_similarity(query_result, document_result)
print("Cosine Similarity:", similarity)
```

**ì„¤ëª…:**

* ì´ ë¸”ë¡ì€ ë‘ ì„ë² ë”© ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
* ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ë‘ ë²¡í„° ì‚¬ì´ì˜ ê°ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ë©°, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‘ ë²¡í„°ê°€ ìœ ì‚¬í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
* `np.dot(vec1, vec2)`ëŠ” ë‘ ë²¡í„°ì˜ ë‚´ì ì„ ê³„ì‚°í•˜ê³ , `np.linalg.norm(vec1)`ì™€ `np.linalg.norm(vec2)`ëŠ” ê°ê°ì˜ ë²¡í„°ì˜ í¬ê¸°(ë…¸ë¦„)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
* ë§ˆì§€ë§‰ìœ¼ë¡œ `dot_product / (norm_vec1 * norm_vec2)`ëŠ” ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/5d47d4ec-dfdd-4e1d-ae96-925d0eb38c3a/image.png)

* ì œê°€ ì‚¬ìš©í•œ GPT ëª¨ë¸ì˜ ì„ë°°ë”© ê¸°ë°˜ì˜ Queryì™€, Documentì˜ ìœ ì‚¬ë„ëŠ” ê·¸ë ‡ê²Œ ë†’ì§„ ì•Šì§€ë§Œ, ì–´ëŠì •ë„ì˜ ìœ ì‚¬ì„±ì„ ë„ê³  ìˆê¸´í•˜ë„¤ìš”!

**4. ë¬¸ì„œ ë¡œë”**

```
from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader(
    web_paths=("<https://lilianweng.github.io/posts/2023-06-23-agent/>",),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")
        )
    ),
)

blog_docs = loader.load()
```

**ì„¤ëª…:**

* ì´ ë¸”ë¡ì—ì„œëŠ” `langchain_community`ì˜ `WebBaseLoader`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ ì›¹ í˜ì´ì§€ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
* `WebBaseLoader`ëŠ” ì›¹ í˜ì´ì§€ì˜ íŠ¹ì • HTML ìš”ì†Œë¥¼ ì¶”ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” `bs4.SoupStrainer`ë¥¼ ì‚¬ìš©í•˜ì—¬ `class_`ë¡œ ì§€ì •ëœ ìš”ì†Œë“¤ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
* `loader.load()`ëŠ” ë¡œë“œëœ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

**5. í…ìŠ¤íŠ¸ ë¶„í• ê¸°**

```
from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
    chunk_size=300,
    chunk_overlap=50
)

splits = text_splitter.split_documents(blog_docs)
```

**ì„¤ëª…:**

* ì´ ë¶€ë¶„ì€ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ë©ì–´ë¦¬ë¡œ ë¶„í• í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. `RecursiveCharacterTextSplitter`ëŠ” í…ìŠ¤íŠ¸ë¥¼ íŠ¹ì • í¬ê¸°ë¡œ ë‚˜ëˆ„ë˜, ë©ì–´ë¦¬ ê°„ì— ê²¹ì¹˜ëŠ” ë¶€ë¶„ë„ í¬í•¨ë˜ë„ë¡ í•©ë‹ˆë‹¤.
* `chunk_size=300`ì€ ê° ë©ì–´ë¦¬ì˜ ìµœëŒ€ í¬ê¸°ë¥¼ ì„¤ì •í•˜ë©°, `chunk_overlap=50`ì€ ë©ì–´ë¦¬ ê°„ì˜ ê²¹ì¹˜ëŠ” ë¶€ë¶„ì˜ í¬ê¸°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
* ìµœì¢…ì ìœ¼ë¡œ `split_documents` ë©”ì„œë“œë¥¼ í†µí•´ ë¬¸ì„œë¥¼ ë¶„í• í•©ë‹ˆë‹¤.

**6. ë²¡í„° ìŠ¤í† ì–´**

```
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

vectorstore = Chroma.from_documents(documents=splits,
                                    embedding=OpenAIEmbeddings())

# ê²€ìƒ‰ê¸° ìƒì„±
retriever = vectorstore.as_retriever()
```

**ì„¤ëª…:**

* ì´ ì½”ë“œì—ì„œëŠ” ë¶„í• ëœ ë¬¸ì„œ ë©ì–´ë¦¬ë“¤ì„ ë²¡í„° ìŠ¤í† ì–´ì— ì¸ë±ì‹±í•©ë‹ˆë‹¤. `Chroma`ëŠ” í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
* `Chroma.from_documents`ëŠ” ë¬¸ì„œì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•©ë‹ˆë‹¤.
* ë§ˆì§€ë§‰ìœ¼ë¡œ `vectorstore.as_retriever()`ë¥¼ í†µí•´ ì €ì¥ëœ ì„ë² ë”©ì—ì„œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ì´ ê°€ëŠ¥í•œ ê²€ìƒ‰ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

---

### Part 3 (ê²€ìƒ‰)

* ì´ ë¹„ë””ì˜¤ëŠ” LangChainì˜ Lanceê°€ ì§„í–‰í•˜ëŠ” "RAG From Scratch" ì‹œë¦¬ì¦ˆì˜ ì„¸ ë²ˆì§¸ ì˜ìƒìœ¼ë¡œ, ì´ë²ˆ ì£¼ì œëŠ” **ì •ë³´ ê²€ìƒ‰**(Retrieval)ì…ë‹ˆë‹¤.
* **ìƒ‰ì¸í™”ì˜ ê¸°ë³¸ ê°œë…**
  + ë¬¸ì„œë¥¼ ìƒ‰ì¸í™”í•˜ëŠ” ê³¼ì •ì€ ë¬¸ì„œë¥¼ **ì‘ì€ ì¡°ê°**(Chunks)ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ì´ë¥¼ **ì„ë² ë”©**(Embedding)í•˜ì—¬ **ë²¡í„°í™”**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
  + ì´ ë²¡í„°í™”ëœ ì„ë² ë”©ì€ ë¬¸ì„œì˜ **ì˜ë¯¸ì  ë‚´ìš©**ì— ë”°ë¼ ê³ ì°¨ì› ê³µê°„ì˜ í•œ ì ìœ¼ë¡œ í‘œí˜„ë©ë‹ˆë‹¤. ì´ ì ì˜ ìœ„ì¹˜ëŠ” ë¬¸ì„œì˜ ì˜ë¯¸ë¥¼ ë°˜ì˜í•˜ë©°, ì§ˆë¬¸ë„ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì„ë² ë”©ë˜ì–´ í•´ë‹¹ ê³µê°„ì—ì„œ ë¬¸ì„œì™€ì˜ ìœ ì‚¬ì„±ì„ ê²€ìƒ‰í•˜ê²Œ ë©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/9e572c2c-2324-4df2-ab5d-0b561de72654/image.png)

**ì½”ë“œ ì‹œì—°**

* ë¬¸ì„œê°€ ì„ë² ë”©ëœ ê³ ì°¨ì› ê³µê°„ì—ì„œ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ê³¼ì •ì€ **ë¡œì»¬ ë„¤ì´ë²„í›„ë“œ ê²€ìƒ‰**(Local Neighborhood Search)ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ì´ ê²€ìƒ‰ ê³¼ì •ì—ì„œ ì§ˆë¬¸ê³¼ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ìˆëŠ” ë¬¸ì„œë“¤ì„ ì°¾ì•„ë‚´ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
* ë¬¸ì„œ ê²€ìƒ‰ ì‹œ, ë°˜í™˜í•  ë¬¸ì„œì˜ ìˆ˜ë¥¼ ê²°ì •í•˜ëŠ” **K-ê°’**ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, K=1ë¡œ ì„¤ì •í•˜ë©´ ì§ˆë¬¸ê³¼ ê°€ì¥ ê°€ê¹Œìš´ í•œ ê°œì˜ ë¬¸ì„œë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.

  ```
  # Index
  from langchain_openai import OpenAIEmbeddings
  from langchain_community.vectorstores import Chroma

  # ì•ì—ì„œ ë³¸ ê²ƒì²˜ëŸ¼ vectorstore ì„ ì–¸
  vectorstore = Chroma.from_documents(documents=splits,
                                      embedding=OpenAIEmbeddings())

  retriever = vectorstore.as_retriever(search_kwargs={"k": 1})
  docs = retriever.get_relevant_documents("What is Task Decomposition?")

  len(docs) # 1ì´ ë°˜í™˜ë¨
  ```

![](https://velog.velcdn.com/images/euisuk-chung/post/9f47da0e-f61a-4b02-b5fb-760efff009ef/image.png)

---

### Part 4 (ìƒì„±)

* í•´ë‹¹ ì˜ìƒì—ì„œëŠ” ë¬¸ì„œ ê²€ìƒ‰ì„ í†µí•´ ì–»ì€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ `LLM(Large Language Model)ì„ í™œìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê³¼ì •`ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/04a7e3ff-fa8f-43b8-97d5-7f7a761cf660/image.png)

**(ë³µìŠµ) ë¬¸ì„œ ì‚½ì…ê³¼ LLM ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°**

* ë¬¸ì„œ ê²€ìƒ‰ í›„, ë¬¸ì„œë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë‚˜ëˆˆ ë’¤, ì´ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•©ë‹ˆë‹¤.
* ì§ˆë¬¸ë„ ë§ˆì°¬ê°€ì§€ë¡œ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ KNN(K-Nearest Neighbors)ê³¼ ê°™ì€ ê¸°ë²•ìœ¼ë¡œ ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ë¹„êµí•©ë‹ˆë‹¤.
* ê²€ìƒ‰ëœ ë¬¸ì„œëŠ” LLMì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ì— ì‚½ì…ë˜ì–´ ë‹µë³€ ìƒì„±ì— ì‚¬ìš©ë©ë‹ˆë‹¤.

ìœ„ì—ì„œ ë³´ì—¬ë“œë¦° ê·¸ë¦¼ì„ ì¢€ ë” ìì„¸í•˜ê²Œ ì‚´í´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤:

![](https://velog.velcdn.com/images/euisuk-chung/post/d1363a77-7d33-429f-b13a-8ac8ab80dc29/image.png)

1. **Documents â†’ Embedding â†’ Vectorstore**
   * **Documents**: ì´ ë¶€ë¶„ì€ ìš°ë¦¬ê°€ ì²˜ë¦¬í•˜ê³ ì í•˜ëŠ” ì›ë³¸ ë¬¸ì„œì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
   * **Embedding**: ë¬¸ì„œë¥¼ ì§ì ‘ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ê¸° ì–´ë ¤ìš°ë¯€ë¡œ, ì´ ë¬¸ì„œë“¤ì„ ì„ë² ë”©(embedding)í•˜ì—¬ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì„ë² ë”©ëœ ë²¡í„°ëŠ” ë¬¸ì„œì˜ ì˜ë¯¸ì  íŠ¹ì§•ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
   * **Vectorstore**: ë²¡í„°ë¡œ ë³€í™˜ëœ ë¬¸ì„œë“¤ì€ ë²¡í„° ìŠ¤í† ì–´(vectorstore)ì— ì €ì¥ë©ë‹ˆë‹¤. ë²¡í„° ìŠ¤í† ì–´ëŠ” ë‚˜ì¤‘ì— ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. (Ex. KNN, HNSW ê¸°ë²• ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.)
     + `HNSW(Hierarchical Navigable Small World)`: ê³ ì°¨ì› ë²¡í„° ë°ì´í„°ì˜ ê·¼ì‚¬ ìµœê·¼ì ‘ ì´ì›ƒ(Approximate Nearest Neighbor) ê²€ìƒ‰ì„ ìœ„í•œ íš¨ìœ¨ì ì¸ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.
2. **Question â†’ Embedding â†’ Vectorstore â†’ Relevant Documents**
   * **Question**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ë˜ì§€ë©´, ì´ ì§ˆë¬¸ë„ ë¬¸ì„œì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì„ë² ë”©ë©ë‹ˆë‹¤. ì¦‰, ì§ˆë¬¸ë„ ë²¡í„°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.
   * **Vectorstore â†’ Relevant Documents**: ë³€í™˜ëœ ì§ˆë¬¸ ë²¡í„°ëŠ” ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ë¬¸ì„œ ë²¡í„°ë“¤ê³¼ ë¹„êµë˜ì–´ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë“¤ì´ ê²€ìƒ‰ë©ë‹ˆë‹¤.
     + ì´ ë¬¸ì„œë“¤ì´ **Relevant Documents**ë¡œ í‘œì‹œë©ë‹ˆë‹¤. ì´ëŠ” ì§ˆë¬¸ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ë¬¸ì„œë“¤ì´ë©°, **LLMì˜ ì»¨í…ìŠ¤íŠ¸**ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
3. **Dict ìƒì„±**
   * ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì§ˆë¬¸ì€ **Dict**ë¼ëŠ” ìë£Œ êµ¬ì¡°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.
   * ì´ DictëŠ” ë‘ ê°€ì§€ í•„ë“œë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ë°:
     + **{Context}**: ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤.
     + **{Question}**: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤.
   * ì´ DictëŠ” **Prompt Template**ì— ë“¤ì–´ê°ˆ ë°ì´í„°ë¥¼ ì •ì˜í•˜ëŠ” ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.
4. **Prompt Template**
   * í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿(Prompt Template)ì€ LLM(Large Language Model)ì„ ì´ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ë•Œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.
     + LLMì€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë°›ì•„ë“¤ì´ëŠ” ë°©ì‹ì´ ë§¤ìš° ìœ ì—°í•˜ì§€ë§Œ, ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ëŒ€ë¡œ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ë ¤ë©´ ì¼ê´€ë˜ê³  êµ¬ì¡°í™”ëœ ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì—ê²Œ ì •ë³´ë¥¼ ì œê³µí•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì€ ë°”ë¡œ ì´ ê³¼ì •ì„ ë•ê¸° ìœ„í•œ ë„êµ¬ì…ë‹ˆë‹¤.
   * í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì€ **í…ìŠ¤íŠ¸ ìƒì„± ê³¼ì •ì„ ì‰½ê²Œ ë°˜ë³µ ê°€ëŠ¥**í•˜ê²Œ í•˜ê³ , **ê°ê¸° ë‹¤ë¥¸ ì…ë ¥ì— ë”°ë¼ ë³€í˜•í•  ìˆ˜ ìˆëŠ” ì¼ì¢…ì˜ í…œí”Œë¦¿ì„ ì œê³µ**í•©ë‹ˆë‹¤.
     + ë¬¸ì„œì™€ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì‘ì—…ì„ í•  ë•Œ, ëª¨ë¸ì— ë™ì¼í•œ êµ¬ì¡°ë¡œ ì •ë³´(ë¬¸ì„œì™€ ì§ˆë¬¸)ë¥¼ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
     + í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì€ ë¬¸ì„œë¥¼ {context}ì—, ì§ˆë¬¸ì„ {question}ì— ì‚½ì…í•¨ìœ¼ë¡œì¨ ì´ êµ¬ì¡°ë¥¼ ìœ ì§€í•´ ì¤ë‹ˆë‹¤.

       ```
         # ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ í…œí”Œë ›
         Answer the question based only on the following context:
        {context}

        Question:
        {question}
       ```
     + ì´ì œ, ì‹¤ì œ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì±„ì›Œ ë„£ëŠ” ìˆœê°„, Prompt Valueë¼ëŠ” ìµœì¢… í”„ë¡¬í”„íŠ¸ê°€ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤. ì´ í”„ë¡¬í”„íŠ¸ëŠ” í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë˜ì–´ LLMì— ì „ë‹¬í•  ì¤€ë¹„ê°€ ëœ ìƒíƒœì…ë‹ˆë‹¤.
     + ì˜ˆë¥¼ ë“¤ì–´, í…œí”Œë¦¿ì— ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì§ˆë¬¸ì´ ì‚½ì…ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ ë³€í™˜ë©ë‹ˆë‹¤.

       ```
          Answer the question based only on the following context:
          "Document 1 content here. Document 2 content here..."

          Question:
          "What is Task Decomposition?"
       ```

> Q. ì•„ë‹ˆ ê·¸ëƒ¥ dictë¡œ ì£¼ë©´ ë˜ì§€ ì•Šë‚˜? ì™œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì§€?  
> A. ì´ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ì€ ì¥ì ì´ ìˆìŠµë‹ˆë‹¤:
>
> * **ìë™í™”**: ì—¬ëŸ¬ ê°œì˜ ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë™ì¼í•œ í˜•ì‹ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> * **ì¬ì‚¬ìš©ì„±**: ê°™ì€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë‹¤ì–‘í•œ ì…ë ¥ ë°ì´í„°ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> * **ì¼ê´€ì„±**: ì¼ì •í•œ í˜•ì‹ìœ¼ë¡œ LLMì— ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ì—¬, ë” ì¼ê´€ëœ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>
> 1. **LLM (Large Language Model)**
>    * **Prompt Value**ê°€ LLMì— ì „ë‹¬ë©ë‹ˆë‹¤. LLMì€ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°(Context Window)ë¥¼ ì‚¬ìš©í•´ ì „ë‹¬ëœ ë¬¸ì„œì™€ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
> 2. **Parser**
>    * LLMì—ì„œ ìƒì„±ëœ ë‹µë³€ì€ **Parser**ë¥¼ í†µí•´ ì²˜ë¦¬ë©ë‹ˆë‹¤. ParserëŠ” LLMì—ì„œ ìƒì„±ëœ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì ì ˆíˆ íŒŒì‹±í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ **Answer**ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

**ì½”ë“œ ì‹œì—°**

* ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³ , ì´ë¥¼ ë¶„í• í•œ í›„, ì„ë² ë”©ì„ ì ìš©í•˜ì—¬ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•˜ëŠ” ì‘ì—…ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
* ìƒì„± ë¶€ë¶„ì—ì„œëŠ” ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë§Œë“¤ì–´, ë¬¸ë§¥(context)ê³¼ ì§ˆë¬¸(question)ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
* LangChainì—ì„œ ì œê³µí•˜ëŠ” `LangChain Expression Language`ë¥¼ í™œìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸, LLM, íŒŒì„œ(parser), ê·¸ë¦¬ê³  ë¦¬íŠ¸ë¦¬ë²„(retriever)ë¥¼ ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**(1) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ LLMì— ë“¤ì–´ê°€ëŠ” ê³¼ì •**

* ì•„ë˜ ì½”ë“œë¥¼ í†µí•´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ LLMì— ì „ë‹¬ë˜ê³ , ê·¸ ê²°ê³¼ë¡œ ë‹µë³€ì´ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  ```
  from langchain_openai import ChatOpenAI
  from langchain.prompts import ChatPromptTemplate

  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
  template = """Answer the question based only on the following context:
  {context}

  Question:
  {question}
  """

  # í…œí”Œë¦¿ì„ ChatPromptTemplate ê°ì²´ë¡œ ë³€í™˜
  prompt = ChatPromptTemplate.from_template(template)

  # LLM ìƒì„±
  llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

  # ì²´ì¸(chain) ìƒì„±: í”„ë¡¬í”„íŠ¸ì™€ LLM ì—°ê²°
  chain = prompt | llm

  # ì‹¤í–‰: ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì„ í…œí”Œë¦¿ì— ì‚½ì…í•˜ì—¬ ë‹µë³€ ìƒì„±
  # ì•ì—ì„œ ì„ ì–¸í•´ë‘” docsì™€ Questionì„ Invokeí•˜ëŠ” í˜•íƒœ
  chain.invoke({"context": docs, "question": "What is Task Decomposition?"})
  ```

  + **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜**: ë¨¼ì € í…œí”Œë¦¿ ë¬¸ìì—´ì„ ì •ì˜í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ {context}ëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì‚½ì…ë˜ëŠ” ìë¦¬ì´ê³ , {question}ì€ ì§ˆë¬¸ì´ ì‚½ì…ë˜ëŠ” ìë¦¬ì…ë‹ˆë‹¤. ì´ í…œí”Œë¦¿ì€ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° í•„ìš”í•œ ëª¨ë“  ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
  + **í…œí”Œë¦¿ì„ ê°ì²´ë¡œ ë³€í™˜**: ChatPromptTemplate.from\_template() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ ë¬¸ìì—´ í˜•íƒœì˜ í…œí”Œë¦¿ì„ ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ ê°ì²´ëŠ” ë‚˜ì¤‘ì— ë°ì´í„°ê°€ ì‚½ì…ë  ìˆ˜ ìˆëŠ” ì¤€ë¹„ëœ í…œí”Œë¦¿ì…ë‹ˆë‹¤.
  + **LLM ì •ì˜**: ChatOpenAI í´ë˜ìŠ¤ì—ì„œ gpt-3.5-turboë¼ëŠ” ëª¨ë¸ì„ ì„ íƒí•˜ì—¬ LLMì„ ì •ì˜í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ temperature=0ì€ ëª¨ë¸ì´ ë”ìš± ì¼ê´€ëœ(ì¦‰, ëœ ëœë¤í•œ) ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ì„¤ì •í•œ ê²ƒì…ë‹ˆë‹¤.
  + **í”„ë¡¬í”„íŠ¸ì™€ LLM ì—°ê²°(Chain)**: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ LLMì„ ì—°ê²°í•˜ì—¬ ì²´ì¸ì„ ë§Œë“­ë‹ˆë‹¤. ì´ ì²´ì¸ì€ í”„ë¡¬í”„íŠ¸ì— ë°ì´í„°ë¥¼ ì‚½ì…í•˜ê³ , LLMì„ í˜¸ì¶œí•´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ í•˜ë‚˜ì˜ íë¦„ìœ¼ë¡œ ë¬¶ìŠµë‹ˆë‹¤.
  + **ì‹¤í–‰**: chain.invoke() ë©”ì„œë“œë¥¼ í†µí•´ {context}ì—ëŠ” ë¬¸ì„œ(docs)ê°€, {question}ì—ëŠ” ì§ˆë¬¸ì´ ì‚½ì…ëœ í”„ë¡¬í”„íŠ¸ê°€ LLMì— ì „ë‹¬ë©ë‹ˆë‹¤. ëª¨ë¸ì€ ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

**(2) LangChainê³¼ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**

* LangChainì—ì„œëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë³´ë‹¤ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
* ì˜ˆë¥¼ ë“¤ì–´, í…œí”Œë¦¿ê³¼ LLM, ê·¸ë¦¬ê³  íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ê³ , ì´ë¥¼ í†µí•´ ê²€ìƒ‰ ê¸°ë°˜ ë‹µë³€ ìƒì„±(RAG)ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  ```
  from langchain import hub
  from langchain_core.output_parsers import StrOutputParser
  from langchain_core.runnables import RunnablePassthrough

  prompt_hub_rag = hub.pull("rlm/rag-prompt")

  # RAG ì²´ì¸ ìƒì„±
  rag_chain = (
      {"context": retriever, "question": RunnablePassthrough()}
      | prompt_hub_rag # í˜¸ì¶œí•œ template ì‚¬ìš©
      | llm
      | StrOutputParser()
  )

  # ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
  rag_chain.invoke("What is Task Decomposition?")
  ```
* ì œëŒ€ë¡œ ê²°ê³¼ê°€ ì¶œë ¥ë˜ê³ , ì‹¤í–‰ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

![](https://velog.velcdn.com/images/euisuk-chung/post/b9643753-70f3-41f3-a38f-d0c1f781c2ef/image.png)

![](https://velog.velcdn.com/images/euisuk-chung/post/b3893438-0961-4d28-9828-affb8be755b9/image.png)

---