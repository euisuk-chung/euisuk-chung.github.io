---
title: "[ê°•ì˜ë…¸íŠ¸] LangChain Academy : Introduction to LangGraph (Module 4)"
date: "2024-10-16"
tags:
  - "langgraph"
  - "ê°•ì˜ë…¸íŠ¸"
year: "2024"
---

# [ê°•ì˜ë…¸íŠ¸] LangChain Academy : Introduction to LangGraph (Module 4)

ì›ë³¸ ê²Œì‹œê¸€: https://velog.io/@euisuk-chung/LangChain-Academy-Introduction-to-LangGraph-Module-4



**ë­ì²´ì¸(LangChain)**ê³¼ **ë­ê·¸ë˜í”„(LangGraph)**ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ ë„êµ¬ë“¤ì…ë‹ˆë‹¤. ìœ„ ê°•ì˜ëŠ” LangChainì—ì„œ ìš´ì˜í•˜ëŠ” LangChain Academyì—ì„œ ì œì‘í•œ "Introduction to LangGraph" ê°•ì˜ì˜ ë‚´ìš©ì„ ì •ë¦¬ ë° ì¶”ê°€ ì„¤ëª…í•œ ë‚´ìš©ì…ë‹ˆë‹¤.

* ê°•ì˜ ë§í¬ : <https://youtu.be/29XE10U6ooc>
* ë­ì²´ì¸ : <https://www.langchain.com/>

  

ì´ë²ˆ í¬ìŠ¤íŠ¸ëŠ” **"Module4"**ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤:

* Lesson 1: Parallelization
* Lesson 2: Sub-graphs
* Lesson 3: Map-reduce
* Lesson 4: Research Assistant

  

---

Lesson 1: Parallelization
-------------------------

### ê°œìš”

* **ë³‘ë ¬í™”(Parallelization)**ëŠ” ì‘ì—…ì„ ì—¬ëŸ¬ ê°œì˜ ë…¸ë“œë¡œ ë‚˜ëˆ„ì–´ ë™ì‹œì— ì²˜ë¦¬í•˜ì—¬ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
  + ê·¸ëŸ¬ë‚˜ ë³‘ë ¬ë¡œ ì‹¤í–‰ëœ ë…¸ë“œë“¤ì´ ë™ì¼í•œ ìƒíƒœ í‚¤ë¥¼ ì—…ë°ì´íŠ¸í•  ë•Œ ìƒíƒœ ì¶©ëŒì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **ë¦¬ë“€ì„œ(Reducer)**ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ì•ˆì „í•˜ê²Œ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì£¼ìš” ê°œë…

1. **ë³‘ë ¬í™” ê°œë…**

* `íŒ¬ì•„ì›ƒ(fan-out)`: **í•œ ë…¸ë“œ**ì—ì„œ **ì—¬ëŸ¬ ë…¸ë“œë¡œ ì‘ì—…ì´ í™•ì¥**ë˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.
  + ì˜ˆë¥¼ ë“¤ì–´, ë…¸ë“œ Aì—ì„œ Bì™€ Cë¥¼ ë™ì‹œì— ì‹¤í–‰í•˜ëŠ” ê²ƒì„ `íŒ¬ì•„ì›ƒ`ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* `íŒ¬ì¸(fan-in)`: **ì—¬ëŸ¬ ë³‘ë ¬ ì‘ì—…ì´ ëª¨ë‘ ì™„ë£Œ**ëœ í›„ **í•˜ë‚˜ì˜ ë…¸ë“œë¡œ ë‹¤ì‹œ í•©ì³ì§€ëŠ” ê³¼ì •**ì…ë‹ˆë‹¤.
  + ì˜ˆë¥¼ ë“¤ì–´, Bì™€ Cì˜ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ D ë…¸ë“œë¡œ í•©ì³ì§€ëŠ” ê²ƒì´ `íŒ¬ì¸`ì…ë‹ˆë‹¤.

2. **ë³‘ë ¬ ë…¸ë“œ ì‹¤í–‰**:
   
   * ì‘ì—…ì„ ì—¬ëŸ¬ ë…¸ë“œë¡œ ë¶„ë°°í•˜ì—¬ ë™ì‹œì— ì‹¤í–‰í•˜ëŠ” ì‘ì—…ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
   * ì—¬ëŸ¬ ë…¸ë“œê°€ ë™ì‹œì— ì‹¤í–‰ë  ë•Œ **ìƒíƒœë¥¼ ì•ˆì „í•˜ê²Œ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•œ ì¡°ì¹˜ê°€ í•„ìš”**í•©ë‹ˆë‹¤.
3. **ë¦¬ë“€ì„œ(Reducer)**:
   
   * ë³‘ë ¬ë¡œ ì‹¤í–‰ëœ ë…¸ë“œê°€ **ë™ì¼í•œ ìƒíƒœ í‚¤ë¥¼ ì—…ë°ì´íŠ¸**í•  ë•Œ ì´ë¥¼ **ë³‘í•©**í•˜ëŠ” ì—­í• ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
   * ë³‘ë ¬ ë…¸ë“œê°€ ìƒíƒœ í‚¤ì— ì¶”ê°€í•˜ëŠ” ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³‘í•©í•˜ëŠ” ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### ì½”ë“œ ì˜ˆì‹œ

1. **ê¸°ë³¸ì ì¸ ë³‘ë ¬í™” ì²˜ë¦¬ ì˜ˆì‹œ**:
   * ê¸°ë³¸ì ìœ¼ë¡œ ì§ë ¬ ì‹¤í–‰ë˜ëŠ” ê·¸ë˜í”„ì—ì„œ A, B, C, D ìˆœì„œëŒ€ë¡œ ë…¸ë“œê°€ ì‹¤í–‰ë©ë‹ˆë‹¤.
   * ì•„ë˜ ê·¸ë˜í”„ëŠ” ê° ë‹¨ê³„ì—ì„œ ìƒíƒœë¥¼ ë®ì–´ì“°ëŠ” ê°„ë‹¨í•œ ì„ í˜• ê·¸ë˜í”„ì…ë‹ˆë‹¤.

```
from IPython.display import Image, display

from typing import Any
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END

class State(TypedDict):
    # operator.add ë¦¬ë“€ì„œ í•¨ìˆ˜ëŠ” ì´ê²ƒì„ ì¶”ê°€ ì „ìš©ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤
    state: str

class ReturnNodeValue:
    def __init__(self, node_secret: str):
        self._value = node_secret

    def __call__(self, state: State) -> Any:
        print(f"{self._value}ë¥¼ {state['state']}ì— ì¶”ê°€í•©ë‹ˆë‹¤")
        return {"state": [self._value]}

# ë…¸ë“œ ì¶”ê°€
builder = StateGraph(State)

# ê° ë…¸ë“œë¥¼ node_secretìœ¼ë¡œ ì´ˆê¸°í™” 
builder.add_node("a", ReturnNodeValue("ë‚˜ëŠ” Aì…ë‹ˆë‹¤"))
builder.add_node("b", ReturnNodeValue("ë‚˜ëŠ” Bì…ë‹ˆë‹¤"))
builder.add_node("c", ReturnNodeValue("ë‚˜ëŠ” Cì…ë‹ˆë‹¤"))
builder.add_node("d", ReturnNodeValue("ë‚˜ëŠ” Dì…ë‹ˆë‹¤"))

# íë¦„
builder.add_edge(START, "a")
builder.add_edge("a", "b")
builder.add_edge("b", "c")
builder.add_edge("c", "d")
builder.add_edge("d", END)
graph = builder.compile()

display(Image(graph.get_graph().draw_mermaid_png()))
```

![](https://velog.velcdn.com/images/euisuk-chung/post/0fe0c60b-4fb0-4992-ab43-35ab48312415/image.png)

2. **ë³‘ë ¬í™” ì²˜ë¦¬**:
   * ì´ì œ Aì—ì„œ Bì™€ Cê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ë„ë¡ íŒ¬ì•„ì›ƒ êµ¬ì¡°ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤.

```
builder = StateGraph(State)

# ê° ë…¸ë“œë¥¼ node_secretìœ¼ë¡œ ì´ˆê¸°í™” 
builder.add_node("a", ReturnNodeValue("ë‚˜ëŠ” Aì…ë‹ˆë‹¤"))
builder.add_node("b", ReturnNodeValue("ë‚˜ëŠ” Bì…ë‹ˆë‹¤"))
builder.add_node("c", ReturnNodeValue("ë‚˜ëŠ” Cì…ë‹ˆë‹¤"))
builder.add_node("d", ReturnNodeValue("ë‚˜ëŠ” Dì…ë‹ˆë‹¤"))

# íë¦„
builder.add_edge(START, "a")
builder.add_edge("a", "b")
builder.add_edge("a", "c")
builder.add_edge("b", "d")
builder.add_edge("c", "d")
builder.add_edge("d", END)
graph = builder.compile()

display(Image(graph.get_graph().draw_mermaid_png()))
```

![](https://velog.velcdn.com/images/euisuk-chung/post/57bedd44-45b7-4ef1-9d24-18865ed49494/image.png)

3. **ì—ëŸ¬ ë°œìƒ**

* êµ¬ì¡°ëŠ” ìœ„ì™€ ê°™ì´ ì‰½ê²Œ ì •ì˜í•  ìˆ˜ ìˆì§€ë§Œ, ë§‰ìƒ ì‹¤í–‰í•´ë³´ë©´, Bì™€ Cê°€ `ë™ì‹œì— ë™ì¼í•œ ìƒíƒœ í‚¤ë¥¼ ì—…ë°ì´íŠ¸`í•˜ë ¤ í•˜ë¯€ë¡œ **ì¶©ëŒì´ ë°œìƒ**í•˜ì—¬ **ì—ëŸ¬ê°€ ë°œìƒ**í•˜ê²Œ ë©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/a9aead21-4402-47eb-97e8-ff69b28e88e9/image.png)

4. **ë¦¬ë“€ì„œë¥¼ í†µí•œ ì¶©ëŒ í•´ê²°**:
   * ë³‘ë ¬ ë…¸ë“œ Bì™€ Cê°€ ë™ì‹œì— ë¦¬ìŠ¤íŠ¸ì— ê°’ì„ ì¶”ê°€í•˜ë„ë¡ ë¦¬ë“€ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒíƒœ ì¶©ëŒì„ í•´ê²°í•©ë‹ˆë‹¤.
   * íŒ¬ ì•„ì›ƒì„ ì‚¬ìš©í•  ë•ŒëŠ” ë‹¨ê³„ê°€ ë™ì¼í•œ ì±„ë„/í‚¤ì— ì“°ëŠ” ê²½ìš° ë¦¬ë“€ì„œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
   * ëª¨ë“ˆ 2ì—ì„œ ì–¸ê¸‰í–ˆë“¯ì´ `operator.add`ëŠ” Pythonì˜ ë‚´ì¥ operator ëª¨ë“ˆì˜ í•¨ìˆ˜ì…ë‹ˆë‹¤.
   * `operator.add`ê°€ ë¦¬ìŠ¤íŠ¸ì— ì ìš©ë˜ë©´ ë¦¬ìŠ¤íŠ¸ ì—°ê²°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```
import operator
from typing import Annotated

class State(TypedDict):
    # operator.add ë¦¬ë“€ì„œ í•¨ìˆ˜ëŠ” ì´ê²ƒì„ ì¶”ê°€ ì „ìš©ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤
    state: Annotated[list, operator.add]

# ë…¸ë“œ ì¶”ê°€
builder = StateGraph(State)

# ê° ë…¸ë“œë¥¼ node_secretìœ¼ë¡œ ì´ˆê¸°í™” 
builder.add_node("a", ReturnNodeValue("ë‚˜ëŠ” Aì…ë‹ˆë‹¤"))
builder.add_node("b", ReturnNodeValue("ë‚˜ëŠ” Bì…ë‹ˆë‹¤"))
builder.add_node("c", ReturnNodeValue("ë‚˜ëŠ” Cì…ë‹ˆë‹¤"))
builder.add_node("d", ReturnNodeValue("ë‚˜ëŠ” Dì…ë‹ˆë‹¤"))

# íë¦„
builder.add_edge(START, "a")
builder.add_edge("a", "b")
builder.add_edge("a", "c")
builder.add_edge("b", "d")
builder.add_edge("c", "d")
builder.add_edge("d", END)
graph = builder.compile()

display(Image(graph.get_graph().draw_mermaid_png()))
```

![](https://velog.velcdn.com/images/euisuk-chung/post/4b1139ea-46b3-4223-95ac-65f4666d5172/image.png)

```
graph.invoke({"state": []})
```

* ìœ„ì™€ ê°™ì´ ê·¸ë˜í”„ë¥¼ ìˆ˜í–‰í•˜ë©´ ì˜ë„í•œ ê²ƒì²˜ëŸ¼ ëê¹Œì§€ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
ë‚˜ëŠ” Aì…ë‹ˆë‹¤ë¥¼ []ì— ì¶”ê°€í•©ë‹ˆë‹¤
ë‚˜ëŠ” Bì…ë‹ˆë‹¤ë¥¼ ['ë‚˜ëŠ” Aì…ë‹ˆë‹¤']ì— ì¶”ê°€í•©ë‹ˆë‹¤
ë‚˜ëŠ” Cì…ë‹ˆë‹¤ë¥¼ ['ë‚˜ëŠ” Aì…ë‹ˆë‹¤']ì— ì¶”ê°€í•©ë‹ˆë‹¤
ë‚˜ëŠ” Dì…ë‹ˆë‹¤ë¥¼ ['ë‚˜ëŠ” Aì…ë‹ˆë‹¤', 'ë‚˜ëŠ” Bì…ë‹ˆë‹¤', 'ë‚˜ëŠ” Cì…ë‹ˆë‹¤']ì— ì¶”ê°€í•©ë‹ˆë‹¤
{'state': ['ë‚˜ëŠ” Aì…ë‹ˆë‹¤', 'ë‚˜ëŠ” Bì…ë‹ˆë‹¤', 'ë‚˜ëŠ” Cì…ë‹ˆë‹¤', 'ë‚˜ëŠ” Dì…ë‹ˆë‹¤']}
```

* ì´ì œ `b`ì™€ `c`ê°€ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•œ ì—…ë°ì´íŠ¸ê°€ ìƒíƒœì— ì¶”ê°€ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

4. **ì¶”ê°€ ì‹¤ìŠµ**

* ì¢€ ë” ë³µì¡í•œ ë³‘ë ¬ ê·¸ë˜í”„ì—ì„œë„ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ì´ ê²½ìš° `b`, `b2`, `c`ëŠ” ëª¨ë‘ ë™ì¼í•œ ë‹¨ê³„ì˜ ì¼ë¶€ì…ë‹ˆë‹¤.
* ê·¸ë˜í”„ëŠ” `d` ë‹¨ê³„ë¡œ ì§„í–‰í•˜ê¸° ì „ì— ì´ ëª¨ë“  ê²ƒë“¤ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.

```
class State(TypedDict):
    # operator.add ë¦¬ë“€ì„œ í•¨ìˆ˜ëŠ” ì´ê²ƒì„ ì¶”ê°€ ì „ìš©ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤
    state: Annotated[list, operator.add]

# Add nodes
builder = StateGraph(State)

# Initialize each node with node_secret 
builder.add_node("a", ReturnNodeValue("I'm A"))
builder.add_node("b", ReturnNodeValue("I'm B"))
builder.add_node("b2", ReturnNodeValue("I'm B2"))
builder.add_node("c", ReturnNodeValue("I'm C"))
builder.add_node("d", ReturnNodeValue("I'm D"))

# Flow
builder.add_edge(START, "a")
builder.add_edge("a", "b")
builder.add_edge("a", "c")
builder.add_edge("b", "b2")
builder.add_edge(["b2", "c"], "d")
builder.add_edge("d", END)
graph = builder.compile()

display(Image(graph.get_graph().draw_mermaid_png()))
```

![](https://velog.velcdn.com/images/euisuk-chung/post/cb3014bd-0415-41f5-a78d-481f0f95c613/image.png)

* `b`ì™€ `c`ëŠ” ë³‘ë ¬ë¡œ ì‹¤í–‰ì´ ë˜ê¸°ë•Œë¬¸ì— ë¨¼ì € ì‹¤í–‰ì´ ë˜ê³ , `.add` operatorë¡œ ì¸í•´ì„œ appendëœ ìˆœì„œëŒ€ë¡œ ì¶œë ¥ì´ ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
{'state': ["I'm A", "I'm B", "I'm C", "I'm B2", "I'm D"]}
```

5. **ê·¸ë˜í”„ ë³‘ë ¬í™” ìˆœì„œ ì œì–´**

* ê¸°ë³¸ì ìœ¼ë¡œ `LangGraph`ëŠ” ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ëŠ” ë…¸ë“œë“¤ì˜ ì—…ë°ì´íŠ¸ ìˆœì„œë¥¼ `ìë™ìœ¼ë¡œ ê²°ì •`í•©ë‹ˆë‹¤.
* ìœ„ì— 4ë²ˆ ì˜ˆì œì—ì„œë„ ì´ëŠ” ìš°ë¦¬ê°€ ì œì–´í•˜ì§€ ì•ŠëŠ” ê·¸ë˜í”„ í† í´ë¡œì§€ì— ê¸°ë°˜í•˜ì—¬ LangGraphê°€ **ê²°ì •ë¡ ì  ìˆœì„œ**ë¥¼ ì •í•´ì¤€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  
  + ìœ„ì—ì„œ ìš°ë¦¬ëŠ” `c`ê°€ `b2` ì „ì— ì¶”ê°€ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  + í•˜ì§€ë§Œ, ë§Œì•½ ì‚¬ìš©ìê°€ `íŠ¹ì • ìˆœì„œë¡œ ê²°ê³¼ë¥¼ ì²˜ë¦¬`í•˜ê³  ì‹¶ë‹¤ë©´, **ì»¤ìŠ¤í…€ ë¦¬ë“€ì„œ(Custom Reducer)**ë¥¼ ì •ì˜í•˜ì—¬ ì´ **ìˆœì„œë¥¼ ì§ì ‘ ì œì–´**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
def sorting_reducer(left, right):
    """ ë¦¬ìŠ¤íŠ¸ì˜ ê°’ë“¤ì„ ê²°í•©í•˜ê³  ì •ë ¬í•©ë‹ˆë‹¤"""
    if not isinstance(left, list):
        left = [left]

    if not isinstance(right, list):
        right = [right]
    
    return sorted(left + right, reverse=False)

class State(TypedDict):
    # sorting_reducerëŠ” ìƒíƒœì˜ ê°’ë“¤ì„ ì •ë ¬í•©ë‹ˆë‹¤
    state: Annotated[list, sorting_reducer]

# ë…¸ë“œ ì¶”ê°€
builder = StateGraph(State)

# ê° ë…¸ë“œë¥¼ node_secretìœ¼ë¡œ ì´ˆê¸°í™” 
builder.add_node("a", ReturnNodeValue("ë‚˜ëŠ” Aì…ë‹ˆë‹¤"))
builder.add_node("b", ReturnNodeValue("ë‚˜ëŠ” Bì…ë‹ˆë‹¤"))
builder.add_node("b2", ReturnNodeValue("ë‚˜ëŠ” B2ì…ë‹ˆë‹¤"))
builder.add_node("c", ReturnNodeValue("ë‚˜ëŠ” Cì…ë‹ˆë‹¤"))
builder.add_node("d", ReturnNodeValue("ë‚˜ëŠ” Dì…ë‹ˆë‹¤"))

# íë¦„
builder.add_edge(START, "a")
builder.add_edge("a", "b")
builder.add_edge("a", "c")
builder.add_edge("b", "b2")
builder.add_edge(["b2", "c"], "d")
builder.add_edge("d", END)
graph = builder.compile()

display(Image(graph.get_graph().draw_mermaid_png()))
```

* ì´ì œ ë¦¬ë“€ì„œê°€ ì—…ë°ì´íŠ¸ëœ ìƒíƒœ ê°’ì„ ì •ë ¬í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
{'state': ["I'm A", "I'm B", "I'm B2", "I'm C", "I'm D"]}
```

![](https://velog.velcdn.com/images/euisuk-chung/post/61e07515-1797-4e52-940f-0ff19e6f8c2a/image.png)

6. (ì‘ìš©) **ê·¸ë˜í”„ ë³‘ë ¬í™” ìˆœì„œ ì œì–´**

* ì¢€ ë” ì–´ë ¤ìš´(?) ëª¨ì–‘ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ê³  í•œë²ˆ ë” ì‹¤ìŠµì„ í•´ë³´ê² ìŠµë‹ˆë‹¤.

1) **ê¸°ì¡´ `operator.add` ë¦¬ë“€ì„œ ì‚¬ìš©í•œ ê²½ìš°**:

```
class State(TypedDict):
    # operator.add ë¦¬ë“€ì„œ í•¨ìˆ˜ëŠ” ì´ê²ƒì„ ì¶”ê°€ ì „ìš©ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤
    state: Annotated[list, operator.add]
```

* ì´ ë°©ì‹ì—ì„œëŠ” ë…¸ë“œê°€ ìˆœì°¨ì ìœ¼ë¡œ ê°’ì„ ì¶”ê°€í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
* **ê° ë…¸ë“œì—ì„œ ìƒì„±ëœ ê°’ì€ ìˆœì„œëŒ€ë¡œ ìƒíƒœ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€**ë©ë‹ˆë‹¤.
* `"b1"`ê³¼ `"c1"`ì´ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ê³ , ê·¸ í›„ì— `"b2"`ì™€ `"c2"`ê°€ ì‹¤í–‰ë˜ì–´ ê·¸ ê²°ê³¼ë“¤ì´ í•©ì³ì§„ ë‹¤ìŒ `"d"`ë¡œ ì´ë™í•©ë‹ˆë‹¤.
* ì´ë•ŒëŠ” ì•½ê°„ì˜ **DFS**ì²˜ëŸ¼ ë™ì‘í•©ë‹ˆë‹¤. ì¦‰, í•œ ê²½ë¡œë¥¼ ë”°ë¼ ëê¹Œì§€ ì‹¤í–‰í•œ ë‹¤ìŒ, ë‹¤ë¥¸ ê²½ë¡œë¥¼ ë”°ë¼ê°‘ë‹ˆë‹¤.
* ë”°ë¼ì„œ ì¶œë ¥ì€ `"I'm A", "I'm B1", "I'm C1", "I'm B2", "I'm C2", "I'm D"`ì™€ ê°™ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
* ì•„ë˜ íë¦„ì„ ì‚´í´ë³´ë©´:
  
  1. **`a`** ì‹¤í–‰ í›„ **`b1`**ê³¼ **`c1`** ë³‘ë ¬ë¡œ ì‹¤í–‰.
  2. **`b1`**ê°€ ì‹¤í–‰ë˜ê³  ë‚˜ì„œ **`b2`**ë¡œ ì´ë™.
  3. **`c1`**ì´ ì‹¤í–‰ë˜ê³  ë‚˜ì„œ **`c2`**ë¡œ ì´ë™.
  4. **`b2`**ì™€ **`c2`**ê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ê³  ê·¸ í›„ **`d`**ë¡œ ì´ë™.
* ê²°ê³¼:
  
  ```
  {'state': ["I'm A", "I'm B1", "I'm C1", "I'm B2", "I'm C2", "I'm D"]}
  ```
* ì´ê²ƒì€ ë§ˆì¹˜ **DFS**ì—ì„œ í•œ ê²½ë¡œë¥¼ ì­‰ ë”°ë¼ê°€ë©´ì„œ ì‹¤í–‰í•˜ê³ , ê·¸ í›„ ë‹¤ë¥¸ ê²½ë¡œë¡œ ì§„í–‰í•˜ëŠ” íë¦„ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.

2) **`sorting_reducer`ë¥¼ ì‚¬ìš©í•œ ê²½ìš°**:

```
def sorting_reducer(left, right):
    """Combines and sorts the values in a list"""
    if not isinstance(left, list):
        left = [left]
    
    if not isinstance(right, list):
        right = [right]
    
    return sorted(left + right, reverse=False)

class State(TypedDict):
    # sorting_reducer will sort the values in state
    state: Annotated[list, sorting_reducer]
```

* **`sorting_reducer`**ë¥¼ ì‚¬ìš©í•˜ë©´, ë³‘ë ¬ë¡œ ì‹¤í–‰ëœ ë…¸ë“œë“¤ì˜ ê°’ì´ ì •ë ¬ë˜ì–´ ìƒíƒœ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ë©ë‹ˆë‹¤.
* ì´ ë°©ì‹ì€ **BFS**ì²˜ëŸ¼ ì‘ë™í•©ë‹ˆë‹¤. ì¦‰, ë™ì¼í•œ ë ˆë²¨ì— ìˆëŠ” ë…¸ë“œë“¤ì´ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ê³ , ê·¸ í›„ì— ë‹¤ìŒ ë ˆë²¨ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.
* `"b1"`ê³¼ `"c1"`ì´ ë³‘ë ¬ë¡œ ì‹¤í–‰ëœ í›„, `"b2"`ì™€ `"c2"`ê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
* ìƒíƒœì— ì¶”ê°€ë  ë•ŒëŠ” ì•ŒíŒŒë²³ ìˆœì„œëŒ€ë¡œ ì •ë ¬ë˜ê¸° ë•Œë¬¸ì— `"I'm B1"`, `"I'm B2"`, `"I'm C1"`, `"I'm C2"`ì˜ ìˆœì„œë¡œ ì •ë ¬ë©ë‹ˆë‹¤.
* ì•„ë˜ íë¦„ì„ ì‚´í´ë³´ë©´:
  
  1. **`a`** ì‹¤í–‰ í›„ **`b1`**ê³¼ **`c1`**ì´ ë³‘ë ¬ë¡œ ì‹¤í–‰.
  2. **`b1`**ê³¼ **`c1`**ì˜ ê²°ê³¼ê°€ ë³‘í•©ë˜ê³ , **`b2`**ì™€ **`c2`**ê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰.
  3. **`b2`**ì™€ **`c2`**ì˜ ê²°ê³¼ê°€ ë³‘í•©ë˜ê³  **ì •ë ¬**ë¨.
  4. ê·¸ í›„ **`d`**ê°€ ì‹¤í–‰ë¨.
* ê²°ê³¼:
  
  ```
  {'state': ["I'm A", "I'm B1", "I'm B2", "I'm C1", "I'm C2", "I'm D"]}
  ```
* ì´ëŠ” ë§ˆì¹˜ **BFS**ì—ì„œ í•œ ë ˆë²¨ì˜ ë…¸ë“œë¥¼ ëª¨ë‘ ì‹¤í–‰í•œ í›„ ë‹¤ìŒ ë ˆë²¨ë¡œ ë„˜ì–´ê°€ëŠ” ë°©ì‹ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. ë³‘ë ¬ë¡œ ì‹¤í–‰ëœ ë…¸ë“œë“¤ì´ í•­ìƒ ì •ë ¬ëœ í˜•íƒœë¡œ ìƒíƒœì— ì €ì¥ë©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/ccab4f89-cad8-4e10-a44f-06fa8b9997b4/image.png)

7. (ì‹¬í™”) **ì •ë³´ ê²€ìƒ‰ ê·¸ë˜í”„ êµ¬í˜„**

* ì—¬ê¸°ì„œ ë‘ ê°œì˜ ê²€ìƒ‰ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ëŠ” ê·¸ë˜í”„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤:
  
  + **ì›¹ ê²€ìƒ‰(Web Search)**: ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì›¹ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
  + **ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰(Wikipedia Search)**: ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
* ë‘ ê²€ìƒ‰ ê²°ê³¼ëŠ” ëª¨ë‘ **context**ë¼ëŠ” ìƒíƒœ í‚¤ì— ì €ì¥ë©ë‹ˆë‹¤.
* ì•„ë˜ ì½”ë“œëŠ” `ì›¹ ê²€ìƒ‰`ê³¼ `ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰`ì„ **ë³‘ë ¬ë¡œ ì‹¤í–‰**í•œ í›„, **ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ LLMì„ í†µí•´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±**í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/ea7d0219-c0e8-407e-9522-66ef54be2ef9/image.png)

0) **Import Libraries**

```
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.document_loaders import WikipediaLoader
from langchain_community.tools.tavily_search import TavilySearchResults
```

1) **`search_web` í•¨ìˆ˜**

```
def search_web(state):
    
    """ ì›¹ ê²€ìƒ‰ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰ """

    # ê²€ìƒ‰
    tavily_search = TavilySearchResults(max_results=3)
    search_docs = tavily_search.invoke(state['question'])

     # í˜•ì‹ ì§€ì •
    formatted_search_docs = "\n\n---\n\n".join(
        [
            f'<Document href="{doc["url"]}"/>\n{doc["content"]}\n</Document>'
            for doc in search_docs
        ]
    )

    return {"context": [formatted_search_docs]} 
```

* **ì—­í• **: `search_web` í•¨ìˆ˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ì„œ ì›¹ì—ì„œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
  
  + ì—¬ê¸°ì„œëŠ” **TavilySearchResults**ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœëŒ€ 3ê°œì˜ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
* **`tavily_search.invoke`**: ì§ˆë¬¸ì„ ì…ë ¥ë°›ì•„ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ ë¬¸ì„œë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
* **ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜**: ê²€ìƒ‰ ê²°ê³¼ëŠ” HTML í˜•ì‹ì˜ íƒœê·¸ë¡œ ì§€ì •ë˜ë©°, ê° ë¬¸ì„œëŠ” `<Document>` íƒœê·¸ë¡œ ê°ì‹¸ì ¸ ìˆìŠµë‹ˆë‹¤.
  
  + `search_docs` ë¦¬ìŠ¤íŠ¸ì˜ ê° ìš”ì†Œ `doc`ì— ëŒ€í•´ ë°˜ë³µí•©ë‹ˆë‹¤.
  + ê° `doc`ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ, `url`ê³¼ `content` í‚¤ë¥¼ ê°€ì§‘ë‹ˆë‹¤.
  + ê° `doc`ë¥¼ `<Document>` íƒœê·¸ë¡œ ê°ì‹¸ê³ , `href` ì†ì„±ì— `url` ê°’ì„, íƒœê·¸ ì•ˆì— `content` ê°’ì„ ë„£ìŠµë‹ˆë‹¤.
  + ì´ ê³¼ì •ì„ í†µí•´ ê° docë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
* **ë¬¸ìì—´ ê²°í•©**: ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ì„ í†µí•´ ìƒì„±ëœ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ `"\n\n---\n\n"` ë¬¸ìì—´ë¡œ ê²°í•©í•©ë‹ˆë‹¤.
  
  + ì´ ê²°í•© ë¬¸ìì—´ì€ ê° ë¬¸ì„œ ì‚¬ì´ì— **êµ¬ë¶„ì„ ì„ ì¶”ê°€**í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
* **ì¶œë ¥**: í¬ë§·íŒ…ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸(`formatted_search_docs`)ëŠ” `context`ì— ì €ì¥ë˜ì–´ ë°˜í™˜ë©ë‹ˆë‹¤.

---

2) **`search_wikipedia` í•¨ìˆ˜**

```
def search_wikipedia(state):
    
    """ ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰ """

    # ê²€ìƒ‰
    search_docs = WikipediaLoader(query=state['question'], 
                                  load_max_docs=2).load()

     # í˜•ì‹ ì§€ì •
    formatted_search_docs = "\n\n---\n\n".join(
        [
            f'<Document source="{doc.metadata["source"]}" page="{doc.metadata.get("page", "")}"/>\n{doc.page_content}\n</Document>'
            for doc in search_docs
        ]
    )

    return {"context": [formatted_search_docs]} 
```

* **ì—­í• **: `search_wikipedia` í•¨ìˆ˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ì„œ **ìœ„í‚¤í”¼ë””ì•„**ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
* **`WikipediaLoader`**: ì£¼ì–´ì§„ ì§ˆë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ìµœëŒ€ 2ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
* **í˜•ì‹ ì§€ì •**: ê²€ìƒ‰ ê²°ê³¼ëŠ” `<Document>` íƒœê·¸ë¡œ í¬ë§·íŒ…ë˜ì–´ ë¬¸ì„œì˜ ì¶œì²˜ì™€ í˜ì´ì§€ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
  
  + `formatted_search_docs` ë³€ìˆ˜ëŠ” ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ê° ë¬¸ì„œë¥¼ íŠ¹ì • XML í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•œ ë¬¸ìì—´ë“¤ì„ ê²°í•©í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
  + ê° ë¬¸ì„œëŠ” `<Document>` íƒœê·¸ë¡œ ê°ì‹¸ì ¸ ìˆìœ¼ë©°, ë¬¸ì„œì˜ ì¶œì²˜ì™€ í˜ì´ì§€ ì •ë³´ê°€ í¬í•¨ë©ë‹ˆë‹¤. ì´ ì •ë³´ëŠ” `doc.metadata` ë”•ì…”ë„ˆë¦¬ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
  + ë¬¸ì„œì˜ ì‹¤ì œ ë‚´ìš©ì€ `doc.page_content`ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
* **ì¶œë ¥**: í¬ë§·íŒ…ëœ ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ê°€ `context`ì— ì €ì¥ë˜ì–´ ë°˜í™˜ë©ë‹ˆë‹¤.

---

3) **`generate_answer` í•¨ìˆ˜**

```

def generate_answer(state):
    
    """ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë…¸ë“œ """

    # ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
    context = state["context"]
    question = state["question"]

    # í…œí”Œë¦¿
    answer_template = """ì´ ë§¥ë½ì„ ì‚¬ìš©í•˜ì—¬ {question} ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”: {context}"""
    answer_instructions = answer_template.format(question=question, 
                                                       context=context)    
    
    # ë‹µë³€
    answer = llm.invoke([SystemMessage(content=answer_instructions)]+[HumanMessage(content=f"ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.")])
      
    # ìƒíƒœì— ì¶”ê°€
    return {"answer": answer}
```

* **ì—­í• **: `generate_answer` í•¨ìˆ˜ëŠ” `ì›¹ ê²€ìƒ‰` ë° `ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰` ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
* **í…œí”Œë¦¿**: ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì„ ê²°í•©í•˜ì—¬ **LLM(Large Language Model)**ì— ì „ë‹¬í•  í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
* **LLM ì‚¬ìš©**: ìƒì„±ëœ í…œí”Œë¦¿ì„ **`SystemMessage`**ì™€ **`HumanMessage`**ë¡œ LLMì— ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
* **ì¶œë ¥**: ìƒì„±ëœ ë‹µë³€ì€ ìƒíƒœì— ì¶”ê°€ë˜ì–´ ë°˜í™˜ë©ë‹ˆë‹¤.

---

4) **ê·¸ë˜í”„ ë…¸ë“œ ì¶”ê°€ ë° íë¦„ ì„¤ì •**

```
# ë…¸ë“œ ì¶”ê°€
builder = StateGraph(State)

# ê° ë…¸ë“œë¥¼ node_secretìœ¼ë¡œ ì´ˆê¸°í™” 
builder.add_node("search_web",search_web)
builder.add_node("search_wikipedia", search_wikipedia)
builder.add_node("generate_answer", generate_answer)

# íë¦„
builder.add_edge(START, "search_wikipedia")
builder.add_edge(START, "search_web")
builder.add_edge("search_wikipedia", "generate_answer")
builder.add_edge("search_web", "generate_answer")
builder.add_edge("generate_answer", END)
graph = builder.compile()

display(Image(graph.get_graph().draw_mermaid_png()))
```

* **íë¦„**: ì´ ê·¸ë˜í”„ëŠ” ë³‘ë ¬ë¡œ ê²€ìƒ‰ ì‘ì—…ì„ ì²˜ë¦¬í•˜ê³ , ê·¸ í›„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì´ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
* **ì‹¤í–‰ íë¦„ ì„¤ëª…**:
  
  + ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, **ìœ„í‚¤í”¼ë””ì•„**ì™€ **ì›¹ ê²€ìƒ‰**ì´ ë™ì‹œì— ì‹¤í–‰ë©ë‹ˆë‹¤.
  + ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì´ ê°ê° í¬ë§·íŒ…ë˜ì–´ `context` ìƒíƒœì— ì €ì¥ë©ë‹ˆë‹¤.
  + ê·¸ í›„, ë‘ ê²€ìƒ‰ì˜ ê²°ê³¼ê°€ ë³‘í•©ë˜ì–´ `generate_answer` ë…¸ë“œì—ì„œ LLMì„ í†µí•´ ë‹µë³€ì´ ìƒì„±ë©ë‹ˆë‹¤.
* ê²°ê³¼ì ìœ¼ë¡œ, ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

---

5) **ì§ˆë¬¸ ì…ë ¥**

* ì•„ë˜ì™€ ê°™ì´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ TAVILYì™€ WIKIPEDIA SEARCHë¥¼ í†µí•´ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```
result = graph.invoke({"question": "LGì „ìì˜ 2024ë…„ 3ë¶„ê¸° ì‹¤ì ì€ ì–´ë• ë‚˜ìš”?"})
print(result['answer'].content)
```

* ì•„ë˜ëŠ” ìœ„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì˜ˆì‹œì…ë‹ˆë‹¤:

```
LGì „ìì˜ 2024ë…„ 3ë¶„ê¸° ì‹¤ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- ë§¤ì¶œ: 22ì¡°1769ì–µì›, ì „ë…„ ë™ê¸° ëŒ€ë¹„ 10.7% ì¦ê°€
- ì˜ì—…ì´ìµ: 7511ì–µì›, ì „ë…„ ë™ê¸° ëŒ€ë¹„ 20.9% ê°ì†Œ

ë§¤ì¶œì€ 3ë¶„ê¸° ìµœëŒ€ì¹˜ë¥¼ ê¸°ë¡í–ˆìœ¼ë©°, ì´ëŠ” ê°€ì „ì œí’ˆê³¼ ì „ì¥ ë¶€ë¬¸ì˜ ì§€ì†ì ì¸ ì„±ì¥ ë•ë¶„ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì˜ì—…ì´ìµì€ ë¬¼ë¥˜ë¹„ ê¸‰ë“± ë° ë§ˆì¼€íŒ…ë¹„ ì¦ê°€ë¡œ ì¸í•´ ê°ì†Œí–ˆìŠµë‹ˆë‹¤.
```

---

Lesson 2: Sub-graphs
--------------------

### ê°œìš”

* `ì„œë¸Œê·¸ë˜í”„(Sub-graph)`ëŠ” í° ê·¸ë˜í”„ì˜ ì¼ë¶€ë¶„ìœ¼ë¡œ, ë…ë¦½ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ì‘ì—… ë‹¨ìœ„ì…ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/6b13f7ed-c6e4-4dbc-a334-4049a5bac025/image.png)

* ì„œë¸Œê·¸ë˜í”„ëŠ” ìƒíƒœ í‚¤ë¥¼ ê³µìœ í•˜ê±°ë‚˜ ë…ë¦½ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì—ì„œ ê° ì—ì´ì „íŠ¸ê°€ ë…ë¦½ì ì¸ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë©´ì„œë„ ë¶€ëª¨ ê·¸ë˜í”„ì™€ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ê°„ë‹¨í•œ ì˜ˆë¥¼ ì‚´í´ë´…ì‹œë‹¤:
  
  + **ë¡œê·¸ë¥¼ ë°›ëŠ” ì‹œìŠ¤í…œ**ì´ ìˆìŠµë‹ˆë‹¤
  + ì´ **ì‹œìŠ¤í…œ**ì€ ì„œë¡œ ë‹¤ë¥¸ ê°ê°ì˜ ì—ì´ì „íŠ¸(Summary Agent, Failure Analysis Agent)ì— ì˜í•´ ë‘ ê°€ì§€ ë³„ë„ì˜ í•˜ìœ„ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤(ë¬¸ì„œìš”ì•½, ì˜¤ë¥˜ë¶„ì„)
  + ì´ ë‘ ê°€ì§€ ì‘ì—…ì„ ë‘ ê°œì˜ ë‹¤ë¥¸ ì„œë¸Œ ê·¸ë˜í”„ì—ì„œ ìˆ˜í–‰í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/30201199-3377-4e57-85f9-c57e71f80236/image.png)

* ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ê²ƒì€ ê·¸ë˜í”„ë“¤ì´ "ì–´ë–»ê²Œ í†µì‹ ì„ í• ê¹Œ"ë¼ëŠ” ê²ƒì…ë‹ˆë‹¤.
* ê°„ë‹¨íˆ ë§í•´, í†µì‹ ì€ **ê²¹ì¹˜ëŠ” í‚¤**ë¥¼ í†µí•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤:
  
  + ì„œë¸Œ ê·¸ë˜í”„ëŠ” ë¶€ëª¨ë¡œë¶€í„° docsì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
  + ë¶€ëª¨ëŠ” ì„œë¸Œ ê·¸ë˜í”„ë¡œë¶€í„° Summary Agent ë˜ëŠ” Failure Analysis Agentì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

### ì£¼ìš” ê°œë…

1. **ì„œë¸Œ ê·¸ë˜í”„ì™€ ë¶€ëª¨ ê·¸ë˜í”„ ê°„ì˜ ìƒíƒœ ê³µìœ **:
   
   * `ì„œë¸Œ ê·¸ë˜í”„`ì™€ `ë¶€ëª¨ ê·¸ë˜í”„` ê°„ì— **ë°ì´í„°ë¥¼ êµí™˜í•˜ê¸° ìœ„í•´ ìƒíƒœ í‚¤ê°€ ì¤‘ë³µ**ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
   * íŠ¹ì • ìƒíƒœëŠ” ì„œë¸Œê·¸ë˜í”„ ë‚´ì—ì„œë§Œ ê´€ë¦¬ë˜ë©° ë¶€ëª¨ ê·¸ë˜í”„ì—ëŠ” ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.
2. **ì¶œë ¥ ìŠ¤í‚¤ë§ˆ**:
   
   * ì„œë¸Œ ê·¸ë˜í”„ì˜ ì¶œë ¥ ìƒíƒœë¥¼ ì œí•œí•˜ì—¬ ë¶ˆí•„ìš”í•œ ìƒíƒœ í‚¤ë¥¼ ë¶€ëª¨ ê·¸ë˜í”„ì— ë°˜í™˜í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.

### ì½”ë“œ ì˜ˆì‹œ

* ì´ë²ˆ ì½”ë“œ ì‹¤ìŠµì€ **ë‘ ê°œì˜ ì„œë¸Œ-ê·¸ë˜í”„**(`Failure Analysis ì„œë¸Œ-ê·¸ë˜í”„`ì™€ `Question Summarization ì„œë¸Œ-ê·¸ë˜í”„`)ë¥¼ **ë¶€ëª¨ ê·¸ë˜í”„**(`EntryGraph`)ë¡œ í†µí•©í•˜ì—¬, **ì£¼ì–´ì§„ ë¡œê·¸ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œ**ì„ êµ¬í˜„í•œ ì˜ˆì œì…ë‹ˆë‹¤.
  + ì´ ì‹œìŠ¤í…œì€ ë³‘ë ¬ë¡œ ë‘ ê°œì˜ ì„œë¸Œê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•œ í›„, ê°ê°ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ `ìµœì¢… ë³´ê³ ì„œ`ì™€ `ìš”ì•½ì„ ìƒì„±`í•©ë‹ˆë‹¤.

```
# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from operator import add
from typing_extensions import TypedDict
from typing import List, Optional, Annotated
```

**1. ë¡œê·¸ êµ¬ì¡° ì •ì˜**:

* ë¨¼ì €, `Log` í´ë˜ìŠ¤ëŠ” ë¡œê·¸ ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ê° ë¡œê·¸ëŠ” ì§ˆë¬¸ê³¼ ë‹µë³€, í‰ê°€ ì •ë³´ ë° í”¼ë“œë°±ì„ í¬í•¨í•©ë‹ˆë‹¤.

```
class Log(TypedDict):
    id: str
    question: str
    docs: Optional[List]
    answer: str
    grade: Optional[int]
    grader: Optional[str]
    feedback: Optional[str]

```

* **id**: ë¡œê·¸ì˜ ê³ ìœ  ì‹ë³„ì.
* **question**: ì‚¬ìš©ìì˜ ì§ˆë¬¸.
* **docs**: ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤.
* **answer**: ì œê³µëœ ë‹µë³€.
* **grade**: ë¡œê·¸ì˜ í‰ê°€ (ì˜ˆ: í’ˆì§ˆ ì ìˆ˜).
* **grader**: í‰ê°€ì ì •ë³´.
* **feedback**: í‰ê°€ì™€ ê´€ë ¨ëœ í”¼ë“œë°±.

---

**2. Failure Analysis ì„œë¸Œê·¸ë˜í”„**:

* `Failure Analysis` ì„œë¸Œê·¸ë˜í”„ì˜ ëª©í‘œëŠ” **ì‹¤íŒ¨í•œ ë¡œê·¸ë¥¼ ì‹ë³„í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ìš”ì•½**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/049db968-6a17-4327-99cb-d3a37d210d4a/image.png)

* `FailureAnalysisState`ëŠ” ì‹¤íŒ¨ ë¶„ì„ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ê´€ë¦¬í•  ìƒíƒœë¥¼ ì •ì˜í•˜ë©°, ì£¼ë¡œ ì‹¤íŒ¨í•œ ë¡œê·¸ì— ëŒ€í•œ ìš”ì•½ê³¼ ì²˜ë¦¬ëœ ë¡œê·¸ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

```
class FailureAnalysisState(TypedDict):
    cleaned_logs: List[Log]   # ì²˜ë¦¬ëœ ë¡œê·¸
    failures: List[Log]       # ì‹¤íŒ¨í•œ ë¡œê·¸ ëª©ë¡
    fa_summary: str           # ì‹¤íŒ¨ ë¶„ì„ ìš”ì•½
    processed_logs: List[str] # ì²˜ë¦¬ëœ ë¡œê·¸ ì •ë³´

```

* `FailureAnalysisOutputState`ëŠ” ì‹¤íŒ¨ ë¶„ì„ ì„œë¸Œê·¸ë˜í”„ì˜ ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•©ë‹ˆë‹¤. í•´ë‹¹ ì¶œë ¥ ìŠ¤í‚¤ë§ˆëŠ” ìœ„ì—ì™€ëŠ” ë‹¤ë¥´ê²Œ **ìœ ì €ì—ê²Œ ì „í•˜ê³  ì‹¶ì€ ì •ë³´**ë§Œ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

```
class FailureAnalysisOutputState(TypedDict):
    fa_summary: str
    processed_logs: List[str]

```

* **get\_failures**: ì‹¤íŒ¨í•œ ë¡œê·¸(gradeê°€ í¬í•¨ëœ ë¡œê·¸)ë¥¼ í•„í„°ë§í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.

```
def get_failures(state):
    """ ì‹¤íŒ¨ë¥¼ í¬í•¨í•˜ëŠ” ë¡œê·¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ """
    cleaned_logs = state["cleaned_logs"]
    failures = [log for log in cleaned_logs if "grade" in log]
    return {"failures": failures}

```

* **generate\_summary**: í•„í„°ë§ëœ ì‹¤íŒ¨ ë¡œê·¸ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ì„ ìƒì„±í•˜ê³ , ì´ë¥¼ `processed_logs`ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.

```
def generate_summary(state):
    """ ì‹¤íŒ¨ì˜ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤ """
    failures = state["failures"]
    # í•¨ìˆ˜ ì¶”ê°€: fa_summary = summarize(failures)
    fa_summary = "Chroma ë¬¸ì„œì˜ ê²€ìƒ‰ í’ˆì§ˆì´ ë‚®ìŒ."
    return {"fa_summary": fa_summary, 
            "processed_logs": [f"failure-analysis-on-log-{failure['id']}" for failure in failures]}

```

* **sub-graph ì •ì˜**: ì•„ë˜ ì½”ë“œë¥¼ í†µí•´ì„œ sub-graphë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

```
fa_builder = StateGraph(input=FailureAnalysisState,output=FailureAnalysisOutputState)
fa_builder.add_node("get_failures", get_failures)
fa_builder.add_node("generate_summary", generate_summary)
fa_builder.add_edge(START, "get_failures")
fa_builder.add_edge("get_failures", "generate_summary")
fa_builder.add_edge("generate_summary", END)

graph = fa_builder.compile()
display(Image(graph.get_graph().draw_mermaid_png()))
```

---

**3. Question Summarization ì„œë¸Œê·¸ë˜í”„**

* `Question Summarization` ì„œë¸Œê·¸ë˜í”„ëŠ” ë¡œê·¸ë¥¼ ìš”ì•½í•˜ê³ , ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/f9b8246c-934a-4bef-8a52-662cb28e7431/image.png)

* `QuestionSummarizationState`ëŠ” ì§ˆë¬¸ ìš”ì•½ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ì‚¬ìš©í•  ìƒíƒœë¥¼ ì •ì˜í•˜ë©°, ì£¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ìš”ì•½ê³¼ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```
class QuestionSummarizationState(TypedDict):
    cleaned_logs: List[Log]   # ì²˜ë¦¬ëœ ë¡œê·¸
    qs_summary: str           # ì§ˆë¬¸ ìš”ì•½
    report: str               # ë³´ê³ ì„œ
    processed_logs: List[str] # ì²˜ë¦¬ëœ ë¡œê·¸ ì •ë³´

```

* `QuestionSummarizationOutputState`ëŠ” ì§ˆë¬¸ ìš”ì•½ ì„œë¸Œê·¸ë˜í”„ì˜ ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•©ë‹ˆë‹¤. í•´ë‹¹ ì¶œë ¥ ìŠ¤í‚¤ë§ˆëŠ” ìœ„ì—ì™€ëŠ” ë‹¤ë¥´ê²Œ **ìœ ì €ì—ê²Œ ì „í•˜ê³  ì‹¶ì€ ì •ë³´**ë§Œ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

```
class QuestionSummarizationOutputState(TypedDict):
    report: str
    processed_logs: List[str]

```

* **generate\_summary**: ì§ˆë¬¸ ë¡œê·¸ë¥¼ ìš”ì•½í•˜ê³ , ê° ë¡œê·¸ì˜ ìš”ì•½ ê²°ê³¼ë¥¼ `processed_logs`ì— ê¸°ë¡í•©ë‹ˆë‹¤.

```
def generate_summary(state):
    cleaned_logs = state["cleaned_logs"]
    # í•¨ìˆ˜ ì¶”ê°€: summary = summarize(generate_summary)
    summary = "ì§ˆë¬¸ì€ ChatOllamaì™€ Chroma ë²¡í„° ì €ì¥ì†Œì˜ ì‚¬ìš©ì— ì´ˆì ì„ ë§ì·„ìŠµë‹ˆë‹¤."
    return {"qs_summary": summary, 
            "processed_logs": [f"summary-on-log-{log['id']}" for log in cleaned_logs]}
```

* **send\_to\_slack**: ìƒì„±ëœ ìš”ì•½ì„ ë³´ê³ ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤(ë‹¨ìˆœí•œ ë”ë¯¸ ì˜ˆì‹œì—ì„œ "foo bar baz"ë¼ëŠ” ê²°ê³¼ë¥¼ ë°˜í™˜).

```
def send_to_slack(state):
    qs_summary = state["qs_summary"]
    # í•¨ìˆ˜ ì¶”ê°€: report = report_generation(qs_summary)
    report = "foo bar baz"
    return {"report": report}

```

* **sub-graph ì •ì˜**: ì•„ë˜ ì½”ë“œë¥¼ í†µí•´ì„œ sub-graphë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

```
qs_builder = StateGraph(input=QuestionSummarizationState,output=QuestionSummarizationOutputState)
qs_builder.add_node("generate_summary", generate_summary)
qs_builder.add_node("send_to_slack", send_to_slack)
qs_builder.add_edge(START, "generate_summary")
qs_builder.add_edge("generate_summary", "send_to_slack")
qs_builder.add_edge("send_to_slack", END)

graph = qs_builder.compile()
display(Image(graph.get_graph().draw_mermaid_png()))
```
> ğŸ“š (ì°¸ê³ ) **EntryGraphStates**
> 
> * ìš°ë¦¬ëŠ” `EntryGraphState` í´ë˜ìŠ¤ë¡œ ë¶€ëª¨ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> * ì•„ë˜ì²˜ëŸ¼ ì •ì˜í•´ì„œ ì„œë¸Œ ë…¸ë“œë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>   + `entry_builder.add_node("question_summarization", qs_builder.compile())`
>   + `entry_builder.add_node("failure_analysis", fa_builder.compile())`
> * `EntryGraphState` í´ë˜ìŠ¤ë¥¼ ì‚´í´ë³´ë©´, `cleaned_logs`ì™€ `processed_logs`ì— `Annotated[List[Log], add]`ê°€ ì‚¬ìš©ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> 
> ```
> # ì§„ì… ê·¸ë˜í”„
> class EntryGraphState(TypedDict):
>     raw_logs: List[Log]
>     cleaned_logs: Annotated[List[Log], add] # ì´ê²ƒì€ ë‘ ì„œë¸Œ ê·¸ë˜í”„ì—ì„œ ëª¨ë‘ ì‚¬ìš©ë©ë‹ˆë‹¤
>     fa_summary: str # ì´ê²ƒì€ FA ì„œë¸Œ ê·¸ë˜í”„ì—ì„œë§Œ ìƒì„±ë©ë‹ˆë‹¤
>     report: str # ì´ê²ƒì€ QS ì„œë¸Œ ê·¸ë˜í”„ì—ì„œë§Œ ìƒì„±ë©ë‹ˆë‹¤
>     processed_logs: Annotated[List[int], add] # ì´ê²ƒì€ ë‘ ì„œë¸Œ ê·¸ë˜í”„ì—ì„œ ëª¨ë‘ ìƒì„±ë©ë‹ˆë‹¤
> ```
> 
> * ìœ„ì˜ `EntryGraphState`ì—ì„œ ê°ê° **cleaned\_logs**ì™€ **processed\_logs**ì— `Annotated[List[Log], add]` ë¦¬ë“€ì„œê°€ ì‚¬ìš©ë˜ëŠ” ì´ìœ ëŠ”, ë‘ ì„œë¸Œê·¸ë˜í”„ê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ë©´ì„œ ë™ì¼í•œ ìƒíƒœ í‚¤ë¥¼ ì°¸ì¡°í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
> * ê°ê°ì˜ ë¦¬ë“€ì„œë¥¼ ì •ì˜í•´ì¤Œìœ¼ë¡œì¨ `Annotated[List[int], add]` ë³‘ë ¬ ì‹¤í–‰ ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìƒíƒœ ì¶©ëŒì„ ë°©ì§€í•˜ê³ , ì—¬ëŸ¬ ê°’ì„ ì•ˆì „í•˜ê²Œ ë³‘í•©í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.

> ğŸ“š (ì‹¬í™”) **`cleaned_logs: Annotated[List[Log], add]`**
> 
> ```
> cleaned_logs: Annotated[List[Log], add]
> ```
> 
> * **ë‘ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©**: `cleaned_logs`ëŠ” **Failure Analysis ì„œë¸Œê·¸ë˜í”„**ì™€ **Question Summarization ì„œë¸Œê·¸ë˜í”„**ê°€ **ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ìƒíƒœ**ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ìƒíƒœëŠ” ë‘ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ìˆ˜ì •ë˜ì§€ ì•Šê³  ì°¸ì¡°ë§Œ ë©ë‹ˆë‹¤.
> * **ë³‘ë ¬ ì‹¤í–‰ ì‹œì˜ ìƒíƒœ ì¶©ëŒ ë°©ì§€**: ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ëŠ” ë‘ ì„œë¸Œê·¸ë˜í”„ê°€ ê°™ì€ ìƒíƒœ í‚¤(`cleaned_logs`)ë¥¼ ì°¸ì¡°í•˜ì§€ë§Œ, ê·¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•  ë•Œ **ë™ì¼í•œ í‚¤ë¥¼ ë°˜í™˜**í•˜ê¸° ë•Œë¬¸ì—, ì´ í‚¤ì— ëŒ€í•œ ìƒíƒœ ë³‘í•©ì´ í•„ìš”í•©ë‹ˆë‹¤. ë¦¬ë“€ì„œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë‘ ì„œë¸Œê·¸ë˜í”„ê°€ ë°˜í™˜í•˜ëŠ” ìƒíƒœê°€ ì¶©ëŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> * **`add` ë¦¬ë“€ì„œì˜ ì—­í• **: `add` ë¦¬ë“€ì„œëŠ” ê° ì„œë¸Œê·¸ë˜í”„ì—ì„œ ë°˜í™˜ëœ `cleaned_logs` ë¦¬ìŠ¤íŠ¸ë¥¼ ë³‘í•©í•´ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ë©°, ì´ë•Œ ì›ë³¸ ë¦¬ìŠ¤íŠ¸ëŠ” ìˆ˜ì •ë˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤. ì¦‰, ë‘ ì„œë¸Œê·¸ë˜í”„ê°€ ê°™ì€ `cleaned_logs`ë¥¼ ë°˜í™˜í•˜ë”ë¼ë„, `add` ë¦¬ë“€ì„œë¥¼ í†µí•´ ì•ˆì „í•˜ê²Œ ë³‘í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ğŸ“š (ì‹¬í™”) **`processed_logs: Annotated[List[int], add]`**
> 
> ```
> processed_logs: Annotated[List[int], add]
> ```
> 
> * **ë‘ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ìƒì„±ë˜ëŠ” ê°’**: `processed_logs`ëŠ” **Failure Analysis ì„œë¸Œê·¸ë˜í”„**ì™€ **Question Summarization ì„œë¸Œê·¸ë˜í”„**ê°€ **ê°ê¸° ë‹¤ë¥¸ ê°’ì„ ìƒì„±**í•˜ëŠ” ìƒíƒœì…ë‹ˆë‹¤. ê° ì„œë¸Œê·¸ë˜í”„ëŠ” ìì²´ì ìœ¼ë¡œ ì²˜ë¦¬ëœ ë¡œê·¸ì˜ ID ë˜ëŠ” ê´€ë ¨ ì •ë³´ë¥¼ `processed_logs`ì— ê¸°ë¡í•©ë‹ˆë‹¤.
> * **ë³‘ë ¬ ì‹¤í–‰ ì‹œ ê° ì„œë¸Œê·¸ë˜í”„ì—ì„œ ê°’ ì¶”ê°€**: ë‘ ì„œë¸Œê·¸ë˜í”„ê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ë©´ì„œ, ê°ê°ì˜ `processed_logs` ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ë§Œì•½ ë¦¬ë“€ì„œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´, ë‘ ì„œë¸Œê·¸ë˜í”„ê°€ ë°˜í™˜í•œ ê°’ì´ ì¶©ëŒí•˜ì—¬ í•œ ì„œë¸Œê·¸ë˜í”„ì˜ ê°’ë§Œ ë°˜ì˜ë˜ê±°ë‚˜ ìƒíƒœê°€ ë®ì–´ì”Œì›Œì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> * **`add` ë¦¬ë“€ì„œì˜ ì—­í• **: `add` ë¦¬ë“€ì„œëŠ” ë‘ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ë°˜í™˜ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³‘í•©í•˜ì—¬, **ë‘ ì„œë¸Œê·¸ë˜í”„ì˜ ëª¨ë“  ë¡œê·¸ê°€ ì•ˆì „í•˜ê²Œ ê¸°ë¡**ë˜ë„ë¡ í•©ë‹ˆë‹¤. ì¦‰, ë‘ ì„œë¸Œê·¸ë˜í”„ê°€ ê°ê¸° ë‹¤ë¥¸ ê°’ì„ ìƒì„±í•´ë„, `add` ë¦¬ë“€ì„œê°€ ê° ê°’ë“¤ì„ ê²°í•©í•˜ì—¬ `processed_logs`ì— ì €ì¥í•©ë‹ˆë‹¤.

> ğŸ¤” (ì‹¬í™”) **ê°ê° ë‘˜ë‹¤ ê³µí†µì ì¸ íŒŒë¼ë¯¸í„°ë¥¼ ê³µìœ í•˜ë‹¤ë³´ë‹ˆ ê·¸ëŸ°ê±°ë¼ê³  ì´í•´í•  ìˆ˜ ìˆëŠ”ë° ë‹¤ë¥¸ í´ë˜ìŠ¤ë¼ì„œ ìƒê´€ì—†ì§€ ì•Šë‚˜?**
> 
> * ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤! ê²‰ë³´ê¸°ì—ëŠ” `FailureAnalysisState`ì™€ `QuestionSummarizationState`ê°€ ì„œë¡œ ë‹¤ë¥¸ í´ë˜ìŠ¤ì´ê³ , ê° ì„œë¸Œê·¸ë˜í”„ ë‚´ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ ì •ì˜ëœ ìƒíƒœì´ê¸° ë•Œë¬¸ì— `cleaned_logs`ì™€ `processed_logs`ê°€ ê²¹ì¹˜ë”ë¼ë„ ë¬¸ì œê°€ ì—†ì–´ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ **ì´ë“¤ì´ ë™ì¼í•œ ìƒìœ„ ê·¸ë˜í”„(Entry Graph)ì—ì„œ ë³‘ë ¬ë¡œ ì‹¤í–‰ë  ë•ŒëŠ” ìƒí™©ì´ ë‹¤ë¦…ë‹ˆë‹¤**.
> * `cleaned_logs`ì™€ `processed_logs`ê°€ ë…ë¦½ëœ í´ë˜ìŠ¤ì—ì„œ ì •ì˜ë˜ì—ˆì§€ë§Œ, **Entry Graph(ìƒìœ„ ê·¸ë˜í”„)**ì—ì„œëŠ” ì´ë“¤ ì„œë¸Œê·¸ë˜í”„ê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ê¸° ë•Œë¬¸ì— **ë‘ ì„œë¸Œê·¸ë˜í”„ì˜ ìƒíƒœê°€ ìƒìœ„ ê·¸ë˜í”„ì˜ ìƒíƒœë¡œ ë³‘í•©**ë©ë‹ˆë‹¤. ì¦‰, ë‘ ì„œë¸Œê·¸ë˜í”„ëŠ” `EntryGraphState`ì— ì •ì˜ëœ `cleaned_logs`ì™€ `processed_logs`ë¥¼ ê³µìœ í•˜ê²Œ ë©ë‹ˆë‹¤.
> * ì„œë¸Œê·¸ë˜í”„ê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰ë  ë•Œ, ë™ì¼í•œ `cleaned_logs`ì™€ `processed_logs` ìƒíƒœë¥¼ ì°¸ì¡°í•˜ê±°ë‚˜ ë°˜í™˜í•˜ê²Œ ë˜ë¯€ë¡œ, ì´ ìƒíƒœë¥¼ ì•ˆì „í•˜ê²Œ ë³‘í•©í•˜ì§€ ì•Šìœ¼ë©´ ìƒíƒœ ì¶©ëŒì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>   + `cleaned_logs`: ë‘ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ì°¸ì¡°ë§Œ í•˜ë¯€ë¡œ ì‹¤ì œë¡œ ìˆ˜ì •ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‘ ì„œë¸Œê·¸ë˜í”„ê°€ ë³‘ë ¬ë¡œ ì‹¤í–‰ëœ í›„, ê°ê° **cleaned\_logsë¥¼ ë™ì¼í•œ í‚¤ë¡œ ë°˜í™˜**í•˜ë¯€ë¡œ, ìƒìœ„ ê·¸ë˜í”„ì—ì„œëŠ” ì´ë¥¼ ë³‘í•©í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë•Œ `add` ë¦¬ë“€ì„œê°€ ë³‘í•© ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤.
>   + `processed_logs`: ê° ì„œë¸Œê·¸ë˜í”„ì—ì„œ ìƒì„±í•œ ì²˜ë¦¬ ë¡œê·¸ ì •ë³´ë¥¼ ì¶”ê°€í•˜ë¯€ë¡œ, ë³‘ë ¬ ì‹¤í–‰ í›„ ê°ê°ì˜ ì²˜ë¦¬ ê²°ê³¼ê°€ ìƒìœ„ ê·¸ë˜í”„ì˜ **processed\_logsì— ëˆ„ì **ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ë•Œë„ `add` ë¦¬ë“€ì„œê°€ ìˆì–´ì•¼ ë³‘í•© ì¶©ëŒ ì—†ì´ ê°ê°ì˜ ê²°ê³¼ê°€ í•œ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ì•„ì§‘ë‹ˆë‹¤.

---

**4. ë¶€ëª¨ ê·¸ë˜í”„ (EntryGraph)**

* ì´ì œ `ë¶€ëª¨ ê·¸ë˜í”„`ì—ì„œëŠ” **ë‘ ì„œë¸Œê·¸ë˜í”„**ë¥¼ `ë³‘ë ¬ë¡œ ì‹¤í–‰`í•˜ê³  ê·¸ `ê²°ê³¼ë¥¼ ì¢…í•©`í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/8dc6ef61-dafe-45d0-9a96-ccc121debab6/image.png)

* (ì°¸ê³ ) `xray=0` ê°’ìœ¼ë¡œ ì£¼ì—ˆì„ ë•Œì˜ ì‹œê°í™” ê²°ê³¼

![](https://velog.velcdn.com/images/euisuk-chung/post/cd54f304-fad9-48d1-9f71-6f00ae82d092/image.png)

* `EntryGraphState`ëŠ” ë¶€ëª¨ ê·¸ë˜í”„ì—ì„œ ê´€ë¦¬í•  ì „ì²´ ìƒíƒœë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

```
class EntryGraphState(TypedDict):
    raw_logs: List[Log]                        # ì›ì‹œ ë¡œê·¸ ë°ì´í„°
    cleaned_logs: List[Log]                    # ì •ì œëœ ë¡œê·¸ (ë‘ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ì‚¬ìš©)
    fa_summary: str                            # ì‹¤íŒ¨ ë¶„ì„ ìš”ì•½ (FA ì„œë¸Œê·¸ë˜í”„ì—ì„œ ìƒì„±)
    report: str                                # ì§ˆë¬¸ ìš”ì•½ ë³´ê³ ì„œ (QS ì„œë¸Œê·¸ë˜í”„ì—ì„œ ìƒì„±)
    processed_logs: Annotated[List[int], add]  # ì²˜ë¦¬ëœ ë¡œê·¸ ëª©ë¡ (ë‘ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ìƒì„±)

```

* **fa\_summary**: Failure Analysis ì„œë¸Œê·¸ë˜í”„ì—ì„œ ìƒì„±ëœ ì‹¤íŒ¨ ë¶„ì„ ìš”ì•½.
* **report**: Question Summarization ì„œë¸Œê·¸ë˜í”„ì—ì„œ ìƒì„±ëœ ë³´ê³ ì„œ.
* **processed\_logs**: ë‘ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ê³µí†µìœ¼ë¡œ ìƒì„±ëœ ì²˜ë¦¬ëœ ë¡œê·¸ ëª©ë¡ì„ ë³‘í•©í•©ë‹ˆë‹¤.
* **cleaned\_logs**: ì›ì‹œ ë¡œê·¸ ë°ì´í„°ë¥¼ ì •ì œí•˜ì—¬ `cleaned_logs` ìƒíƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ ìƒíƒœëŠ” ë‘ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
  
  ```
  def cleaned_logs(state):
      # ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°
      raw_logs = state["raw_logs"]
      # raw_logs -> docs ë°ì´í„° ì •ì œ 
      cleaned_logs = raw_logs
      return {"cleaned_logs": cleaned_logs}
  
  ```

> ğŸ¤¦â€â™‚ï¸ **ì ê¹!! ì–´!? ì—¬ê¸° cleaned\_logsì—ëŠ” ë¦¬ë“€ì„œê°€ ì—†ëŠ”ë°ìš”?**
> 
> ```
> # ì§„ì… ê·¸ë˜í”„
> class EntryGraphState(TypedDict):
>     raw_logs: List[Log]
>     cleaned_logs: List[Log]
>     fa_summary: str # ì´ê²ƒì€ FA ì„œë¸Œ ê·¸ë˜í”„ì—ì„œë§Œ ìƒì„±ë©ë‹ˆë‹¤
>     report: str # ì´ê²ƒì€ QS ì„œë¸Œ ê·¸ë˜í”„ì—ì„œë§Œ ìƒì„±ë©ë‹ˆë‹¤
>     processed_logs: Annotated[List[int], add] # ì´ê²ƒì€ ë‘ ì„œë¸Œ ê·¸ë˜í”„ì—ì„œ ëª¨ë‘ ìƒì„±ë©ë‹ˆë‹¤
> ```
> 
> * ì´ê²ƒì€ íŠ¹ì´ ì¼€ì´ìŠ¤ë¡œ, ì•ì—ì„œ ê°ê° FailureAnalysisì™€ QuestionSummarizationì˜ `OutputState`(`FailureAnalysisOutputState`, `QuestionSummarizationOutputState`)ë¥¼ ì •ì˜í•˜ì—¬, clean\_logsë¥¼ outputìœ¼ë¡œ ë³´ë‚´ì§€ ì•Šê³  processed\_logsë§Œ ë³´ë‚´ì£¼ê³  ìˆìŠµë‹ˆë‹¤.  
>   
>   ![](https://velog.velcdn.com/images/euisuk-chung/post/10343da6-fa87-4598-aef4-8b1f6ff54319/image.png)
> * ì´ì— `processed_logs: Annotated[List[int], add]`ë§Œ ë³„ë„ë¡œ ë¦¬ë“€ì„œ ì²˜ë¦¬í•´ì¤€ ê²ƒì´ë¼ê³  í•©ë‹ˆë‹¤.

---

**5. ì„œë¸Œê·¸ë˜í”„ì˜ í†µí•© ë° ë³‘ë ¬ ì‹¤í–‰**

ë‘ ì„œë¸Œê·¸ë˜í”„ëŠ” `clean_logs`ê°€ ì™„ë£Œëœ í›„ ë³‘ë ¬ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. ì´ ë•Œ ë‘ ì„œë¸Œê·¸ë˜í”„ëŠ” **ê°™ì€ cleaned\_logs ìƒíƒœ**ë¥¼ ì°¸ì¡°í•˜ì§€ë§Œ ìˆ˜ì •í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.

```
entry_builder.add_node("cleaned_logs", cleaned_logs)
entry_builder.add_node("question_summarization", qs_builder.compile())
entry_builder.add_node("failure_analysis", fa_builder.compile())

entry_builder.add_edge("cleaned_logs", "failure_analysis")
entry_builder.add_edge("cleaned_logs", "question_summarization")
entry_builder.add_edge("failure_analysis", END)
entry_builder.add_edge("question_summarization", END)

graph = entry_builder.compile()
```

* **`cleaned_logs`**: ë¶€ëª¨ ê·¸ë˜í”„ì—ì„œ ì›ì‹œ ë¡œê·¸ ë°ì´í„°ë¥¼ ì •ì œí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
* **`question_summarization`**: Question Summarization ì„œë¸Œê·¸ë˜í”„ë¥¼ ë¶€ëª¨ ê·¸ë˜í”„ì— ì¶”ê°€í•©ë‹ˆë‹¤.
* **`failure_analysis`**: Failure Analysis ì„œë¸Œê·¸ë˜í”„ë¥¼ ë¶€ëª¨ ê·¸ë˜í”„ì— ì¶”ê°€í•©ë‹ˆë‹¤.

---

**6. ì‹¤í–‰ ì˜ˆì œ**

* ë”ë¯¸ ë¡œê·¸ ì˜ˆì‹œ:

```
# ë”ë¯¸ ë¡œê·¸
question_answer = Log(
    id="1",
    question="ChatOllamaë¥¼ ì–´ë–»ê²Œ ì„í¬íŠ¸í•  ìˆ˜ ìˆë‚˜ìš”?",
    answer="ChatOllamaë¥¼ ì„í¬íŠ¸í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‚¬ìš©í•˜ì„¸ìš”: 'from langchain_community.chat_models import ChatOllama.'",
)

question_answer_feedback = Log(
    id="2",
    question="Chroma ë²¡í„° ì €ì¥ì†Œë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?",
    answer="Chromaë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•˜ì„¸ìš”: rag_chain = create_retrieval_chain(retriever, question_answer_chain).",
    grade=0,
    grader="ë¬¸ì„œ ê´€ë ¨ì„± íšŒìƒ",
    feedback="ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì€ ë²¡í„° ì €ì¥ì†Œì— ëŒ€í•´ ì¼ë°˜ì ìœ¼ë¡œ ë…¼ì˜í•˜ì§€ë§Œ, Chromaì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ë£¨ì§€ ì•ŠìŠµë‹ˆë‹¤",
)
```

* ì˜ˆì‹œ-1:

```
raw_logs = [question_answer, question_answer_feedback]
graph.invoke({"raw_logs": [question_answer]})
```

* ì¶œë ¥ ê²°ê³¼-1:

```
{'raw_logs': [{'id': '1',
   'question': 'ChatOllamaë¥¼ ì–´ë–»ê²Œ ì„í¬íŠ¸í•  ìˆ˜ ìˆë‚˜ìš”?',
   'answer': "ChatOllamaë¥¼ ì„í¬íŠ¸í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‚¬ìš©í•˜ì„¸ìš”: 'from langchain_community.chat_models import ChatOllama.'"}],
   
 'cleaned_logs': [{'id': '1',
   'question': 'ChatOllamaë¥¼ ì–´ë–»ê²Œ ì„í¬íŠ¸í•  ìˆ˜ ìˆë‚˜ìš”?',
   'answer': "ChatOllamaë¥¼ ì„í¬íŠ¸í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‚¬ìš©í•˜ì„¸ìš”: 'from langchain_community.chat_models import ChatOllama.'"}],
   
 'fa_summary': 'Chroma ë¬¸ì„œì˜ ê²€ìƒ‰ í’ˆì§ˆì´ ë‚®ìŒ.',
 'report': 'foo bar baz',
 'processed_logs': ['summary-on-log-1']}
```

* ì˜ˆì‹œ-2:

```
ans = graph.invoke({"raw_logs":  [question_answer_feedback]})
ans
```

* ì¶œë ¥ ê²°ê³¼-2:

```
{'raw_logs': [{'id': '2',
   'question': 'Chroma ë²¡í„° ì €ì¥ì†Œë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?',
   'answer': 'Chromaë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•˜ì„¸ìš”: rag_chain = create_retrieval_chain(retriever, question_answer_chain).',
   'grade': 0,
   'grader': 'ë¬¸ì„œ ê´€ë ¨ì„± íšŒìƒ',
   'feedback': 'ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì€ ë²¡í„° ì €ì¥ì†Œì— ëŒ€í•´ ì¼ë°˜ì ìœ¼ë¡œ ë…¼ì˜í•˜ì§€ë§Œ, Chromaì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ë£¨ì§€ ì•ŠìŠµë‹ˆë‹¤'}],
   
 'cleaned_logs': [{'id': '2',
   'question': 'Chroma ë²¡í„° ì €ì¥ì†Œë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?',
   'answer': 'Chromaë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•˜ì„¸ìš”: rag_chain = create_retrieval_chain(retriever, question_answer_chain).',
   'grade': 0,
   'grader': 'ë¬¸ì„œ ê´€ë ¨ì„± íšŒìƒ',
   'feedback': 'ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì€ ë²¡í„° ì €ì¥ì†Œì— ëŒ€í•´ ì¼ë°˜ì ìœ¼ë¡œ ë…¼ì˜í•˜ì§€ë§Œ, Chromaì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ë£¨ì§€ ì•ŠìŠµë‹ˆë‹¤'}],
   
 'fa_summary': 'Chroma ë¬¸ì„œì˜ ê²€ìƒ‰ í’ˆì§ˆì´ ë‚®ìŒ.',
 'report': 'foo bar baz',
 'processed_logs': ['summary-on-log-2', 'failure-analysis-on-log-2']}
```
> ğŸ“‹ **ì˜ˆì œ íë¦„ ì •ë¦¬**
> 
> * 1. **ë¶€ëª¨ ê·¸ë˜í”„**ì—ì„œ `ì›ë³¸ ë¡œê·¸ ë°ì´í„°`ë¥¼ ì •ì œí•˜ì—¬ `cleaned_logs`ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
>   + ì˜ˆì œì—ì„œëŠ” ì´ë¥¼ ìœ„í•´ "ë”ë¯¸ ë¡œê·¸"ë¥¼ ìƒì„± í›„ ë„£ì–´ì£¼ê³  ìˆìŠµë‹ˆë‹¤
> * 2. `cleaned_logs`ëŠ” **Failure Analysis ì„œë¸Œê·¸ë˜í”„**ì™€ **Question Summarization ì„œë¸Œê·¸ë˜í”„**ì— ì „ë‹¬ë©ë‹ˆë‹¤.
>   + **Failure Analysis ì„œë¸Œê·¸ë˜í”„**ëŠ” ì‹¤íŒ¨í•œ ë¡œê·¸(question\_answer\_feedback)ë¥¼ ì‹ë³„í•˜ê³ , ê·¸ ê²°ê³¼ë¡œ ì‹¤íŒ¨ ìš”ì•½(fa\_summary)ì„ ìƒì„±í•©ë‹ˆë‹¤.
>   + **Question Summarization ì„œë¸Œê·¸ë˜í”„**ëŠ” ì§ˆë¬¸ ë¡œê·¸(question\_answer)ë¥¼ ìš”ì•½í•˜ê³ , ê·¸ ê²°ê³¼ë¡œ ë³´ê³ ì„œ(report)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
> * 3. ë‘ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ì²˜ë¦¬ëœ ë¡œê·¸ ì •ë³´ëŠ” `processed_logs`ì— ê¸°ë¡ë©ë‹ˆë‹¤.
> * 4. ìµœì¢… ê²°ê³¼ë¡œ, ê° ì„œë¸Œê·¸ë˜í”„ì˜ ê²°ê³¼(`fa_summary`ì™€ `report`)ì™€ ì²˜ë¦¬ëœ ë¡œê·¸ ëª©ë¡ì´ ì¶œë ¥ë©ë‹ˆë‹¤.

---

Lesson 3: Map-reduce
--------------------

### ê°œìš”

**MapReduce**ëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë‘ ê°€ì§€ ê¸°ë³¸ ë‹¨ê³„ì¸ **Map** ë‹¨ê³„ì™€ **Reduce** ë‹¨ê³„ë¡œ ë‚˜ë‰˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ ê° ë‹¨ê³„ì˜ í•µì‹¬ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

* **Map ë‹¨ê³„**: ì£¼ì–´ì§„ ì‘ì—…ì„ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ ì‘ì—…ìœ¼ë¡œ ë¶„í• í•˜ê³  ì´ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ì—¬ ì¤‘ê°„ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
* **Reduce ë‹¨ê³„**: Map ë‹¨ê³„ì˜ ì¤‘ê°„ ê²°ê³¼ë“¤ì„ í•˜ë‚˜ë¡œ í†µí•©í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.

### ì£¼ìš” ê°œë…

**LangGraphì—ì„œì˜ Map ë‹¨ê³„ êµ¬í˜„**

* ì˜ˆì œì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ìˆœì„œë¡œ **Map ë‹¨ê³„ë¥¼ êµ¬í˜„**í•©ë‹ˆë‹¤:
  
  1. **ì£¼ì œ ìƒì„±**:
     
     + ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ì‚¬ìš©ìê°€ ì œê³µí•œ ì£¼ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ LangGraphê°€ ì—¬ëŸ¬ ê°œì˜ ê´€ë ¨ **ì£¼ì œ(subject)**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
     + ì´ ê³¼ì •ì€ LangGraphì˜ `send` APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ê°œì˜ `generate joke` ë…¸ë“œë¡œ í™•ì¥ë©ë‹ˆë‹¤.
     + ì´ë•Œ ê° ì£¼ì œë³„ë¡œ LangGraphê°€ ë³„ë„ì˜ ë…¸ë“œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ë³‘ë ¬ì ìœ¼ë¡œ jokeì„ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤.
  2. **joke ìƒì„±**:
     
     + ê° ì£¼ì œì— ëŒ€í•´ LangGraphëŠ” `generate joke` ë…¸ë“œì—ì„œ í•´ë‹¹ ì£¼ì œì— ë§ëŠ” jokeì„ ìƒì„±í•©ë‹ˆë‹¤.
     + ì´ ë…¸ë“œëŠ” ì…ë ¥ìœ¼ë¡œ ì£¼ì œë¥¼ ë°›ê³ , í•´ë‹¹ ì£¼ì œì— ë§ëŠ” jokeì„ ìƒì„±í•˜ì—¬ ê²°ê³¼ë¥¼ **jokes ë¦¬ìŠ¤íŠ¸**ì— ì¶”ê°€í•©ë‹ˆë‹¤.
     + LangGraphì˜ **add reducer** ê¸°ëŠ¥ì„ í†µí•´ ìƒì„±ëœ jokeë“¤ì´ í•˜ë‚˜ì˜ jokes ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©ë©ë‹ˆë‹¤.

**LangGraphì—ì„œì˜ Reduce ë‹¨ê³„ êµ¬í˜„**

* **Reduce ë‹¨ê³„**ì—ì„œëŠ” ìƒì„±ëœ ëª¨ë“  joke ì¤‘ì—ì„œ ê°€ì¥ ìš°ìˆ˜í•œ ê²ƒì„ ì„ íƒí•©ë‹ˆë‹¤. ì£¼ìš” ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
  
  1. **ìµœê³ ì˜ joke ì„ íƒ**:
     + ëª¨ë“  jokeì´ jokes ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ë˜ë©´, LangGraphëŠ” í•´ë‹¹ ë¦¬ìŠ¤íŠ¸ë¥¼ í•œ ë¬¸ìì—´ë¡œ í•©ì³ **best joke prompt**ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
     + ëª¨ë¸ì€ ì „ì²´ joke ë¦¬ìŠ¤íŠ¸ë¥¼ í‰ê°€í•˜ê³ , ê°€ì¥ ì¬ë¯¸ìˆëŠ” jokeì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
     + ë°˜í™˜ëœ ì¸ë±ìŠ¤ëŠ” best jokeë¡œì„œ ìµœì¢… ê²°ê³¼ì— í¬í•¨ë©ë‹ˆë‹¤.

### ì½”ë“œ ì˜ˆì‹œ

1. **LLM ë° State ì •ì˜**
   * ë†ë‹´ ìƒì„± ë° ì„ íƒì„ ìœ„í•œ `LLMì„ ì •ì˜`í•©ë‹ˆë‹¤.
   * ê·¸ë˜í”„ì˜ `ì§„ì…ì ì„ ì •ì˜`í•©ë‹ˆë‹¤. ì´ ì§„ì…ì ì€:
     + ì‚¬ìš©ì ì…ë ¥ ì£¼ì œ(topic)ë¥¼ ë°›ìŠµë‹ˆë‹¤
     + ê·¸ë¡œë¶€í„° ë†ë‹´ ì£¼ì œ ëª©ë¡(subject)ì„ ìƒì„±í•©ë‹ˆë‹¤
     + ê° ë†ë‹´ ì£¼ì œë¥¼ ìœ„ì˜ ë†ë‹´ ìƒì„± ë…¸ë“œë¡œ ë³´ëƒ…ë‹ˆë‹¤
   * ì´ë•Œ ìƒì„±ëœ ë†ë‹´ì„ ë¦¬ë“€ì„œë¡œ ì €ì¥í•´ë‘˜ `jokes` í‚¤ ì •ì˜

```
from langchain_openai import ChatOpenAI

# ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸
# subjects_prompt = """ë‹¤ìŒ ì „ì²´ ì£¼ì œì™€ ê´€ë ¨ëœ 3ê°œì˜ sub-topics ëª©ë¡ì„ ìƒì„±í•˜ì„¸ìš”: {topic}."""
# joke_prompt = """{subject}ì— ëŒ€í•œ ë†ë‹´ì„ ìƒì„±í•˜ì„¸ìš”"""
# best_joke_prompt = """ì•„ë˜ëŠ” {topic}ì— ëŒ€í•œ ì—¬ëŸ¬ ë†ë‹´ì…ë‹ˆë‹¤. ê°€ì¥ ì¢‹ì€ ê²ƒì„ ì„ íƒí•˜ì„¸ìš”! ê°€ì¥ ì¢‹ì€ ë†ë‹´ì˜ IDë¥¼ ë°˜í™˜í•˜ì„¸ìš”, ì²« ë²ˆì§¸ ë†ë‹´ì˜ IDëŠ” 0ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤. ë†ë‹´ë“¤: \n\n {jokes}"""

subjects_prompt = """Generate a list of 3 sub-topics that are all related to this overall topic: {topic}."""
joke_prompt = """Generate a joke about {subject}"""
best_joke_prompt = """Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one, starting 0 as the ID for the first joke. Jokes: \n\n  {jokes}"""

# LLM
model = ChatOpenAI(model="gpt-4", temperature=0)
joke_model = ChatOpenAI(model="gpt-4", temperature=1.0)
```
```
import operator
from typing import Annotated
from typing_extensions import TypedDict
from pydantic import BaseModel

class Subjects(BaseModel):
    subjects: list[str]

class BestJoke(BaseModel):
    id: int
    
class OverallState(TypedDict):
    topic: str
    subjects: list
    jokes: Annotated[list, operator.add]
    best_selected_joke: str

```

* **ì½”ë“œ ì„¤ëª…**
  
  + **Subjects**: í•˜ìœ„ ì£¼ì œë“¤ì„ í¬í•¨í•˜ëŠ” êµ¬ì¡°ì²´ë¡œ, ê° ì£¼ì œë³„ë¡œ `joke`ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ `Map` ë‹¨ê³„ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.
  + **BestJoke**: ê°€ì¥ ì¬ë¯¸ìˆëŠ” `joke`ì˜ ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•˜ì—¬, `Reduce` ë‹¨ê³„ì—ì„œ ìµœìƒì˜ jokeë¥¼ ì„ íƒí•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
  + **OverallState**: ì „ì²´ `MapReduce` ê³¼ì •ì˜ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” êµ¬ì¡°ì²´ë¡œ, ì£¼ì–´ì§„ ì£¼ì œì—ì„œ `í•˜ìœ„ ì£¼ì œ`, `ìƒì„±ëœ joke ë¦¬ìŠ¤íŠ¸`, `ìµœì¢… ì„ íƒëœ joke`ê¹Œì§€ì˜ ëª¨ë“  ìƒíƒœë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

2. **ì£¼ì œì— ëŒ€í•œ í•˜ìœ„ ì‘ì—… ìƒì„± (Map ì´ì „ ë‹¨ê³„)** - `generate_topics` í•¨ìˆ˜

![](https://velog.velcdn.com/images/euisuk-chung/post/0cb90c26-ac44-474b-a117-00f9594583fa/image.png)

* **ì—­í• **: `generate_topics` í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ì£¼ì œ(`topic`)ì— ëŒ€í•´ ê´€ë ¨ ìˆëŠ” í•˜ìœ„ ì£¼ì œ ëª©ë¡ì„ ìƒì„±í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
  
  ```
  def generate_topics(state: OverallState):
      prompt = subjects_prompt.format(topic=state["topic"])
      response = model.with_structured_output(Subjects).invoke(prompt)
      return {"subjects": response.subjects}
  
  ```
  + **ë™ì‘**:
    
    - `subjects_prompt`ë¥¼ í†µí•´ ì‚¬ìš©ìê°€ ì œê³µí•œ ì£¼ìš” ì£¼ì œ(`topic`)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LangChain ëª¨ë¸ì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    - `model.with_structured_output(Subjects).invoke(prompt)`ë¥¼ ì‚¬ìš©í•˜ì—¬ LangChain ëª¨ë¸ì—ì„œ `Subjects` ìŠ¤í‚¤ë§ˆì— ë§ëŠ” ì‘ë‹µ(ë¦¬ìŠ¤íŠ¸, ì•„ë˜ ì°¸ê³ )ì„ ìƒì„±í•˜ë„ë¡ ì§€ì •í•©ë‹ˆë‹¤.
    ```
    
    class Subjects(BaseModel):
        subjects: list[str]
    ```
    - ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì˜ ì‘ë‹µì€ `Subjects` ìŠ¤í‚¤ë§ˆì— ì •ì˜ëœ í˜•íƒœ(`subjects: list[str]`)ë¥¼ ê°€ì§€ë©°, ì •í™•í•œ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì£¼ì œë“¤ì´ ë°˜í™˜ë©ë‹ˆë‹¤.
    - ë°˜í™˜ëœ ì£¼ì œ ëª©ë¡ì€ `subjects`ë¡œ ì €ì¥ë˜ì–´ ì´í›„ `Map` ë‹¨ê³„ì—ì„œ ê° ì£¼ì œì— ëŒ€í•œ joke ìƒì„± ì‘ì—…ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
  + **ìƒíƒœ**: í˜„ì¬ ìƒíƒœ(state)ëŠ” `subjects: list[str]`ì˜ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. langgraphì˜ Send APIë¥¼ ì‚¬ìš©í•˜ì—¬ continue\_to\_jokes í•¨ìˆ˜ì— ê°ê°ì˜ subjects ë¦¬ìŠ¤íŠ¸ ì›ì†Œë“¤ì„ ë„˜ê²¨ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    - ì°¸ê³  ë§í¬ : <https://langchain-ai.github.io/langgraph/concepts/low_level/#send>
* `Send`ì™€ `continue_to_jokes` í•¨ìˆ˜
  
  ```
  from langgraph.constants import Send
  
  def continue_to_jokes(state: OverallState):
      return [Send("generate_joke", {"subject": s}) for s in state["subjects"]]
  
  ```
  
  ![](https://velog.velcdn.com/images/euisuk-chung/post/05dea7ab-8421-4b66-81a3-1e158a23e160/image.png)
  
  + `Send`ëŠ” ê° ì£¼ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ `generate_joke` ë…¸ë“œë¡œ ì‘ì—…ì„ ì „ë‹¬í•˜ì—¬ ë³‘ë ¬ì ìœ¼ë¡œ jokeë¥¼ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤.
  + `continue_to_jokes`ëŠ” `generate_joke` ë…¸ë“œë¡œì˜ ì „ì†¡ì„ ì„¤ì •í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
  + **ë™ì‘**:
    
    - `state["subjects"]` ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° ì£¼ì œ `s`ì— ëŒ€í•´ `Send` ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    - `Send("generate_joke", {"subject": s})`ëŠ” `generate_joke` ë…¸ë“œì— `{ "subject": s }` í˜•íƒœë¡œ ìƒíƒœë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
      * ì´ ì „ë‹¬ë˜ëŠ” ìƒíƒœê°€ `OverallState`ì™€ ì¼ì¹˜í•  í•„ìš”ëŠ” ì—†ìœ¼ë©°, `generate_joke` ë…¸ë“œëŠ” ìì‹ ì˜ ìƒíƒœì— ë§ê²Œ ì´ ì •ë³´ë¥¼ í™œìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.
    - ê²°ê³¼ì ìœ¼ë¡œ `Send`ë¥¼ í†µí•´ ê° ì£¼ì œë¥¼ ë³‘ë ¬ë¡œ `generate_joke`ì— ì „ë‹¬í•˜ì—¬ ê° ì£¼ì œì— ëŒ€í•œ jokeë¥¼ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤.

3. **í•˜ìœ„ ì£¼ì œì— ëŒ€í•œ ë†ë‹´ ìƒì„± (Map ë‹¨ê³„)** - `generate_joke` í•¨ìˆ˜
   
   * **ì—­í• **: `generate_joke`ëŠ” ê° ì£¼ì œì— ëŒ€í•´ jokeë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ `OverallState`ì˜ `jokes` ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
     
     ```
     class JokeState(TypedDict):
         subject: str
     
     class Joke(BaseModel):
         joke: str
     
     def generate_joke(state: JokeState):
         prompt = joke_prompt.format(subject=state["subject"])
         response = model.with_structured_output(Joke).invoke(prompt)
         return {"jokes": [response.joke]}
     
     ```
   * **ë™ì‘**:
     
     + `state["subject"]` ê°’ì„ ì´ìš©í•´ `joke_prompt`ë¥¼ ì‘ì„±í•˜ê³ , ì´ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ LangChain ëª¨ë¸ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
     + `model.with_structured_output(Joke).invoke(prompt)`ë¥¼ ì‚¬ìš©í•˜ì—¬ `Joke` ìŠ¤í‚¤ë§ˆì— ë§ëŠ” ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ì§€ì •í•©ë‹ˆë‹¤.
       
       - ëª¨ë¸ì˜ ì‘ë‹µì€ `Joke` ìŠ¤í‚¤ë§ˆì— ì •ì˜ëœ í˜•íƒœ(`joke: str`)ë¡œ ë°˜í™˜ë˜ë©°, ì •í™•í•œ ë¬¸ìì—´ í˜•ì‹ì˜ jokeê°€ ìƒì„±ë©ë‹ˆë‹¤.
     + ë°˜í™˜ëœ jokeëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì ¸ `{ "jokes": [response.joke] }` í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤.
       
       - ì´ëŠ” `OverallState`ì˜ `jokes` í‚¤ì— ì¶”ê°€ë˜ë©°, ì—¬ê¸°ì„œ `jokes` í‚¤ëŠ” `add reducer`ë¥¼ í†µí•´ ë¦¬ìŠ¤íŠ¸ë¡œ ìë™ ì§‘ê³„ë©ë‹ˆë‹¤.
4. **ìµœê³ ì˜ ë†ë‹´ ì„ íƒ (Reduce ë‹¨ê³„)** - `best_joke` í•¨ìˆ˜
   
   * **ì—­í• **: `best_joke` í•¨ìˆ˜ëŠ” `OverallState`ì— ìˆëŠ” ì—¬ëŸ¬ ê°œì˜ joke ì¤‘ì—ì„œ ê°€ì¥ ì¬ë¯¸ìˆëŠ” jokeë¥¼ ì„ íƒí•˜ëŠ” ê¸°ëŠ¥ì„ í•©ë‹ˆë‹¤.
     
     ```
     # Reduce ë‹¨ê³„: ê°€ì¥ ì¬ë¯¸ìˆëŠ” ë†ë‹´ ì„ íƒ
     def best_joke(state: OverallState):
         jokes = "\n\n".join(state["jokes"])
         prompt = best_joke_prompt.format(topic=state["topic"], jokes=jokes)
         response = model.with_structured_output(BestJoke).invoke(prompt)
         return {"best_selected_joke": state["jokes"][response.id]}
     ```
   * **ë™ì‘**:
     
     + `state["jokes"]` ë¦¬ìŠ¤íŠ¸ì— ì €ì¥ëœ ëª¨ë“  jokeë¥¼ `\n\n`ë¡œ êµ¬ë¶„í•˜ì—¬ **í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©**í•©ë‹ˆë‹¤.
     + `best_joke_prompt`ë¥¼ ì‚¬ìš©í•˜ì—¬ **ì£¼ì–´ì§„ topicê³¼ ê²°í•©ëœ joke ë¦¬ìŠ¤íŠ¸ë¥¼ LangChain ëª¨ë¸ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ì„±**í•©ë‹ˆë‹¤.
     + `with_structured_output(BestJoke).invoke(prompt)`ë¥¼ í˜¸ì¶œí•˜ì—¬ LangChain ëª¨ë¸ì´ `BestJoke ìŠ¤í‚¤ë§ˆ`ì— ë§ëŠ” ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤.
       - ì´ ëª¨ë¸ì€ ê°€ì¥ ì¬ë¯¸ìˆëŠ” `jokeì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜`í•˜ë©°, `response.idì— í•´ë‹¹ ì¸ë±ìŠ¤ê°€ ì €ì¥`ë©ë‹ˆë‹¤.
     + ìµœì¢…ì ìœ¼ë¡œ `state["jokes"][response.id]`ì— í•´ë‹¹í•˜ëŠ” jokeë¥¼ `best_selected_joke` í‚¤ì— **ì €ì¥í•˜ì—¬ ë°˜í™˜**í•©ë‹ˆë‹¤.
5. **StateGraph êµ¬ì„± ë° ì»´íŒŒì¼ ë‹¨ê³„**
   
   * **ì—­í• **: `StateGraph`ëŠ” ì „ì²´ MapReduce íë¦„ì„ í•œ ê·¸ë˜í”„ ë‚´ì—ì„œ êµ¬ì„±í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
     
     ```
     from IPython.display import Image
     from langgraph.graph import END, StateGraph, START
     
     # ê·¸ë˜í”„ êµ¬ì„±
     graph = StateGraph(OverallState)
     graph.add_node("generate_topics", generate_topics)
     graph.add_node("generate_joke", generate_joke)
     graph.add_node("best_joke", best_joke)
     graph.add_edge(START, "generate_topics")
     graph.add_conditional_edges("generate_topics", continue_to_jokes, ["generate_joke"])
     graph.add_edge("generate_joke", "best_joke")
     graph.add_edge("best_joke", END)
     ```
   * **ë™ì‘**:
     
     + `OverallState`ë¥¼ ìƒíƒœë¡œ ì‚¬ìš©í•˜ëŠ” `StateGraph ê°ì²´ë¥¼ ìƒì„±`í•©ë‹ˆë‹¤.
     + `generate_topics`, `generate_joke`, `best_joke` ë…¸ë“œë¥¼ ê°ê° ê·¸ë˜í”„ì— ì¶”ê°€í•˜ì—¬ ê° ì‘ì—… ë‹¨ê³„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
     + **ì‹œì‘ì (START)**ì—ì„œ `generate_topics` ë…¸ë“œë¡œ ì´ë™í•˜ë„ë¡ `add_edge` ë©”ì„œë“œë¡œ **ì—£ì§€ë¥¼ ì¶”ê°€**í•©ë‹ˆë‹¤.
     + `generate_topics` ë‹¨ê³„ ì´í›„ ê° ì£¼ì œì— ëŒ€í•´ `ì¡°ê±´ë¶€ ì—£ì§€(add_conditional_edges)`ë¥¼ ì¶”ê°€í•˜ì—¬ `generate_jokeë¡œ ì—°ê²°`ë˜ë„ë¡ í•©ë‹ˆë‹¤.
     + ê° `generate_joke` ì‘ì—… ì´í›„ `best_joke ë‹¨ê³„ë¡œ ì—°ê²°`ë˜ë©°, `best_jokeì—ì„œ ìµœì¢… ê²°ê³¼ë¥¼ ìƒì„±`í•˜ì—¬ **ì¢…ë£Œì (END)**ìœ¼ë¡œ ì—°ê²°ë©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/e30949d3-26eb-4bef-b39d-87d86eeb8486/image.png)

**ì‹¤í–‰ ì˜ˆì œ**

* ì•„ë˜ì™€ ê°™ì´ `science`ë¼ëŠ” topicì„ ì£¼ë©´, LLMì´ ìœ ì‚¬ ì£¼ì œ 3ê°œë¥¼ ë§Œë“¤ê³ , ì´ì™€ ê´€ë ¨ëœ joke ìƒì„± í›„ best jokeë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
# ê·¸ë˜í”„ í˜¸ì¶œ: ì—¬ê¸°ì„œ ë†ë‹´ ëª©ë¡ì„ ìƒì„±í•˜ê¸° ìœ„í•´ í˜¸ì¶œí•©ë‹ˆë‹¤
for s in app.stream({"topic": "science"}):
    print(s)
```
```
Generated Subjects: ['Physics', 'Biology', 'Chemistry']

{'generate_topics': {'subjects': ['Physics', 'Biology', 'Chemistry']}}

{'generate_joke': {
         'jokes': ["Why did the biologist look forward to casual Fridays? Because they're allowed to wear genes to work!"]}}
{'generate_joke': {
         'jokes': ["Why can't you trust an atom? Because they make up everything!"]}}
{'generate_joke': {
         'jokes': ["Why do chemists like nitrates so much? Because they're cheaper than day rates!"]}}
         
{'best_joke': {'best_selected_joke': "Why can't you trust an atom? Because they make up everything!"}}
```

![](https://velog.velcdn.com/images/euisuk-chung/post/fd5300b2-a1ff-49b0-86e4-498b9afeb215/image.png)

---

Lesson 4: Research Assistant
----------------------------

### ê°œìš”

**Research Assistant** ì‹œìŠ¤í…œì€ ì—¬ëŸ¬ AI ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°êµ¬ ì‘ì—…ì„ ìë™í™”í•˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤. ì£¼ì œì— ë”°ë¼ ê° ì—ì´ì „íŠ¸ê°€ í•˜ìœ„ ì£¼ì œë¥¼ ë‹´ë‹¹í•˜ê³ , ì™¸ë¶€ ì†ŒìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•œ í›„ ê²°ê³¼ë¥¼ ë³‘í•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

### ì£¼ìš” ê°œë…

ì´ë²ˆ ì±•í„°ì˜ ëª©í‘œëŠ” ì±„íŒ… ëª¨ë¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ ê²½ëŸ‰ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì—¬ **ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ìµœì í™”**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

í•´ë‹¹ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì€ ì•„ë˜ ëª¨ë“ˆë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

* `ì†ŒìŠ¤ ì„ íƒ`
  
  + ì‚¬ìš©ìëŠ” ì—°êµ¬ì— ì‚¬ìš©í•  ì…ë ¥ ì†ŒìŠ¤ ì„¸íŠ¸ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* `ê³„íš`
  
  + ì‚¬ìš©ìê°€ ì£¼ì œë¥¼ ì œê³µí•˜ë©´ ì‹œìŠ¤í…œì€ AI ë¶„ì„ê°€ íŒ€ì„ ìƒì„±í•˜ê³ , ê° ë¶„ì„ê°€ëŠ” í•˜ë‚˜ì˜ í•˜ìœ„ ì£¼ì œì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
  + ì—°êµ¬ ì‹œì‘ ì „ì— ì´ëŸ¬í•œ í•˜ìœ„ ì£¼ì œë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ `Human-in-the-loop`ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.
* `LLM í™œìš©`
  
  + ê° ë¶„ì„ê°€ëŠ” ì„ íƒëœ ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ë¬¸ê°€ AIì™€ ì‹¬ì¸µ ì¸í„°ë·°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
  + ì¸í„°ë·°ëŠ” [STORM](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/storm/storm.ipynb) ë…¼ë¬¸ì—ì„œ ë³´ì—¬ì§„ ê²ƒì²˜ëŸ¼ ìƒì„¸í•œ í†µì°°ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë‹¤ì¤‘ í„´ ëŒ€í™”ê°€ ë  ê²ƒì…ë‹ˆë‹¤.
  + ì´ëŸ¬í•œ ì¸í„°ë·°ëŠ” ë‚´ë¶€ ìƒíƒœë¥¼ ê°€ì§„ `sub-graphs`ë¥¼ ì‚¬ìš©í•˜ì—¬ ìº¡ì²˜ë  ê²ƒì…ë‹ˆë‹¤.
* `ì—°êµ¬ í”„ë¡œì„¸ìŠ¤`
  
  + ì „ë¬¸ê°€ë“¤ì€ ë¶„ì„ê°€ì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ `parallel`ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
  + ëª¨ë“  ì¸í„°ë·°ëŠ” `map-reduce`ë¥¼ í†µí•´ ë™ì‹œì— ìˆ˜í–‰ë©ë‹ˆë‹¤.
* `ì¶œë ¥ í˜•ì‹`
  
  + ê° ì¸í„°ë·°ì—ì„œ ìˆ˜ì§‘ëœ í†µì°°ì€ ìµœì¢… ë³´ê³ ì„œë¡œ ì¢…í•©ë©ë‹ˆë‹¤.
  + ìš°ë¦¬ëŠ” ë³´ê³ ì„œì— ëŒ€í•´ ë§ì¶¤í™” ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ ì—°í•œ ì¶œë ¥ í˜•ì‹ì„ í—ˆìš©í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/f316778d-8c6a-40d6-97f8-9f6ecd137bba/image.png)

> ğŸŒªï¸ **"ìœ„í‚¤í”¼ë””ì•„ì™€ ìœ ì‚¬í•œ ê¸€ ì‘ì„±ì„ ìœ„í•œ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ì§€ì› ì‹œìŠ¤í…œ, STORM"**
> 
> * **ë…¼ë¬¸ ë§í¬** : <https://arxiv.org/pdf/2402.14207>
> * í•´ë‹¹ ë…¼ë¬¸ì€ **ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)**ì„ í™œìš©í•˜ì—¬ **ìœ„í‚¤í”¼ë””ì•„ ìˆ˜ì¤€ì˜ ì¥ë¬¸ ê¸€ ì‘ì„±**ì„ ì§€ì›í•˜ëŠ” `STORM ì‹œìŠ¤í…œ`ì„ ì†Œê°œí•©ë‹ˆë‹¤.  
>   
>   ![](https://velog.velcdn.com/images/euisuk-chung/post/ca7f92cf-226b-4c05-99fb-5c7f74ca2895/image.png)
> * STORMì€ ì‚¬ìš©ìê°€ ì œê³µí•œ ì£¼ì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ„í‚¤í”¼ë””ì•„ ìŠ¤íƒ€ì¼ì˜ ì•„í‹°í´ì„ ìƒì„±í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ ë³´ë‹¤ ì¡°ì§ì ì´ê³  í¬ê´„ì ì¸ ì•„í‹°í´ì„ ë§Œë“¤ê¸° ìœ„í•´ ë‹¤ìŒ ë‘ ê°€ì§€ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ë¥¼ í™œìš©í•©ë‹ˆë‹¤:
>   + **ìœ ì‚¬í•œ ì£¼ì œì— ëŒ€í•œ ì¿¼ë¦¬ë¥¼ í†µí•´ ê°œìš”ë¥¼ ìƒì„±**í•˜ëŠ” ê²ƒì´ ì£¼ì œì˜ í¬ê´„ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
>   + **ë‹¤ì–‘í•œ ê´€ì ì„ ë°˜ì˜í•˜ê³  ê²€ìƒ‰ì— ê¸°ë°˜í•œ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜**ì„ í†µí•´ ì°¸ì¡° ìë£Œì˜ ìˆ˜ì™€ ì •ë³´ ë°€ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
> * ìœ„ ê·¸ë¦¼ì€ ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ flow diagramì´ë©°, ì•„ë˜ ê·¸ë¦¼ì€ langchain ì¸¡ì—ì„œ ì¢€ ë” ë””í…Œì¼í•˜ê²Œ ê·¸ë¦° flow diagramì…ë‹ˆë‹¤.
> * **ìë£Œ ë§í¬** : <https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/storm/storm.ipynb>  
>   
>   ![](https://velog.velcdn.com/images/euisuk-chung/post/fb058bf1-85b9-460c-b2e7-94ec9c66051d/image.png)

> ğŸŒªï¸ **STORM** ë…¼ë¬¸ì—ì„œ ìˆ˜í–‰í•˜ëŠ” **ë‹¤ì¤‘ í„´ ëŒ€í™”(multi-turn conversation)**ëŠ” **ìœ„í‚¤í”¼ë””ì•„ ì‘ì„±ì**ì™€ **ì£¼ì œ ì „ë¬¸ê°€** ê°„ì˜ ê°€ìƒ ëŒ€í™”ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ì •ë³´ë¥¼ ì–»ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.
> 
> * ì´ ê³¼ì •ì—ì„œ STORMì€ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¥¼ ê±°ì¹©ë‹ˆë‹¤:
>   1. **ì§ˆë¬¸ ìƒì„±**: íŠ¹ì • ê´€ì ì„ ê°€ì§„ ìœ„í‚¤í”¼ë””ì•„ ì‘ì„±ìê°€ ì£¼ì œì— ëŒ€í•´ ì§ˆë¬¸ì„ ë˜ì§‘ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, â€œ2022ë…„ ë™ê³„ ì˜¬ë¦¼í”½ ê°œë§‰ì‹ì˜ êµí†µ ì¤€ë¹„ëŠ” ì–´ë–»ê²Œ ë˜ì—ˆëŠ”ê°€?â€ì™€ ê°™ì€ ì„¸ë¶€ì ì¸ ì§ˆë¬¸ì´ ìƒì„±ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœí•œ â€œë¬´ì—‡â€ì´ë‚˜ â€œì–¸ì œâ€ì™€ ê°™ì€ í‘œë©´ì ì¸ ì§ˆë¬¸ì—ì„œ ë²—ì–´ë‚˜, **ì£¼ì œì— ëŒ€í•œ ì‹¬ì¸µì ì¸ íƒêµ¬ë¥¼ ìœ ë„**í•©ë‹ˆë‹¤.
>   2. **ì§ˆë¬¸ ì„¸ë¶„í™” ë° ê²€ìƒ‰**: ê° ì§ˆë¬¸ì€ ì„¸ë¶€ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ë¶„í• ë˜ê³ , **ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¸í„°ë„· ì¶œì²˜**ë¥¼ ì‚¬ìš©í•´ í•„ìš”í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ì—ì„œëŠ” ìœ„í‚¤í”¼ë””ì•„ì˜ ì‹ ë¢°ë„ ê¸°ì¤€ì— ë§ëŠ” ì¶œì²˜ë§Œ ì„ íƒí•˜ì—¬, ì •í™•í•œ ì •ë³´ë§Œì´ ë‹µë³€ì— ë°˜ì˜ë˜ë„ë¡ í•©ë‹ˆë‹¤.
>   3. **ëŒ€ë‹µ ìƒì„± ë° ëŒ€í™” ë°˜ë³µ**: ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ìƒì˜ ì „ë¬¸ê°€ê°€ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , ì´ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ìê°€ ìƒˆë¡œìš´ í›„ì† ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì²« ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì—ì„œ ì¶”ê°€ì ì¸ êµí†µ í¸ì˜ì— ê´€í•œ ì–¸ê¸‰ì´ ìˆë‹¤ë©´, ì‘ì„±ìëŠ” ì´ì™€ ê´€ë ¨ëœ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>   4. **ìë£Œ ì¶•ì  ë° êµ¬ì¡° í˜•ì„±**: ì—¬ëŸ¬ ë¼ìš´ë“œì— ê±¸ì¹œ ëŒ€í™”ê°€ ì§„í–‰ë˜ë©´ì„œ, STORMì€ ì£¼ì œì™€ ê´€ë ¨ëœ ê¹Šì´ ìˆëŠ” ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ë ‡ê²Œ ì–»ì–´ì§„ ì •ë³´ëŠ” ë‚˜ì¤‘ì— ì „ì²´ ë¬¸ì„œì˜ ê°œìš”ë¥¼ ì •ë¦¬í•˜ëŠ” ë° í™œìš©ë©ë‹ˆë‹¤.

### ì½”ë“œ ì˜ˆì‹œ

âœ”ï¸ **Generate Analysts: Human-In-The-Loop**

`Generate Analysts` ì„¹ì…˜ì—ì„œëŠ” LangGraphì˜ `Human-in-the-loop`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°êµ¬ ì£¼ì œì— ë§ëŠ” AI ë¶„ì„ê°€ë¥¼ ìƒì„±í•˜ê³  ì¸ê°„ì˜ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë¶„ì„ê°€ë¥¼ ê²€í† í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

* ì´ë¥¼ í†µí•´ ì—°êµ¬ ì£¼ì œë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ **ìµœì ì˜ ë¶„ì„ê°€ íŒ€**ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

**1. ê¸°ë³¸ ì½”ë“œ êµ¬ì„±**

ë¨¼ì € í•„ìš”í•œ ëª¨ë“ˆê³¼ ê¸°ë³¸ í´ë˜ìŠ¤ êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ë¶„ì„ê°€ëŠ” ì—°êµ¬ ì£¼ì œì™€ ì—­í• ì— ë”°ë¼ ê°ê¸° ë‹¤ë¥¸ í˜ë¥´ì†Œë‚˜ë¥¼ ê°€ì§€ë©°, ì´ í˜ë¥´ì†Œë‚˜ëŠ” ì£¼ì œì— ë§ëŠ” ì§ˆë¬¸ê³¼ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë° í™œìš©ë©ë‹ˆë‹¤.

1) Analyst í´ë˜ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ì˜

```
from typing import List
from pydantic import BaseModel, Field

class Analyst(BaseModel):
    affiliation: str = Field(
        description="ë¶„ì„ê°€ì˜ ì£¼ìš” ì†Œì†.",
    )
    name: str = Field(
        description="ë¶„ì„ê°€ì˜ ì´ë¦„."
    )
    role: str = Field(
        description="ì£¼ì œì™€ ê´€ë ¨ëœ ë¶„ì„ê°€ì˜ ì—­í• .",
    )
    description: str = Field(
        description="ë¶„ì„ê°€ì˜ ì´ˆì , ê´€ì‹¬ì‚¬, ë™ê¸°ì— ëŒ€í•œ ì„¤ëª….",
    )
    
    # í˜ë¥´ì†Œë‚˜ ì†ì„±: ë¶„ì„ê°€ì˜ ë°°ê²½ ë° ì—­í• ì„ ìš”ì•½í•œ í…ìŠ¤íŠ¸
    @property
    def persona(self) -> str:
        return f"ì´ë¦„: {self.name}\nì—­í• : {self.role}\nì†Œì†: {self.affiliation}\nì„¤ëª…: {self.description}\n"
```

* **Analyst í´ë˜ìŠ¤**: ë¶„ì„ê°€ì— ëŒ€í•œ ì£¼ìš” ì •ë³´ë¥¼ ë‹´ê³  ìˆìœ¼ë©°, `affiliation`, `name`, `role`, `description` ì†ì„±ì„ í¬í•¨í•©ë‹ˆë‹¤.
  + **affiliation**: ë¶„ì„ê°€ì˜ ì£¼ìš” ì†Œì†ì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ìì—´ì…ë‹ˆë‹¤.
  + **name**: ë¶„ì„ê°€ì˜ ì´ë¦„ì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ìì—´ì…ë‹ˆë‹¤.
  + **role**: ì£¼ì œì™€ ê´€ë ¨ëœ ë¶„ì„ê°€ì˜ ì—­í• ì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ìì—´ì…ë‹ˆë‹¤.
  + **description**: ë¶„ì„ê°€ì˜ ì´ˆì , ê´€ì‹¬ì‚¬, ë™ê¸°ì— ëŒ€í•œ ì„¤ëª…ì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ìì—´ì…ë‹ˆë‹¤.
* **persona ì†ì„±**: ë¶„ì„ê°€ì˜ ë°°ê²½ì„ ìš”ì•½í•˜ì—¬ í˜ë¥´ì†Œë‚˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
  + ì´ë¥¼ í†µí•´ ë¶„ì„ê°€ê°€ ìˆ˜í–‰í•  ì—­í• ì— ë§ëŠ” ìºë¦­í„°ë¥¼ ê°–ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  + personaëŠ” `@property` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•œ ë©”ì„œë“œì…ë‹ˆë‹¤. ì´ ë©”ì„œë“œëŠ” ë¶„ì„ê°€ì˜ ì •ë³´ë¥¼ ìš”ì•½ëœ ë¬¸ìì—´ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. í”„ë¡œí¼í‹°ë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨, ì´ ë©”ì„œë“œë¥¼ ì†ì„±ì²˜ëŸ¼ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤ (ì˜ˆ: `analyst.persona`).

2) Perspectives í´ë˜ìŠ¤ ì •ì˜

```
class Perspectives(BaseModel):
    analysts: List[Analyst] = Field(
        description="ë¶„ì„ê°€ë“¤ì˜ ì—­í• ê³¼ ì†Œì†ì„ í¬í•¨í•œ ì¢…í•©ì ì¸ ëª©ë¡.",
    )
```

* **Perspectives í´ë˜ìŠ¤**: ë¶„ì„ê°€ ì§‘í•© ë¦¬ìŠ¤íŠ¸ (`List[Analyst]`)

3) GenerateAnalystsState í´ë˜ìŠ¤ ì •ì˜

```
class GenerateAnalystsState(TypedDict):
    topic: str  # ì—°êµ¬ ì£¼ì œ
    max_analysts: int  # ìƒì„±í•  ë¶„ì„ê°€ ìˆ˜
    human_analyst_feedback: str  # ì¸ê°„ í”¼ë“œë°±
    analysts: List[Analyst]  # ë¶„ì„ê°€ ëª©ë¡
```

* **GenerateAnalystsState í´ë˜ìŠ¤**: ì£¼ì œì™€ ë¶„ì„ê°€ ìˆ˜, ì¸ê°„ í”¼ë“œë°± ë“±ì„ í¬í•¨í•˜ì—¬ ì—°êµ¬ ì£¼ì œì— ë§ëŠ” ë¶„ì„ê°€ íŒ€ì„ ì„¤ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
  + `GenerateAnalystsState` í´ë˜ìŠ¤ëŠ” ì£¼ì œì™€ ë¶„ì„ê°€ íŒ€ì„ ìƒì„±í•˜ê³  ì¸ê°„ì˜ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ì£¼ì–´ì§„ ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

4) ë¶„ì„ê°€ ìƒì„± ì§€ì¹¨ (Analyst Instructions) ì •ì˜

```
analyst_instructions = """ë‹¹ì‹ ì€ AI ë¶„ì„ê°€ í˜ë¥´ì†Œë‚˜ ì„¸íŠ¸ë¥¼ ë§Œë“œëŠ” ì„ë¬´ë¥¼ ë§¡ì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ ì£¼ì˜ ê¹Šê²Œ ë”°ë¥´ì„¸ìš”:

1. ë¨¼ì € ì—°êµ¬ ì£¼ì œë¥¼ ê²€í† í•˜ì„¸ìš”:
{topic}
        
2. ë¶„ì„ê°€ ìƒì„±ì„ ì•ˆë‚´í•˜ê¸° ìœ„í•´ ì„ íƒì ìœ¼ë¡œ ì œê³µëœ í¸ì§‘ í”¼ë“œë°±ì„ ê²€í† í•˜ì„¸ìš”:
{human_analyst_feedback}
    
3. ìœ„ì˜ ë¬¸ì„œ ë°/ë˜ëŠ” í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ í¥ë¯¸ë¡œìš´ ì£¼ì œë¥¼ ê²°ì •í•˜ì„¸ìš”.
                    
4. ìƒìœ„ {max_analysts}ê°œì˜ ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”.

5. ê° ì£¼ì œì— í•œ ëª…ì˜ ë¶„ì„ê°€ë¥¼ í• ë‹¹í•˜ì„¸ìš”.
"""
```

* **analyst\_instructions ì§€ì¹¨**: ì—°êµ¬ ì£¼ì œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ê°€ì˜ í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ì¼ë ¨ì˜ ë‹¨ê³„ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
  + ë¶„ì„ê°€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ì¸ `analyst_instructions`ëŠ” ì—°êµ¬ ì£¼ì œì™€ í”¼ë“œë°±ì„ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì •í•œ ë¶„ì„ê°€ë¥¼ ìƒì„±í•˜ëŠ” ì§€ì¹¨ì„ í¬í•¨í•©ë‹ˆë‹¤.
  + í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ í¥ë¯¸ë¡œìš´ ì£¼ì œë¥¼ ê²°ì •í•˜ê³ , ê°ê°ì˜ ì£¼ì œì— ë§ëŠ” ë¶„ì„ê°€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

5) create\_analysts í•¨ìˆ˜ ì •ì˜

```
def create_analysts(state: GenerateAnalystsState):
    topic = state['topic']
    max_analysts = state['max_analysts']
    human_analyst_feedback = state.get('human_analyst_feedback', '')
        
    # êµ¬ì¡°í™”ëœ ì¶œë ¥ ê°•ì œ
    structured_llm = llm.with_structured_output(Perspectives)

    # ì‹œìŠ¤í…œ ë©”ì‹œì§€
    system_message = analyst_instructions.format(topic=topic,
                                                 human_analyst_feedback=human_analyst_feedback, 
                                                 max_analysts=max_analysts)

    # ì§ˆë¬¸ ìƒì„±
    analysts = structured_llm.invoke(
                                 [SystemMessage(content=system_message)] 
                                 + 
                                 [HumanMessage(content="ë¶„ì„ê°€ ì§‘ë‹¨(set of analysts)ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")]
                                 )

    # ë¶„ì„ ëª©ë¡ì„ ìƒíƒœì— ê¸°ë¡
    return {"analysts": analysts.analysts}
```

* **create\_analysts í•¨ìˆ˜**: ì£¼ì–´ì§„ ìƒíƒœë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ê°€ë¥¼ ìƒì„±í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. `llm.invoke` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ ë¶„ì„ê°€ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
  + **structured\_llm**: `llm.with_structured_output(Perspectives)`ì„ í†µí•´ ë¶„ì„ê°€ì˜ ì¶œë ¥ í˜•ì‹ì„ êµ¬ì¡°í™”í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤. (*2 Perspective í´ë˜ìŠ¤* ì°¸ê³ )
  + **system\_message**: ì£¼ì œì™€ í”¼ë“œë°±ì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ê°€ì˜ í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ì…ë‹ˆë‹¤.
  + **invoke**: êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ ë¶„ì„ê°€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ë©°, ì´ ë¦¬ìŠ¤íŠ¸ëŠ” ìƒíƒœì— ê¸°ë¡ë©ë‹ˆë‹¤.

6-1) Human Feedback í•¨ìˆ˜ ì •ì˜

```
def human_feedback(state: GenerateAnalystsState):
    """ ì¤‘ë‹¨ë˜ì–´ì•¼ í•˜ëŠ” no-op ë…¸ë“œ """
    pass
```

* **human\_feedback**: ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” í”¼ë“œë°±ì„ ë°˜ì˜í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. í”¼ë“œë°±ì„ ì£¼ê³ ë°›ëŠ” ê³¼ì •ì„ ìœ„í•´ ì„ì‹œ ì¤‘ë‹¨ ìƒíƒœë¥¼ ì œê³µí•©ë‹ˆë‹¤.
  + ìƒì„±ëœ ë¶„ì„ê°€ì— ëŒ€í•œ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ê¸° ìœ„í•´ `human_feedback` í•¨ìˆ˜ì™€ `should_continue` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
  + í”¼ë“œë°±ì´ ìˆì„ ê²½ìš°, `create_analysts` í•¨ìˆ˜ê°€ ë‹¤ì‹œ í˜¸ì¶œë˜ì–´ í”¼ë“œë°±ì— ë§ëŠ” ìƒˆë¡œìš´ ë¶„ì„ê°€ê°€ ìƒì„±ë©ë‹ˆë‹¤.
  + `should_continue` í•¨ìˆ˜ëŠ” ì•„ë˜ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.

6-2) should\_continue í•¨ìˆ˜ ì •ì˜

```
def should_continue(state: GenerateAnalystsState):
    # ì¸ê°„ í”¼ë“œë°± í™•ì¸
    human_analyst_feedback = state.get('human_analyst_feedback', None)
    if human_analyst_feedback:
        return "create_analysts"
    return END
```

* **should\_continue**: í”¼ë“œë°±ì´ ìˆë‹¤ë©´ `create_analysts`ë¡œ ëŒì•„ê°€ ë¶„ì„ê°€ë¥¼ ë‹¤ì‹œ ìƒì„±í•˜ë©°, ì—†ë‹¤ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤.

> (ì¶”ê°€) **ì‘ë™ë°©ì‹ ë¶€ì—° ì„¤ëª…**
> 
> * LangGraphì—ì„œ ë¶„ì„ê°€ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì • ì¤‘, human\_feedback ë…¸ë“œê°€ ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ì¤‘ë‹¨ ì§€ì ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ í•¨ìˆ˜ê°€ í˜¸ì¶œë˜ëŠ” ë™ì•ˆ ì‚¬ìš©ìëŠ” ìƒì„±ëœ ë¶„ì„ê°€ ëª©ë¡ì„ ë³´ê³ , í•„ìš”í•œ ê²½ìš° í”¼ë“œë°±ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> * ì´í›„, ì‚¬ìš©ìì˜ í”¼ë“œë°±ì´ should\_continue í•¨ìˆ˜ë¥¼ í†µí•´ í™•ì¸ë˜ê³ , í”¼ë“œë°±ì´ ìˆëŠ” ê²½ìš° ë¶„ì„ê°€ ìƒì„± ë‹¨ê³„(create\_analysts)ë¡œ ë‹¤ì‹œ ëŒì•„ê°€ í”¼ë“œë°±ì„ ë°˜ì˜í•œ ìƒˆë¡œìš´ ë¶„ì„ê°€ê°€ ìƒì„±ë©ë‹ˆë‹¤.

6-3) Graph ì„ ì–¸

```
from langgraph.graph import START, END, StateGraph
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

builder = StateGraph(GenerateAnalystsState)
builder.add_node("create_analysts", create_analysts)
builder.add_node("human_feedback", human_feedback)
builder.add_edge(START, "create_analysts")
builder.add_edge("create_analysts", "human_feedback")
builder.add_conditional_edges("human_feedback", should_continue, ["create_analysts", END])

# ì»´íŒŒì¼
memory = MemorySaver()
graph = builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)

# ë³´ê¸°
display(Image(graph.get_graph(xray=1).draw_mermaid_png()))
```

* ì´ì œ `StateGraph` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì¶”ê°€í•˜ê³  ì „ì²´ì ì¸ íë¦„ì„ ì„¤ì •í•©ë‹ˆë‹¤.
  + **builder**: ê·¸ë˜í”„ ë¹Œë”ë¥¼ ì„¤ì •í•˜ê³  ê° ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
  + **add\_node**: `create_analysts` ë° `human_feedback` ë…¸ë“œë¥¼ ì¶”ê°€í•˜ì—¬ ë¶„ì„ê°€ ìƒì„±ê³¼ í”¼ë“œë°±ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
  + **add\_edge**: ì‹œì‘ê³¼ ì¢…ë£Œ ë…¸ë“œë¥¼ ì—°ê²°í•˜ë©°, í”¼ë“œë°±ì´ ìˆì„ ê²½ìš° ë¶„ì„ê°€ë¥¼ ìƒì„±í•˜ëŠ” ë…¸ë“œë¡œ ëŒì•„ê°€ë„ë¡ í•©ë‹ˆë‹¤.
  + **MemorySaver**: ì‹¤í–‰ ìƒíƒœë¥¼ ì €ì¥í•˜ì—¬ í•„ìš”í•  ë•Œ ë³µì›í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
  + **display**: ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•˜ì—¬ êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/d2178bcb-b153-49d9-86be-11c443898d8a/image.png)

> (ì¤‘ê°„ ì ê²€) **ê·¸ëŸ¼ ì´ì œ ì˜ ë§Œë“¤ì–´ì¡Œë‚˜ í™•ì¸í•´ë´ì•¼ê² ì£ ?**
> 
> * ì•„ë˜ì™€ ê°™ì´ `LLMOps ì†”ë£¨ì…˜ ì œì‘`ì´ë¼ëŠ” ì£¼ì œë¡œ ì „ë¬¸ê°€ë“¤ì„ 3ëª… ê³ ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.
> 
> ```
> # ì…ë ¥
> max_analysts = 3
> topic = "LLMOps ì†”ë£¨ì…˜ ì œì‘"
> thread = {"configurable": {"thread_id": "1"}}
> # ì²« ë²ˆì§¸ ì¤‘ë‹¨ê¹Œì§€ ê·¸ë˜í”„ ì‹¤í–‰
> for event in graph.stream({"topic":topic,"max_analysts":max_analysts,}, thread, stream_mode="values"):
>     # ê²€í† 
>     analysts = event.get('analysts', '')
>     if analysts:
>         for analyst in analysts:
>             print(f"ì´ë¦„: {analyst.name}")
>             print(f"ì†Œì†: {analyst.affiliation}")
>             print(f"ì—­í• : {analyst.role}")
>             print(f"ì„¤ëª…: {analyst.description}")
>             print("-" * 50)  
> ```

> (ê²°ê³¼ í™•ì¸) **ì‹¤ì œë¡œ ì „ë¬¸ê°€ë“¤ì´ ì œëŒ€ë¡œ ìƒì„±ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤**
> 
> * `Lead Research Scientist`, `Data Engineer`, `AI Ethics Consultant` ì§ì±…ìœ¼ë¡œ ê³„ì‹  ë¶„ë“¤ì„ ë§Œë“¤ì–´ëƒˆêµ°ìš”.
> 
> ```
> ì´ë¦„: Dr. Emily Carter
> ì†Œì†: Tech Innovators Inc.
> ì—­í• : Lead Research Scientist
> ì„¤ëª…: Dr. Carter focuses on the development and optimization of LLMOps solutions, with a particular interest in scalability and efficiency.
> --------------------------------------------------
> ì´ë¦„: Michael Thompson
> ì†Œì†: AI Solutions Ltd.
> ì—­í• : Data Engineer
> ì„¤ëª…: Michael specializes in data pipeline architecture and is passionate about integrating LLMOps solutions to streamline data processing workflows.
> --------------------------------------------------
> ì´ë¦„: Sophia Martinez
> ì†Œì†: FutureTech Analytics
> ì—­í• : AI Ethics Consultant
> ì„¤ëª…: Sophia is dedicated to ensuring that LLMOps solutions are developed and deployed ethically, with a focus on transparency and fairness.
> --------------------------------------------------
> ```

![](https://velog.velcdn.com/images/euisuk-chung/post/66d793a6-5194-443b-81f0-041cbea724ef/image.png)

ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•´ë³´ë©´ í˜„ì¬ `('human_feedback',)`ì´ì „ì—ì„œ ëŒ€ê¸° ì¤‘ì´ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
# ìƒíƒœ ê°€ì ¸ì˜¤ê³  ë‹¤ìŒ ë…¸ë“œ í™•ì¸
state = graph.get_state(thread)
state.next
```

ê·¸ë¦¬ê³  ë‚˜ì„œ ì•„ë˜ì™€ ê°™ì€ ì½”ë“œë¡œ `human_feedback`ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
# ì´ì œ human_feedback ë…¸ë“œì¸ ê²ƒì²˜ëŸ¼ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤
graph.update_state(thread, {"human_analyst_feedback": 
                            "ê¸°ì—…ê°€ì  ê´€ì ì„ ì¶”ê°€í•˜ê¸° ìœ„í•´ gen ai ë„¤ì´í‹°ë¸Œ ìŠ¤íƒ€íŠ¸ì—…ì˜ CEOë¥¼ ì¶”ê°€í•˜ì„¸ìš”"}, as_node="human_feedback")
```

ê·¸ëŸ¼ human\_feedback ë…¸ë“œë¥¼ í†µí•´ ì´ì œ ë‹¤ì‹œ create\_analyst ë…¸ë“œë¡œ ë„˜ì–´ê°€ì„œ ì¶”ê°€ì ìœ¼ë¡œ analystë¥¼ ë§Œë“œëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/4485ce78-1525-4a8c-b067-cc144aa64062/image.png)

ìœ„ ê·¸ë¦¼ì„ ê¸€ë¡œ ì •ë¦¬í•˜ìë©´,

1. ì²« ë²ˆì§¸ `create_analysts` í˜¸ì¶œ:
   
   * ì£¼ì œì— ë§ëŠ” ë¶„ì„ê°€ 3ëª…ì„ ìƒì„±í•˜ì—¬ `analysts` ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
   * ì´ ë¦¬ìŠ¤íŠ¸ëŠ” **state**ì— ì €ì¥ë©ë‹ˆë‹¤.
2. `human_feedback`ë¥¼ í†µí•œ í”¼ë“œë°± ë°˜ì˜:
   
   * `human_feedback` ë…¸ë“œì—ì„œ í”¼ë“œë°±ì„ ë°›ê³ , `create_analysts`ê°€ ì¬í˜¸ì¶œë©ë‹ˆë‹¤.
   * ì´ë•Œ, `state['analysts']`ì— ê¸°ì¡´ 3ëª…ì˜ ë¶„ì„ê°€ê°€ ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
   * ìƒˆë¡œìš´ 3ëª…ì´ ì¶”ê°€ë˜ë©´ì„œ ìµœì¢…ì ìœ¼ë¡œ 6ëª…ì˜ ë¶„ì„ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ìƒì„±ë©ë‹ˆë‹¤.

í˜„ì¬ ì¶œë ¥ì— ì§€ê¸ˆ 6ëª…ìœ¼ë¡œ ëœ¬ ì´ìœ ëŠ” MemorySaver()ê°€ checkpointerë¡œ ì‚¬ìš©ë˜ì—ˆê¸° ë•Œë¬¸ì— ì´ì „ ì‹¤í–‰ ìƒíƒœê°€ ë©”ëª¨ë¦¬ì— ì €ì¥ë˜ì—ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

* ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ create\_analystsê°€ ì¬í˜¸ì¶œë˜ë©´ì„œ ê¸°ì¡´ ë¶„ì„ê°€ ëª©ë¡(ì´ì „ì— í˜¸ì¶œëœ 3ëª…ì˜ ë¶„ì„ê°€)ì— ìƒˆë¡œìš´ ë¶„ì„ê°€ë“¤(ìƒˆë¡­ê²Œ ì´ë²ˆì— ì¶”ê°€ëœ 3ëª…ì˜ ì¶”ê°€ ë¶„ì„ê°€)ì´ ê³„ì† ì¶”ê°€ëœ ê²ƒì…ë‹ˆë‹¤(ì´ 6ëª…ì˜ ë¶„ì„ê°€).

í˜„ì¬ state ì •ë³´ë§Œ ë³´ë ¤ë©´ ì•„ë˜ì™€ ê°™ì´ ì½”ë“œë¥¼ ì¶œë ¥í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```
state = graph.get_state(thread)
# state.values

# í˜„ì¬ ìƒíƒœ ì¶œë ¥
print(f"ì£¼ì œ: {state.values['topic']}")
print(f"ìµœëŒ€ ë¶„ì„ê°€ ìˆ˜: {state.values['max_analysts']}")
print(f"í”¼ë“œë°±: {state.values['human_analyst_feedback']}")

print('======================')
print('      PRINT INFO ')
print('======================')

# analysts ëª©ë¡ ì¶œë ¥
analysts = state.values['analysts']
if analysts:
    for analyst in analysts:
        print(f"\nì´ë¦„: {analyst.name}")
        print(f"ì†Œì†: {analyst.affiliation}")
        print(f"ì—­í• : {analyst.role}")
        print(f"ì„¤ëª…: {analyst.description}")
        print("-" * 50)

```
```
ì£¼ì œ: LLMOps ì†”ë£¨ì…˜ ì œì‘
ìµœëŒ€ ë¶„ì„ê°€ ìˆ˜: 3
í”¼ë“œë°±: ê¸°ì—…ê°€ì  ê´€ì ì„ ì¶”ê°€í•˜ê¸° ìœ„í•´ gen ai ë„¤ì´í‹°ë¸Œ ìŠ¤íƒ€íŠ¸ì—…ì˜ CEOë¥¼ ì¶”ê°€í•˜ì„¸ìš”
======================
      PRINT INFO 
======================

ì´ë¦„: Dr. Emily Zhang
ì†Œì†: Tech Innovators Inc.
ì—­í• : AI Research Scientist
ì„¤ëª…: Dr. Zhang focuses on the development and optimization of large language models (LLMs). She is particularly interested in the technical challenges and innovations in LLMOps.
--------------------------------------------------

ì´ë¦„: Alex Kim
ì†Œì†: GenAI Startups
ì—­í• : CEO
ì„¤ëª…: Alex is the CEO of a GenAI-native startup. He brings an entrepreneurial perspective to the table, focusing on the business applications and market potential of LLMOps solutions.
--------------------------------------------------

ì´ë¦„: Priya Natarajan
ì†Œì†: Data Security Solutions
ì—­í• : Data Privacy Analyst
ì„¤ëª…: Priya specializes in data privacy and security. Her interest lies in ensuring that LLMOps solutions comply with data protection regulations and maintain user privacy.
--------------------------------------------------
```

ë”ì´ìƒ `human-in-the-loop` (íœ´ë¨¼-í”¼ë“œë°±)ì´ í•„ìš”ì—†ë‹¤ê³  íŒë‹¨ì´ ë˜ë©´ ì•„ë˜ì™€ ê°™ì´ `None`ì„ í”¼ë“œë°±ìœ¼ë¡œ ì œê³µí•˜ì—¬ ê·¸ë˜í”„ê°€ ì¢…ë£Œë  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

```
# ë§Œì¡±í•œë‹¤ë©´ í”¼ë“œë°± ì—†ìŒì„ ì œê³µ
further_feedack = None
graph.update_state(thread, {"human_analyst_feedback": 
                            further_feedack}, as_node="human_feedback")
```

ì´ë ‡ê²Œ ê·¸ë˜í”„ë¥¼ ëê¹Œì§€ ì‹¤í–‰ì´ ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì¶œë ¥ ê²°ê³¼: `()`)

```
# ê·¸ë˜í”„ ì‹¤í–‰ì„ ëê¹Œì§€ ê³„ì†í•©ë‹ˆë‹¤
for event in graph.stream(None, thread, stream_mode="updates"):
    print("--ë…¸ë“œ--")
    node_name = next(iter(event.keys()))
    print(node_name)

final_state = graph.get_state(thread)
analysts = final_state.values.get('analysts')

final_state.next
```

![](https://velog.velcdn.com/images/euisuk-chung/post/ed4db6da-3560-453f-819b-4cd2f58dc9d6/image.png)

ìµœì¢… ì„ ì • Analystë„ ìœ„ì—ì„œ 1ë²ˆì˜ í”¼ë“œë°±ì„ ê±°ì¹œ ë¶„ì„ê°€ë“¤ì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

![](https://velog.velcdn.com/images/euisuk-chung/post/1765ca54-e376-4e46-8442-8a6e52231e4d/image.png)

---

âœ”ï¸ **Conduct Interview: ì§ˆë¬¸ ìƒì„± ë° ì¸í„°ë·° ìˆ˜í–‰**

`Conduct Interview ë‹¨ê³„`ì—ì„œëŠ” ìƒì„±ëœ ë¶„ì„ê°€ê°€ ì „ë¬¸ê°€ AIì™€ ëŒ€í™”í•˜ë©° ì£¼ì œì— ëŒ€í•œ í†µì°°ì„ ì–»ê¸° ìœ„í•´ ì§ˆë¬¸ì„ ë˜ì§€ê³  ë‹µë³€ì„ ìˆ˜ì§‘í•˜ëŠ” ê³¼ì •ì„ ì§„í–‰í•©ë‹ˆë‹¤.

* ì´ ê³¼ì •ì€ ë¶„ì„ê°€ì˜ ì—­í• ì— ë”°ë¼ ì„¤ê³„ëœ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³ , ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜ì§‘í•œ ë’¤ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

```
import operator
from typing import  Annotated
from langgraph.graph import MessagesState
```

1. **`InterviewState` í´ë˜ìŠ¤**:
   
   * `MessagesState`ë¥¼ ìƒì†ë°›ì•„ ì¸í„°ë·° ëŒ€í™”ì—ì„œ í•„ìš”í•œ ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
     
     ```
     class InterviewState(MessagesState):
         max_num_turns: int # ëŒ€í™” í„´ ìˆ˜
         context: Annotated[list, operator.add] # ì†ŒìŠ¤ ë¬¸ì„œ
         analyst: Analyst # ì§ˆë¬¸í•˜ëŠ” ë¶„ì„ê°€
         interview: str # ì¸í„°ë·° ê¸°ë¡
         sections: list # Send() APIë¥¼ ìœ„í•´ ì™¸ë¶€ ìƒíƒœì—ì„œ ë³µì œí•˜ëŠ” ìµœì¢… í‚¤
     ```
   * ì´ í´ë˜ìŠ¤ëŠ” **ë¶„ì„ê°€(Analyst)**ì™€ **ì¸í„°ë·° ì§„í–‰ ê³¼ì •**ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì—¬ëŸ¬ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
     
     + `max_num_turns`: ì¸í„°ë·°ì˜ ìµœëŒ€ í„´ ìˆ˜ë¥¼ ì„¤ì •í•˜ì—¬, ì¸í„°ë·°ê°€ **ëª‡ ì°¨ë¡€ì˜ ì§ˆë¬¸-ì‘ë‹µ ìŒ ì´í›„ ì¢…ë£Œ**ë ì§€ ê²°ì •í•©ë‹ˆë‹¤.
     + `context`: **Annotated íƒ€ì…**ì„ ì‚¬ìš©í•˜ì—¬ ì†ŒìŠ¤ ë¬¸ì„œì˜ ëª©ë¡ì„ ì„¤ì •í•˜ê³ , `operator.add`ë¥¼ ì ìš©í•˜ì—¬ **ê° ì¸í„°ë·°ì—ì„œ ìˆ˜ì§‘ëœ ì†ŒìŠ¤ ë¬¸ì„œë¥¼ ì ì§„ì ìœ¼ë¡œ ëˆ„ì **í•©ë‹ˆë‹¤.
     + `analyst`: í˜„ì¬ ì§ˆë¬¸ì„ í•˜ëŠ” ë¶„ì„ê°€ë¥¼ ë‚˜íƒ€ë‚´ë©°, `Analyst` ê°ì²´ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤.
     + `interview`: ì¸í„°ë·° ë‚´ìš©ì„ ë¬¸ìì—´ë¡œ ì €ì¥í•˜ì—¬, **ëŒ€í™” ì „ì²´ì˜ ê¸°ë¡ì„ ë³´ì¡´**í•©ë‹ˆë‹¤.
     + `sections`: `Send()` APIì—ì„œ **ì™¸ë¶€ ìƒíƒœì™€ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” í‚¤**ì…ë‹ˆë‹¤.
2. **`SearchQuery` í´ë˜ìŠ¤**:
   
   * `search_query` ì†ì„±ë§Œì„ ê°€ì§€ëŠ” ê°„ë‹¨í•œ ë°ì´í„° ëª¨ë¸ë¡œ, ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë¬¸ìì—´ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
     
     ```
     class SearchQuery(BaseModel):
         search_query: str = Field(None, description="ê²€ìƒ‰ì„ ìœ„í•œ ì¿¼ë¦¬.")
     ```
   * `search_query`ëŠ” `Field` í•¨ìˆ˜ì™€ í•¨ê»˜ ì„¤ì •ë˜ì–´, **ê²€ìƒ‰ì–´ì˜ ìš©ë„ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ëª…**í•©ë‹ˆë‹¤.
     
     + **Field í•¨ìˆ˜**ë¥¼ í†µí•´ ê²€ìƒ‰ ì¿¼ë¦¬ì˜ ìš©ë„ë¥¼ ì„¤ëª…í•˜ì—¬ `search_query`ë¥¼ ëª…í™•í•˜ê²Œ ì§€ì •í•©ë‹ˆë‹¤.
     + **ê²€ìƒ‰ ê³¼ì •ì—ì„œ ë¶„ì„ê°€ì˜ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±**í•˜ì—¬ ì €ì¥í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
3. **`question_instructions` ì¿¼ë¦¬**:

* `question_instructions`ëŠ” ì¸í„°ë·°ë¥¼ ì§„í–‰í•˜ëŠ” **ë¶„ì„ê°€ê°€ ì „ë¬¸ê°€ì—ê²Œ í¥ë¯¸ë¡­ê³  êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ë˜ì§€ë„ë¡ ë•ëŠ” ê°€ì´ë“œë¼ì¸**ì…ë‹ˆë‹¤.
  + ì´ í”„ë¡¬í”„íŠ¸ëŠ” ë¶„ì„ê°€ê°€ ì¸í„°ë·°ì˜ ì´ˆì ê³¼ ëª©í‘œì— ë§ì¶° ëŒ€í™”ë¥¼ ì´ëŒì–´ë‚˜ê°€ë„ë¡ ìœ ë„í•˜ë©°, ì „ì²´ ì¸í„°ë·° ëŒ€í™”ì˜ ì§ˆê³¼ ë°©í–¥ì„±ì„ ìœ ì§€í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.

```
# ë¶„ì„ê°€ê°€ ì „ë¬¸ê°€ì—ê²Œ í¥ë¯¸ë¡­ê³  êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ë˜ì§€ë„ë¡ ë•ëŠ” ê°€ì´ë“œë¼ì¸
question_instructions = """

ë‹¹ì‹ ì€ íŠ¹ì • ì£¼ì œì— ëŒ€í•´ ì „ë¬¸ê°€ë¥¼ ì¸í„°ë·°í•˜ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤. 

ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì£¼ì œì™€ ê´€ë ¨ëœ í¥ë¯¸ë¡­ê³  êµ¬ì²´ì ì¸ í†µì°°ì„ ì–»ëŠ” ê²ƒì…ë‹ˆë‹¤.

  1. Interesting: ì‚¬ëŒë“¤ì´ ë†€ëê±°ë‚˜ ëœ»ë°–ì´ë¼ê³  ìƒê°í•  í†µì°°.
        
  2. Specific: ì¼ë°˜ë¡ ì„ í”¼í•˜ê³  ì „ë¬¸ê°€ì˜ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ëŠ” í†µì°°.

ë‹¤ìŒì€ ë‹¹ì‹ ì˜ topic of focusì™€ set of goalsì…ë‹ˆë‹¤: {goals}
        
ë‹¹ì‹ ì˜ í˜ë¥´ì†Œë‚˜ì— ë§ëŠ” ì´ë¦„ìœ¼ë¡œ ìì‹ ì„ ì†Œê°œí•˜ê³  ì§ˆë¬¸ì„ ì‹œì‘í•˜ì„¸ìš”.

ì£¼ì œì— ëŒ€í•œ ì´í•´ë¥¼ ì‹¬í™”í•˜ê³  êµ¬ì²´í™”í•˜ê¸° ìœ„í•´ ê³„ì†í•´ì„œ ì§ˆë¬¸í•˜ì„¸ìš”.
        
ì´í•´ê°€ ì¶©ë¶„í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´ "ë„ì›€ ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤!"ë¼ê³  ë§í•˜ë©° ì¸í„°ë·°ë¥¼ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.

ì œê³µëœ í˜ë¥´ì†Œë‚˜ì™€ ëª©í‘œë¥¼ ë°˜ì˜í•˜ë©° ì‘ë‹µ ì „ì²´ì— ê±¸ì³ ìºë¦­í„°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
"""
```

1) ì§ˆë¬¸ ìƒì„± (Generate Question)

ì´ ë‹¨ê³„ëŠ” ë¶„ì„ê°€ê°€ ì „ë¬¸ê°€ì—ê²Œ ì£¼ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì„ ë˜ì§ˆ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.

* ì§ˆë¬¸ ìƒì„±ì€ `generate_question` í•¨ìˆ˜ì—ì„œ ì´ë£¨ì–´ì§€ë©°, ì´ í•¨ìˆ˜ëŠ” ë¶„ì„ê°€ì˜ í˜ë¥´ì†Œë‚˜ì™€ ëª©í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ì§ˆë¬¸ì„ ë§Œë“­ë‹ˆë‹¤.

```
def generate_question(state: InterviewState):
    # ë¶„ì„ê°€ì™€ ì´ì „ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    analyst = state["analyst"]
    messages = state["messages"]
    
    # ë¶„ì„ê°€ì˜ ëª©í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ ìƒì„±
    system_message = question_instructions.format(goals=analyst.persona)
    question = llm.invoke([SystemMessage(content=system_message)] + messages)
    
    # ìƒì„±ëœ ì§ˆë¬¸ì„ ìƒíƒœì— ê¸°ë¡í•˜ì—¬ ë‹¤ìŒ í”„ë¡œì„¸ìŠ¤ë¡œ ì „ë‹¬
    return {"messages": [question]}
```

* **analyst**: ë¶„ì„ê°€ì˜ í˜ë¥´ì†Œë‚˜ ë° ëª©í‘œë¥¼ í¬í•¨í•œ ì¸ìŠ¤í„´ìŠ¤ë¡œ, ì—°êµ¬ ì£¼ì œì™€ ê´€ë ¨ëœ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë° í•„ìš”í•œ ì •ë³´ê°€ ë‹´ê¹ë‹ˆë‹¤.
* **question\_instructions**: ë¶„ì„ê°€ê°€ ì§ˆë¬¸ì„ í•  ë•Œ ë”°ë¼ì•¼ í•  ì§€ì¹¨ìœ¼ë¡œ, ì§ˆë¬¸ì´ í¥ë¯¸ë¡­ê³  êµ¬ì²´ì ì¸ í†µì°°ì„ ìœ ë„í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
  
  + (ì°¸ê³ ) `question_instructions`ì€ ë°”ë¡œ ìœ„ **`3. question_instructions ì¿¼ë¦¬`**ì—ì„œ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

* **question** = `llm.invoke` ë©”ì„œë“œëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì´ì „ ëŒ€í™” ë©”ì‹œì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
  + llm.invokeì— ë“¤ì–´ê°€ëŠ” ì¸ìëŠ” `[SystemMessage(content=system_message)] + messages`ë¡œ, ìœ„ì—ì„œ ì •ì˜í•œ question\_instructionsê³¼ messagesì…ë‹ˆë‹¤.
  + ì°¸ê³ ë¡œ, messagesëŠ” í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì¸í„°ë·° ëŒ€í™”ì˜ ì „ì²´ ë©”ì‹œì§€ ê¸°ë¡ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ëŠ” ë¶„ì„ê°€ì™€ ì „ë¬¸ê°€ ê°„ì˜ ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ìˆœì„œëŒ€ë¡œ í¬í•¨ëœ ìƒíƒœì…ë‹ˆë‹¤.

2) ë³‘ë ¬ ë‹µë³€ ìˆ˜ì§‘ (Parallelized Answer Collection)

LangGraphì˜ ë³‘ë ¬í™” ê¸°ëŠ¥ì„ í™œìš©í•´ ì „ë¬¸ê°€ê°€ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.

* ë³¸ ì˜ˆì œì—ì„œëŠ” `tavily_search`ì™€ `search_wikipedia` í•¨ìˆ˜ë¥¼ í†µí•´ ê° ì†ŒìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

```
# ì›¹ ê²€ìƒ‰ ë„êµ¬
from langchain_community.tools.tavily_search import TavilySearchResults
tavily_search = TavilySearchResults(max_results=3)

# ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰ ë„êµ¬
from langchain_community.document_loaders import WikipediaLoader
```

**search\_instructions**

* `search_instructions`ëŠ” ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ë° í•„ìš”í•œ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.
  
  + ì´ í”„ë¡¬í”„íŠ¸ëŠ” íŠ¹ì •í•œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ êµ¬ì²´ì ì´ê³  ìœ ìš©í•œ ì¿¼ë¦¬ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.

```
# ê²€ìƒ‰ ì¿¼ë¦¬ ì‘ì„±
search_instructions = SystemMessage(content=f"""
ë¶„ì„ê°€ì™€ ì „ë¬¸ê°€ ì‚¬ì´ì˜ ëŒ€í™”ê°€ ì£¼ì–´ì§ˆ ê²ƒì…ë‹ˆë‹¤. 

ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ëŒ€í™”ì™€ ê´€ë ¨ëœ ê²€ìƒ‰ ë°/ë˜ëŠ” ì›¹ ê²€ìƒ‰ì— ì‚¬ìš©í•  ì˜ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        
ë¨¼ì € ì „ì²´ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

ë¶„ì„ê°€ê°€ ë§ˆì§€ë§‰ìœ¼ë¡œ ì œê¸°í•œ ì§ˆë¬¸ì— íŠ¹íˆ ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ì„¸ìš”.

ì´ ë§ˆì§€ë§‰ ì§ˆë¬¸ì„ ì˜ êµ¬ì¡°í™”ëœ ì›¹ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ì„¸ìš”
""")
```

**ì›¹ ê²€ìƒ‰** (`search_web`)

```
def search_web(state: InterviewState):
    """ ì›¹ ê²€ìƒ‰ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰ """
    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    structured_llm = llm.with_structured_output(SearchQuery)
    search_query = structured_llm.invoke([search_instructions] + state["messages"])
    
    # Tavily ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´
    search_docs = tavily_search.invoke(search_query.search_query)
    
    # í˜•ì‹ ì§€ì •ëœ ê²°ê³¼ ë°˜í™˜
    formatted_search_docs = "\n\n---\n\n".join(
        [f'<Document href="{doc["url"]}"/>\n{doc["content"]}\n</Document>' for doc in search_docs]
    )
    return {"context": [formatted_search_docs]} 
```

* **search\_query**: ë¶„ì„ê°€ì˜ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ì— ì í•©í•œ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
* **tavily\_search**: Tavily APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
  
  + ì´ ê²°ê³¼ëŠ” ì¶”í›„ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
* **formatted\_search\_docs**: ê²€ìƒ‰ ê²°ê³¼ë¥¼ HTML í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë³´ê³ ì„œ ì‘ì„± ì‹œ ì¶œì²˜ë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•©ë‹ˆë‹¤.

**ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰** (`search_wikipedia`)

```
def search_wikipedia(state: InterviewState):
    """ ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰ """
    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    structured_llm = llm.with_structured_output(SearchQuery)
    search_query = structured_llm.invoke([search_instructions] + state["messages"])
    
    # WikipediaLoaderë¡œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    search_docs = WikipediaLoader(query=search_query.search_query, load_max_docs=2).load()
    
    # í˜•ì‹ ì§€ì •ëœ ê²°ê³¼ ë°˜í™˜
    formatted_search_docs = "\n\n---\n\n".join(
        [f'<Document source="{doc.metadata["source"]}" page="{doc.metadata.get("page", "")}"/>\n{doc.page_content}\n</Document>' for doc in search_docs]
    )
    return {"context": [formatted_search_docs]} 
```

* **WikipediaLoader**: ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì—­í• ì„ í•˜ë©°, ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•´ ê´€ë ¨ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
* **formatted\_search\_docs**: ê²€ìƒ‰ ê²°ê³¼ë¥¼ HTML í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë³´ê³ ì„œ ì‘ì„± ì‹œ ì¶œì²˜ë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•©ë‹ˆë‹¤.

**answer\_instructions**

* `answer_instructions`ëŠ” ë¶„ì„ê°€ê°€ ì œì‹œí•œ ì§ˆë¬¸ì— ëŒ€í•´ ì „ë¬¸ê°€ê°€ ê´€ë ¨ ì •ë³´ë§Œì„ ì‚¬ìš©í•´ ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.
  
  + ì´ ê°€ì´ë“œë¼ì¸ì€ ë‹µë³€ì˜ ì¼ê´€ì„±ê³¼ ì •í™•ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

```
answer_instructions = """
ë‹¹ì‹ ì€ ë¶„ì„ê°€ì— ì˜í•´ ì¸í„°ë·°ë¥¼ ë°›ê³  ìˆëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒì€ ë¶„ì„ê°€ì˜ ê´€ì‹¬ ì˜ì—­ì…ë‹ˆë‹¤: 
{goals}. 
        
ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì¸í„°ë·°ì–´ê°€ ì œê¸°í•œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:        
{context}.

ì§ˆë¬¸ì— ëŒ€ë‹µí•  ë•Œ ì•„ë˜ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”:
  1. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì˜ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. 
        
  2. ì»¨í…ìŠ¤íŠ¸ì— ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì™¸ë¶€ ì •ë³´ë¥¼ ë„ì…í•˜ê±°ë‚˜ ê°€ì •í•˜ì§€ ë§ˆì„¸ìš”.

  3. ì»¨í…ìŠ¤íŠ¸ì—ëŠ” ê° ê°œë³„ ë¬¸ì„œ ìƒë‹¨ì— ì†ŒìŠ¤ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

  4. ê´€ë ¨ ì§„ìˆ  ì˜†ì— ì´ëŸ¬í•œ ì†ŒìŠ¤ë¥¼ ë‹µë³€ì— í¬í•¨í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, ì†ŒìŠ¤ #1ì˜ ê²½ìš° [1]ì„ ì‚¬ìš©í•˜ì„¸ìš”. 

  5. ë‹µë³€ í•˜ë‹¨ì— ì†ŒìŠ¤ë¥¼ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´í•˜ì„¸ìš”. [1] ì†ŒìŠ¤ 1, [2] ì†ŒìŠ¤ 2 ë“±
        
  6. ì†ŒìŠ¤ê°€ '<Document source="assistant/docs/llama3_1.pdf" page="7"/>'ì¸ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì—´í•˜ì„¸ìš”: 
        
  [1] assistant/docs/llama3_1.pdf, 7í˜ì´ì§€ 
        
  ì¸ìš© ì‹œ ê´„í˜¸ì™€ Document source ì „ë¬¸ì„ ìƒëµí•˜ì„¸ìš”.
"""
```

3. ë‹µë³€ ìƒì„± (Generate Answer)

ë¶„ì„ê°€ì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ ì›¹ ë° ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©í•´ ìƒì„±ë©ë‹ˆë‹¤.

* `generate_answer` í•¨ìˆ˜ëŠ” ë¬¸ë§¥(context)ê³¼ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì „ë¬¸ê°€ì˜ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

```
def generate_answer(state: InterviewState):
    # ë¶„ì„ê°€ì™€ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    analyst = state["analyst"]
    context = state["context"]
    
    # ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±
    system_message = answer_instructions.format(goals=analyst.persona, context=context)
    answer = llm.invoke([SystemMessage(content=system_message)] + state["messages"])
    answer.name = "expert"  # ì „ë¬¸ê°€ì˜ ì´ë¦„ ì§€ì •
    
    return {"messages": [answer]}
```

* **context**: ì´ì „ì— ìˆ˜ì§‘ëœ ê²€ìƒ‰ ê²°ê³¼ë“¤ì´ í¬í•¨ëœ ë¬¸ë§¥ ë°ì´í„°ë¡œ, ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì‘ì„±í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
* **answer\_instructions**: ì „ë¬¸ê°€ê°€ ì»¨í…ìŠ¤íŠ¸ì™€ ë¶„ì„ê°€ì˜ ëª©í‘œë¥¼ ë°˜ì˜í•˜ì—¬ ì •í™•í•˜ê³  ê´€ë ¨ ìˆëŠ” ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.
  
  + (ì°¸ê³ ) `answer_instructions`ì€ ìœ„ì—ì„œ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
* **answer.name**: ë‹µë³€ì„ ì „ë¬¸ê°€ë¡œë¶€í„° ì˜¨ ë©”ì‹œì§€ë¡œ ì§€ì •í•˜ì—¬ ì¸í„°ë·°ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

4. ì¸í„°ë·° ì €ì¥ ë° ìš”ì•½ (Save Interview)

ì¸í„°ë·°ê°€ ëë‚˜ë©´ ëª¨ë“  ë©”ì‹œì§€ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ëŠ” `save_interview` í•¨ìˆ˜ê°€ í˜¸ì¶œë©ë‹ˆë‹¤. ì´ ì¸í„°ë·° ê¸°ë¡ì€ ì´í›„ ìµœì¢… ë³´ê³ ì„œ ì‘ì„±ì— ì‚¬ìš©ë©ë‹ˆë‹¤.

```
def save_interview(state: InterviewState):
    # ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    messages = state["messages"]
    
    # ì¸í„°ë·° ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
    interview = get_buffer_string(messages)
    
    # ì¸í„°ë·° ë‚´ìš©ì„ ìƒíƒœì— ì €ì¥
    return {"interview": interview}
```

* **get\_buffer\_string**: ì¸í„°ë·° ëŒ€í™”ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì´í›„ ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

> ğŸ¤” **get\_buffer\_string**
> 
> * `get_buffer_string` í•¨ìˆ˜ëŠ” LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì¼ë¶€ì…ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ì´ í•¨ìˆ˜ëŠ” langchain\_core.messages.utils ëª¨ë“ˆì— ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> * **ëª©ì **: ì¼ë ¨ì˜ ë©”ì‹œì§€(Messages)ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì—°ê²°í•©ë‹ˆë‹¤
>   + ì˜ˆì œë¥¼ í†µí•´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.
>   ```
>   from langchain_core import AIMessage, HumanMessage
>   messages = [
>       HumanMessage(content="Hi, how are you?"),
>       AIMessage(content="Good, how are you?"),
>   ]
>   result = get_buffer_string(messages)
>   # ê²°ê³¼: "Human: Hi, how are you?\nAI: Good, how are you?"
>   ```
>   + ìœ„ì˜ ì˜ˆì œì™€ ê°™ì´ `get_buffer_string` í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ë©°, ê° ë©”ì‹œì§€ì— ëŒ€í•´ `prefix`ì™€ `content`ë¥¼ ê²°í•©í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.

5. ë¼ìš°íŒ… í•¨ìˆ˜ (Route Messages)

ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ì£¼ê³ ë°›ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°ìœ¨í•˜ê¸° ìœ„í•´ `route_messages` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

* ì´ í•¨ìˆ˜ëŠ” ì „ë¬¸ê°€ê°€ íŠ¹ì •í•œ ì‘ë‹µ ìˆ˜ì— ë„ë‹¬í–ˆê±°ë‚˜ ë¶„ì„ê°€ê°€ ëŒ€í™”ë¥¼ ë§ˆì¹˜ê³ ì í•˜ëŠ” ì‹ í˜¸(â€œë„ì›€ ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤â€)ë¥¼ ë³´ëƒˆì„ ë•Œ ì¸í„°ë·°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.

```
def route_messages(state: InterviewState, name: str = "expert"):
    # ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    messages = state["messages"]
    max_num_turns = state.get('max_num_turns', 2)
    
    # ì „ë¬¸ê°€ ì‘ë‹µ ìˆ˜ í™•ì¸
    num_responses = len(
        [m for m in messages if isinstance(m, AIMessage) and m.name == name]
    )
    
    # ì‘ë‹µì´ ìµœëŒ€ í„´ ìˆ˜ë¥¼ ì´ˆê³¼í–ˆê±°ë‚˜ ê°ì‚¬ ë©”ì‹œì§€ê°€ ìˆì„ ê²½ìš° ì¸í„°ë·° ì¢…ë£Œ
    if num_responses >= max_num_turns:
        return 'save_interview'
    
    last_question = messages[-2]  # ë§ˆì§€ë§‰ ì§ˆë¬¸ í™•ì¸
    if "ë„ì›€ ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤" in last_question.content:
        return 'save_interview'
    
    return "ask_question"
```

* `ì¢…ë£Œ ì¡°ê±´`:
  
  + **num\_responses**: ì „ë¬¸ê°€ì˜ ì‘ë‹µ íšŸìˆ˜ë¥¼ í™•ì¸í•˜ì—¬ ìµœëŒ€ ì‘ë‹µ ìˆ˜ì— ë„ë‹¬í•˜ë©´ ì¸í„°ë·°ë¥¼ ì¢…ë£Œí•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.
  + **last\_question**: ë¶„ì„ê°€ì˜ ë§ˆì§€ë§‰ ì§ˆë¬¸ì„ í™•ì¸í•˜ì—¬ ëŒ€í™” ì¢…ë£Œë¥¼ ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€ê°€ í¬í•¨ëœ ê²½ìš° ì¸í„°ë·°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.

6. write\_section í•¨ìˆ˜ 

**section\_writer\_instructions**

* `section_writer_instructions`ëŠ” **ì „ë¬¸ ê¸°ìˆ  ì‘ê°€ê°€ ë³´ê³ ì„œ ì„¹ì…˜ì„ ì‘ì„±í•˜ëŠ” ë° í•„ìš”í•œ ì„¸ë¶€ ì§€ì¹¨ì„ ì œê³µ**í•˜ì—¬, ì¸í„°ë·°ì—ì„œ ìˆ˜ì§‘í•œ í†µì°°ì„ ëª…í™•í•˜ê³  ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.
  
  + ì´ ê³¼ì •ì€ `Conduct Interview` ë‹¨ê³„ì—ì„œ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë³´ê³ ì„œì˜ ê° ì„¹ì…˜ì„ ì‘ì„±í•˜ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ì£¼ìš” ì§€ì¹¨ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```
section_writer_instructions = """
ë‹¹ì‹ ì€ ì „ë¬¸ ê¸°ìˆ  ì‘ê°€ì…ë‹ˆë‹¤. 
            
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì†ŒìŠ¤ ë¬¸ì„œ ì„¸íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œì˜ ì§§ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¹ì…˜ì„ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

1. ì†ŒìŠ¤ ë¬¸ì„œì˜ ë‚´ìš© ë¶„ì„: 
- ê° ì†ŒìŠ¤ ë¬¸ì„œì˜ ì´ë¦„ì€ <Document íƒœê·¸ì™€ í•¨ê»˜ ë¬¸ì„œ ì‹œì‘ ë¶€ë¶„ì— ìˆìŠµë‹ˆë‹¤.
        
2. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ë³´ê³ ì„œ êµ¬ì¡° ìƒì„±:
- ì„¹ì…˜ ì œëª©ì—ëŠ” ## ì‚¬ìš©
- í•˜ìœ„ ì„¹ì…˜ í—¤ë”ì—ëŠ” ### ì‚¬ìš©
        
3. ë‹¤ìŒ êµ¬ì¡°ë¥¼ ë”°ë¼ ë³´ê³ ì„œ ì‘ì„±:
a. ì œëª© (## í—¤ë”)
b. ìš”ì•½ (### í—¤ë”)
c. ì¶œì²˜ (### í—¤ë”)

4. ë¶„ì„ê°€ì˜ ê´€ì‹¬ ì˜ì—­ì„ ë°”íƒ•ìœ¼ë¡œ í¥ë¯¸ë¡œìš´ ì œëª© ë§Œë“¤ê¸°: 
{focus}

5. ìš”ì•½ ì„¹ì…˜:
- ë¶„ì„ê°€ì˜ ê´€ì‹¬ ì˜ì—­ê³¼ ê´€ë ¨ëœ ì¼ë°˜ì ì¸ ë°°ê²½/ë§¥ë½ìœ¼ë¡œ ìš”ì•½ ì‹œì‘
- ì¸í„°ë·°ì—ì„œ ì–»ì€ í†µì°° ì¤‘ ìƒˆë¡­ê±°ë‚˜ í¥ë¯¸ë¡­ê±°ë‚˜ ë†€ë¼ìš´ ì  ê°•ì¡°
- ì‚¬ìš©í•œ ì†ŒìŠ¤ ë¬¸ì„œì˜ ë²ˆí˜¸ ëª©ë¡ ìƒì„±
- ì¸í„°ë·°ì–´ë‚˜ ì „ë¬¸ê°€ì˜ ì´ë¦„ ì–¸ê¸‰í•˜ì§€ ì•Šê¸°
- ìµœëŒ€ 400ë‹¨ì–´ë¥¼ ëª©í‘œë¡œ í•¨
- ì†ŒìŠ¤ ë¬¸ì„œì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œì— ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ì¶œì²˜ ì‚¬ìš© (ì˜ˆ: [1], [2])
        
6. ì¶œì²˜ ì„¹ì…˜:
- ë³´ê³ ì„œì— ì‚¬ìš©ëœ ëª¨ë“  ì¶œì²˜ í¬í•¨
- ê´€ë ¨ ì›¹ì‚¬ì´íŠ¸ë‚˜ íŠ¹ì • ë¬¸ì„œ ê²½ë¡œì˜ ì „ì²´ ë§í¬ ì œê³µ
- ê° ì¶œì²˜ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„. ê° ì¤„ ëì— ë‘ ê°œì˜ ê³µë°±ì„ ì‚¬ìš©í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ì—ì„œ ì¤„ë°”ê¿ˆ ìƒì„±.
- ë‹¤ìŒê³¼ ê°™ì´ ë³´ì¼ ê²ƒì…ë‹ˆë‹¤:

### ì¶œì²˜
[1] ë§í¬ ë˜ëŠ” ë¬¸ì„œ ì´ë¦„
[2] ë§í¬ ë˜ëŠ” ë¬¸ì„œ ì´ë¦„

7. ì¶œì²˜ë¥¼ ë°˜ë“œì‹œ ê²°í•©í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒì€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤:

[3] https://ai.meta.com/blog/meta-llama-3-1/
[4] https://ai.meta.com/blog/meta-llama-3-1/

ì¤‘ë³µëœ ì¶œì²˜ê°€ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ê°„ë‹¨íˆ í‘œì‹œí•´ì•¼ í•©ë‹ˆë‹¤:

[3] https://ai.meta.com/blog/meta-llama-3-1/
        
8. ìµœì¢… ê²€í† :
- ë³´ê³ ì„œê°€ í•„ìš”í•œ êµ¬ì¡°ë¥¼ ë”°ë¥´ëŠ”ì§€ í™•ì¸
- ë³´ê³ ì„œ ì œëª© ì „ì— ì„œë¬¸ì„ í¬í•¨í•˜ì§€ ì•ŠìŒ
- ëª¨ë“  ì§€ì¹¨ì„ ë”°ëëŠ”ì§€ í™•ì¸
"""
```

1. `write_section` í•¨ìˆ˜

```
def write_section(state: InterviewState):
    """ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë…¸ë“œ """

    # ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
    interview = state["interview"]
    context = state["context"]
    analyst = state["analyst"]
   
    # ì¸í„°ë·°ì—ì„œ ìˆ˜ì§‘í•œ ì†ŒìŠ¤ ë¬¸ì„œ(context) ë˜ëŠ” ì¸í„°ë·° ìì²´(interview)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¹ì…˜ ì‘ì„±
    system_message = section_writer_instructions.format(focus=analyst.description)
    
    section = llm.invoke(
    			[SystemMessage(content=system_message)]
                +
                [HumanMessage(content=f"ì´ ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¹ì…˜ì„ ì‘ì„±í•˜ì„¸ìš”: {context}")]) 
                
    # ìƒíƒœì— ì¶”ê°€
    return {"sections": [section.content]}
```

* **ëª©ì **: ì´ í•¨ìˆ˜ëŠ” `InterviewState`ì—ì„œ ìˆ˜ì§‘í•œ ì¸í„°ë·° ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œì˜ ê° ì„¹ì…˜ì„ ì‘ì„±í•©ë‹ˆë‹¤.
* **ìƒíƒœ ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°**:
  
  + `interview`: ì¸í„°ë·° ê¸°ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
  + `context`: ì¸í„°ë·°ì—ì„œ ìƒì„±ëœ ì†ŒìŠ¤ ë¬¸ì„œë‚˜ ì°¸ê³  ìë£Œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
  + `analyst`: ë¶„ì„ê°€ì˜ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ í•´ë‹¹ ë¶„ì„ê°€ê°€ ê°€ì§„ íŠ¹ì • ëª©í‘œ(`analyst.description`)ë¥¼ ì„¹ì…˜ ì‘ì„±ì— ë°˜ì˜í•©ë‹ˆë‹¤.
* **ì„¹ì…˜ ì‘ì„±**:
  
  + `section_writer_instructions`ì˜ `focus`ë¥¼ ë¶„ì„ê°€ì˜ ì„¤ëª…(`analyst.description`)ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
  + `section_writer_instructions`ëŠ” ë³´ê³ ì„œê°€ ì¼ê´€ì„± ìˆê²Œ ì‘ì„±ë˜ë„ë¡ ì§€ì¹¨ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
  + `SystemMessage`ëŠ” ì„¹ì…˜ ì‘ì„±ì„ ìœ„í•œ ì§€ì¹¨ì„ ì „ë‹¬í•˜ê³ , `HumanMessage`ëŠ” ìƒì„±ëœ `context`ë¥¼ í¬í•¨í•˜ì—¬ AI ëª¨ë¸ì— ì „ë‹¬í•©ë‹ˆë‹¤.
    - ì´ë¥¼ í†µí•´ ì¸í„°ë·° ë‚´ìš©ì„ ë°˜ì˜í•œ ì„¹ì…˜ì´ ìƒì„±ë©ë‹ˆë‹¤.
* **ì„¹ì…˜ ì¶”ê°€**:
  
  + `sections`ë¼ëŠ” í‚¤ì— í•´ë‹¹ ì„¹ì…˜ì„ ì¶”ê°€í•˜ì—¬ ìƒíƒœì— ë°˜í™˜í•©ë‹ˆë‹¤.
  + ì´ ì„¹ì…˜ì€ ë³´ê³ ì„œ ì‘ì„±ì˜ ìµœì¢… ë‹¨ê³„ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.

---

2. `StateGraph` ì •ì˜ ë° ë…¸ë“œ ì¶”ê°€

```
interview_builder = StateGraph(InterviewState)
interview_builder.add_node("ask_question", generate_question)
interview_builder.add_node("search_web", search_web)
interview_builder.add_node("search_wikipedia", search_wikipedia)
interview_builder.add_node("answer_question", generate_answer)
interview_builder.add_node("save_interview", save_interview)
interview_builder.add_node("write_section", write_section)
```

* **`StateGraph` ì •ì˜**: `InterviewState`ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒíƒœ ê·¸ë˜í”„ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì´ ê·¸ë˜í”„ëŠ” `write_section`ê¹Œì§€ ì´ì–´ì§€ëŠ” ì¸í„°ë·° í”„ë¡œì„¸ìŠ¤ì˜ ëª¨ë“  ë‹¨ê³„ë³„ ë…¸ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
* **ë…¸ë“œ ì¶”ê°€**: ê° ë‹¨ê³„ì˜ ì£¼ìš” ê¸°ëŠ¥ì„ ë‹´ë‹¹í•˜ëŠ” ë…¸ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
  + `ask_question`: ì¸í„°ë·° ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.
  + `search_web` ë° `search_wikipedia`: í•„ìš”í•œ ìë£Œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.
  + `answer_question`: ì „ë¬¸ê°€ì˜ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
  + `save_interview`: ì¸í„°ë·° ë‚´ìš©ì„ ì €ì¥í•©ë‹ˆë‹¤.
  + `write_section`: ì¸í„°ë·°ì˜ ìš”ì ì„ ì„¹ì…˜ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.

---

3. **ì¸í„°ë·° ë‹¨ê³„ì˜ íë¦„ ì •ì˜**

```
# íë¦„
interview_builder.add_edge(START, "ask_question")
interview_builder.add_edge("ask_question", "search_web")
interview_builder.add_edge("ask_question", "search_wikipedia")
interview_builder.add_edge("search_web", "answer_question")
interview_builder.add_edge("search_wikipedia", "answer_question")
interview_builder.add_conditional_edges("answer_question", route_messages, ['ask_question','save_interview'])
interview_builder.add_edge("save_interview", "write_section")
interview_builder.add_edge("write_section", END)
```

* **íë¦„ ì •ì˜**:
  + `START`ì—ì„œ `ask_question`ë¡œ ì—°ê²°í•˜ì—¬ ì¸í„°ë·° ì§ˆë¬¸ì„ ì‹œì‘í•©ë‹ˆë‹¤.
  + ì§ˆë¬¸ í›„ `search_web` ë˜ëŠ” `search_wikipedia`ë¡œ ì§„í–‰í•´ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
  + ê° ê²€ìƒ‰ ê²°ê³¼ëŠ” `answer_question` ë…¸ë“œë¡œ ì „ë‹¬ë˜ì–´ ì¸í„°ë·°ì˜ ë‹µë³€ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.
* **ì¡°ê±´ë¶€ ì—£ì§€**:
  + `answer_question`ì—ì„œ `route_messages`ë¥¼ í†µí•´ ëŒ€í™”ë¥¼ ê³„ì† ì§„í–‰í• ì§€(`ask_question`ìœ¼ë¡œ ëŒì•„ê°) ì•„ë‹ˆë©´ ì¸í„°ë·° ì €ì¥ ë‹¨ê³„(`save_interview`)ë¡œ ë„˜ì–´ê°ˆì§€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
* **ë§ˆì§€ë§‰ ë‹¨ê³„**:
  + ì¸í„°ë·°ê°€ ì €ì¥ë˜ë©´ `write_section`ìœ¼ë¡œ ë„˜ì–´ê°€ ë³´ê³ ì„œì˜ ì„¹ì…˜ì„ ì‘ì„±í•œ í›„ ì¢…ë£Œ(`END`)ë©ë‹ˆë‹¤.

---

4. **ê·¸ë˜í”„ ì»´íŒŒì¼ ë° ì¸í„°ë·° ì‹¤í–‰**

```
# ì¸í„°ë·° 
memory = MemorySaver()
interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name="ì¸í„°ë·° ìˆ˜í–‰")
```

* **`MemorySaver`**: ì¸í„°ë·° ì¤‘ê°„ ìƒíƒœë¥¼ ì €ì¥í•˜ì—¬, ì¸í„°ë·° ì§„í–‰ ì¤‘ì— ë°œìƒí•˜ëŠ” ìƒíƒœ ë³€í™”ë¥¼ ì²´í¬í¬ì¸íŠ¸ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.
* **ê·¸ë˜í”„ ì»´íŒŒì¼**: ì¸í„°ë·° ìˆ˜í–‰ì„ ìœ„í•´ ì „ì²´ ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•˜ë©°, ì´ë¥¼ `interview_graph`ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

---

5. **ê·¸ë˜í”„ ì‹œê°í™”**

```
# ë³´ê¸°
display(Image(interview_graph.get_graph().draw_mermaid_png()))
```

* **ê·¸ë˜í”„ ì‹œê°í™”**: `draw_mermaid_png()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒíƒœ ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•˜ì—¬ íë¦„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/33d2e0f7-7985-4c28-b903-6fd73245edce/image.png)

> (ì¤‘ê°„ì ê²€) ë¶„ì„ê°€ í•œëª…ì„ ì„ íƒí•´ì„œ ê¸€ ì‘ì„±ì„ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> 
> * í•œ ëª…ì„ ì„ íƒí•´ì„œ í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ê¸€ì„ ìš”ì²­í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.
> 
> ```
> # ë¶„ì„ê°€ í•œ ëª… ì„ íƒ
> analysts[0]
> ```
> ```
> Analyst(
> affiliation='Tech Innovators Inc.', 
> name='Dr. Emily Zhang', 
> role='AI Research Scientist', 
> description='Dr. Zhang focuses on the development and optimization of large language models (LLMs). Her interest lies in improving model efficiency and scalability.'
> )
> ```
> 
> * ê¸€ ì‘ì„± ìš”ì²­ í›„ ê²°ê³¼ë¥¼ í•œë²ˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.
> 
> ```
> from IPython.display import Markdown
> messages = [HumanMessage(f"ë‹¹ì‹ ì´ {topic}ì— ëŒ€í•œ ê¸€ì„ ì“°ê³  ìˆë‹¤ê³  í–ˆë‚˜ìš”?")]
> thread = {"configurable": {"thread_id": "1"}}
> interview = interview_graph.invoke({"analyst": analysts[0], "messages": messages, "max_num_turns": 3}, thread)
> Markdown(interview['sections'][0])
> ```
> 
> ![](https://velog.velcdn.com/images/euisuk-chung/post/b6b5ebe1-313e-4bff-a070-1387710d16ae/image.png)
> 
> * ì—„ì²­ ê·¸ëŸ´ ë“¯í•˜ê²Œ LLMOpsì— ëŒ€í•œ ê¸€ì„ ì‘ì„±í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì•ì— ì„¸ìš´ ë¼ìš°íŒ… ê·œì¹™ì— ì˜í•´ `max_num_turns` 3íšŒê¹Œì§€ ëŒê³ , ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
>   
>   ![](https://velog.velcdn.com/images/euisuk-chung/post/5d8ac37d-4089-42a4-a9bb-d9399f379009/image.png)

> (ê²°ê³¼í•´ì„) ì¶œë ¥ ê²°ê³¼ë¥¼ ì¢€ ë” ì„¸ë¶„í™”í•´ì„œ í•´ì„í•´ë³¼ê¹Œìš”?
> 
> * ì¶œë ¥ëœ ê²°ê³¼ë¥¼ ë³´ë©´, ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ì™€ ë¬¸ì„œ ê¸°ë°˜ ì„¹ì…˜ ì‘ì„±ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤.  
>   
>   ![](https://velog.velcdn.com/images/euisuk-chung/post/a879000e-2526-4c19-a11b-d3f2c02729f4/image.png)
> * êµ¬ì²´ì ìœ¼ë¡œ í™•ì¸í•´ë³´ë©´, ì£¼ìš” ì ˆì°¨ê°€ ë‹¤ìŒê³¼ ê°™ì´ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.
>   + **ëŒ€í™” ì§„í–‰**: ëŒ€í™” íë¦„ì´ `HumanMessage`ì™€ `AIMessage`ì˜ ë°˜ë³µìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤. ê° `HumanMessage`ì— ëŒ€í•´ `AIMessage`ê°€ ë…¼ë¦¬ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ê³  ìˆìœ¼ë©°, LLMOps ê´€ë ¨ ì£¼ìš” ê°œë…ê³¼ êµ¬í˜„ ë„ì „ ê³¼ì œë“¤ì´ ì„¤ëª…ë˜ì—ˆìŠµë‹ˆë‹¤.
> * **ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ í™œìš©**: `context`ë¡œ ì§€ì •ëœ ë¬¸ì„œë“¤ì´ `section_writer_instructions`ì— ë”°ë¼ ìš”ì•½ ë° ë¬¸ì„œ êµ¬ì„±ì„ ìœ„í•´ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. `write_section` í•¨ìˆ˜ì—ì„œ ë¬¸ì„œ ë‚´ìš©ì´ ì„¹ì…˜ì— ì ì ˆíˆ ë°˜ì˜ë˜ì–´, `LLMOps`ì˜ ì£¼ìš” ê°œë…ê³¼ ì ìš© ì‚¬ë¡€ ë° ëª¨ë²” ì‚¬ë¡€ê°€ í¬í•¨ëœ ìš”ì•½ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> * **ì„¹ì…˜ ì‘ì„±**: `sections` í•„ë“œì— ì €ì¥ëœ ë³´ê³ ì„œëŠ” `##`ì™€ `###` í˜•ì‹ì„ ì‚¬ìš©í•´ êµ¬ì¡°ì ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆê³ , ì¶œì²˜ ëª©ë¡ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ê° ì¶œì²˜ê°€ `[1]`, `[2]` ë“±ìœ¼ë¡œ ì œëŒ€ë¡œ ë§í¬ë˜ì—ˆìœ¼ë©°, ëª¨ë²” ì‚¬ë¡€ì™€ LLMOpsì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œë„ ìš”ì•½ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

ì´ì œ ê°ê°ì˜ Analystë“¤ì„ í‰í–‰í•˜ê²Œ ê·¸ë˜í”„ ìƒì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ë‹¤ìŒì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

âœ”ï¸ **Parallelize ì¸í„°ë·°: Map-Reduce íŒ¨í„´ ì ìš©**

ì´ êµ¬ì¡°ì—ì„œëŠ” ì¸í„°ë·°ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•˜ì—¬ ì‹œê°„ì„ ì ˆì•½í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ê¸° ìœ„í•´ ê²°ê³¼ë¥¼ ê²°í•©í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

* **ë§µ(Map) ë‹¨ê³„**:
  
  + `initiate_all_interviews` í•¨ìˆ˜ê°€ `Send()` APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ë¡œ ì¸í„°ë·°ë¥¼ ì‹¤í–‰í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
  + `Send()`ëŠ” ê° ë¶„ì„ê°€ì™€ ì „ë¬¸ê°€ ê°„ ì¸í„°ë·° ì„¸ì…˜ì„ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë©°, ê° ì¸í„°ë·°ê°€ ë³„ë„ë¡œ ì§„í–‰ë˜ê¸° ë•Œë¬¸ì— ì—¬ëŸ¬ ì¸í„°ë·°ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ì—¬ ì‹œê°„ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.
  + ì´ ë‹¨ê³„ì—ì„œëŠ” ê° ì¸í„°ë·°ì˜ ê²°ê³¼ê°€ `ResearchGraphState`ì— `sections` ë¦¬ìŠ¤íŠ¸ì— ì €ì¥ë©ë‹ˆë‹¤.
* **ë¦¬ë“€ìŠ¤(Reduce) ë‹¨ê³„**:
  
  + `write_report` í•¨ìˆ˜ëŠ” `sections` ë¦¬ìŠ¤íŠ¸ì— ì €ì¥ëœ ëª¨ë“  ì¸í„°ë·° ì„¸ì…˜ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œ ë‚´ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤.
  + ì´í›„ `write_introduction`ê³¼ `write_conclusion` í•¨ìˆ˜ê°€ ê°ê° ì„œë¡ ê³¼ ê²°ë¡ ì„ ì‘ì„±í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œì— í¬í•¨ë©ë‹ˆë‹¤.
  + ìµœì¢… ë‹¨ê³„ì¸ `finalize_report`ì—ì„œëŠ” ì„œë¡ , ë³¸ë¬¸, ê²°ë¡ ì„ í•˜ë‚˜ì˜ ì™„ì„±ëœ ë³´ê³ ì„œë¡œ í•©ì³ ë¦¬í¬íŠ¸ë¥¼ ì™„ì„±í•©ë‹ˆë‹¤.

1. ResearchGraphState í´ë˜ìŠ¤ ì •ì˜

* **ì—­í• **: ì—°êµ¬ ì£¼ì œ, ë¶„ì„ê°€ ìˆ˜, í”¼ë“œë°±, ë³´ê³ ì„œ ì„œë¡  ë° ê²°ë¡  ë“± ìƒíƒœ ì •ë³´ë¥¼ ì¶”ì í•˜ì—¬, ì „ì²´ ì‹¤í–‰ íë¦„ ì¤‘ ë°ì´í„°ë¥¼ ì‰½ê²Œ ê´€ë¦¬í•˜ê³  ì°¸ì¡°í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

```
import operator
from typing import List, Annotated
from typing_extensions import TypedDict

class ResearchGraphState(TypedDict):
    topic: str # ì—°êµ¬ ì£¼ì œ
    max_analysts: int # ë¶„ì„ê°€ ìˆ˜
    human_analyst_feedback: str # ì¸ê°„ í”¼ë“œë°±
    analysts: List[Analyst] # ì§ˆë¬¸í•˜ëŠ” ë¶„ì„ê°€
    sections: Annotated[list, operator.add] # Send() API í‚¤
    introduction: str # ìµœì¢… ë³´ê³ ì„œì˜ ì„œë¡ 
    content: str # ìµœì¢… ë³´ê³ ì„œì˜ ë‚´ìš©
    conclusion: str # ìµœì¢… ë³´ê³ ì„œì˜ ê²°ë¡ 
    final_report: str # ìµœì¢… ë³´ê³ ì„œ

```

* **TypedDict**ë¡œ ì§€ì •í•˜ì—¬ ìƒíƒœê°€ íŠ¹ì •í•œ í‚¤ì™€ ê°’ì„ ê°–ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤.
* **Annotated**ë¡œ ì—¬ëŸ¬ sectionsë¥¼ ì¶”ê°€í•  ë•Œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³‘í•©í•˜ì—¬ ì €ì¥í•˜ë„ë¡ í•©ë‹ˆë‹¤.

2. **initiate\_all\_interviews** í•¨ìˆ˜: ì¸í„°ë·° ë³‘ë ¬í™” ì‹¤í–‰

* **ì—­í• **: ì¸í„°ë·°ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•˜ëŠ” â€œë§µâ€ ë‹¨ê³„.

```
def initiate_all_interviews(state: ResearchGraphState):
    """ ì´ëŠ” Send APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì¸í„°ë·° ì„œë¸Œê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ëŠ” "ë§µ" ë‹¨ê³„ì…ë‹ˆë‹¤ """    

    # ì¸ê°„ í”¼ë“œë°± í™•ì¸
    human_analyst_feedback=state.get('human_analyst_feedback')
    if human_analyst_feedback:
        # create_analystsë¡œ ëŒì•„ê°€ê¸°
        return "create_analysts"

    # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Send() APIë¥¼ í†µí•´ ì¸í„°ë·°ë¥¼ ë³‘ë ¬ë¡œ ì‹œì‘
    else:
        topic = state["topic"]
        return [Send("conduct_interview", {"analyst": analyst,
                                           "messages": [HumanMessage(
                                               content=f"ë‹¹ì‹ ì´ {topic}ì— ëŒ€í•œ ê¸€ì„ ì“°ê³  ìˆë‹¤ê³  í–ˆë‚˜ìš”?"
                                           )
                                                       ]}) for analyst in state["analysts"]]
```

* `human_analyst_feedback`ì´ ìˆì„ ê²½ìš°, í”¼ë“œë°±ì„ ë°˜ì˜í•´ `create_analysts`ë¡œ ëŒì•„ê°€ ë¶„ì„ê°€ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
* í”¼ë“œë°±ì´ ì—†ìœ¼ë©´ `Send()` APIë¥¼ ì‚¬ìš©í•´ ì¸í„°ë·°ë¥¼ ê° ë¶„ì„ê°€ì™€ ë…ë¦½ì ìœ¼ë¡œ ë³‘ë ¬ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.

**report\_writer\_instructions**

* í•´ë‹¹ ì§€ì¹¨ì€ **ë¶„ì„ê°€ íŒ€ì´ ì œê³µí•œ ë©”ëª¨**ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë³´ê³ ì„œ ë³¸ë¬¸ì„ ì‘ì„±í•˜ëŠ” ë° í•„ìš”í•œ ì„¸ë¶€ì‚¬í•­ì„ ì•ˆë‚´**í•©ë‹ˆë‹¤.
  + ì´ ì§€ì¹¨ì€ ë³´ê³ ì„œ ì‘ì„±ìê°€ ì¼ê´€ì„± ìˆê³  ì¶œì²˜ê°€ ëª…í™•íˆ í‘œì‹œëœ ë³´ê³ ì„œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ë©°, ì œê³µëœ ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í†µì°°ë ¥ ìˆëŠ” ìš”ì•½ì„ ë§Œë“¤ë„ë¡ í•©ë‹ˆë‹¤.

```
report_writer_instructions = """

ë‹¹ì‹ ì€ ë‹¤ìŒ ì „ì²´ ì£¼ì œì— ëŒ€í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ê¸°ìˆ  ì‘ê°€ì…ë‹ˆë‹¤: 

{topic}
    
ë‹¹ì‹ ì—ê²ŒëŠ” ë¶„ì„ê°€ íŒ€ì´ ìˆìŠµë‹ˆë‹¤. ê° ë¶„ì„ê°€ëŠ” ë‘ ê°€ì§€ ì¼ì„ í–ˆìŠµë‹ˆë‹¤: 

1. íŠ¹ì • í•˜ìœ„ ì£¼ì œì— ëŒ€í•´ ì „ë¬¸ê°€ì™€ ì¸í„°ë·°ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.
2. ê·¸ë“¤ì˜ ë°œê²¬ì„ ë©”ëª¨ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ì„ë¬´: 

1. ë¶„ì„ê°€ë“¤ì˜ ë©”ëª¨ ëª¨ìŒì´ ì£¼ì–´ì§ˆ ê²ƒì…ë‹ˆë‹¤.
2. ê° ë©”ëª¨ì˜ í†µì°°ì„ ì‹ ì¤‘íˆ ìƒê°í•´ë³´ì„¸ìš”.
3. ëª¨ë“  ë©”ëª¨ì˜ ì¤‘ì‹¬ ì•„ì´ë””ì–´ë¥¼ í•˜ë‚˜ì˜ ê°„ê²°í•œ ì „ì²´ ìš”ì•½ìœ¼ë¡œ í†µí•©í•˜ì„¸ìš”. 
4. ê° ë©”ëª¨ì˜ ì¤‘ì‹¬ì ì„ í•˜ë‚˜ì˜ ì¼ê´€ëœ ë‚´ëŸ¬í‹°ë¸Œë¡œ ìš”ì•½í•˜ì„¸ìš”.

ë³´ê³ ì„œ í˜•ì‹:
 
1. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”. 
2. ë³´ê³ ì„œì— ì„œë¬¸ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
3. ì†Œì œëª©ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. 
4. ë‹¨ì¼ ì œëª© í—¤ë”ë¡œ ë³´ê³ ì„œë¥¼ ì‹œì‘í•˜ì„¸ìš”: ## í†µì°°
5. ë³´ê³ ì„œì— ë¶„ì„ê°€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
6. ë©”ëª¨ì— ìˆëŠ” ì¸ìš©ì„ ë³´ì¡´í•˜ì„¸ìš”. ì¸ìš©ì€ [1] ë˜ëŠ” [2]ì™€ ê°™ì´ ëŒ€ê´„í˜¸ ì•ˆì— í‘œì‹œë©ë‹ˆë‹¤.
7. ìµœì¢… í†µí•© ì¶œì²˜ ëª©ë¡ì„ ë§Œë“¤ê³  '## ì¶œì²˜' í—¤ë”ê°€ ìˆëŠ” ì¶œì²˜ ì„¹ì…˜ì— ì¶”ê°€í•˜ì„¸ìš”.
8. ì¶œì²˜ë¥¼ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´í•˜ê³  ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.

[1] ì¶œì²˜ 1
[2] ì¶œì²˜ 2

ë‹¤ìŒì€ ë³´ê³ ì„œ ì‘ì„±ì— ì‚¬ìš©í•  ë¶„ì„ê°€ë“¤ì˜ ë©”ëª¨ì…ë‹ˆë‹¤: 

{context}
"""
```

3. **write\_report** í•¨ìˆ˜: ë³´ê³ ì„œ ì‘ì„±

* **ì—­í• **: `sections`ì— ìˆëŠ” ì¸í„°ë·° ë‚´ìš©ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±.

```
def write_report(state: ResearchGraphState):
    # ì „ì²´ ì„¹ì…˜ ì„¸íŠ¸
    sections = state["sections"]
    topic = state["topic"]

    # ëª¨ë“  ì„¹ì…˜ì„ í•˜ë‚˜ë¡œ ì—°ê²°
    formatted_str_sections = "\n\n".join([f"{section}" for section in sections])
    
    # ì„¹ì…˜ì„ ìµœì¢… ë³´ê³ ì„œë¡œ ìš”ì•½
    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)    
    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f"ì´ ë©”ëª¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.")]) 
    return {"content": report.content}
```

* `report_writer_instructions`ì—ì„œ ì£¼ì–´ì§„ ì–‘ì‹ì— ë”°ë¼ `llm.invoke()`ë¥¼ í†µí•´ ë³´ê³ ì„œ ë³¸ë¬¸ì„ ìƒì„±.
* ìµœì¢… ë³´ê³ ì„œ ë³¸ë¬¸ì€ `"content"` í•„ë“œì— ì €ì¥ë©ë‹ˆë‹¤.

**intro\_conclusion\_instructions**

* í•´ë‹¹ ì§€ì¹¨ì€ ë³´ê³ ì„œì— **ì„œë¡  ë˜ëŠ” ê²°ë¡ ì„ ì‘ì„±í•˜ëŠ” ë° í•„ìš”í•œ ì„¸ë¶€ ì§€ì¹¨**ì„ ì œê³µí•©ë‹ˆë‹¤. ë³´ê³ ì„œ ì „ì²´ë¥¼ ìš”ì•½í•˜ê³  ë°©í–¥ì„±ì„ ì œê³µí•˜ê±°ë‚˜, ì „ì²´ ë³´ê³ ì„œ ë‚´ìš©ì„ ì •ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
  + ì´ ì§€ì¹¨ì„ í†µí•´ ì‘ì„±ìëŠ” ë³´ê³ ì„œ ì „ì²´ ë‚´ìš©ì„ ê°„ê²°í•˜ê³  ì„¤ë“ë ¥ ìˆê²Œ ì •ë¦¬í•˜ì—¬, ë…ìë“¤ì´ ë³´ê³ ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ë¹ ë¥´ê²Œ íŒŒì•…í•˜ê±°ë‚˜ ê²°ë¡ ì„ í†µí•´ ì •ë¦¬ëœ í†µì°°ì„ ì–»ê²Œ í•©ë‹ˆë‹¤.

```
intro_conclusion_instructions = """
ë‹¹ì‹ ì€ {topic}ì— ëŒ€í•œ ë³´ê³ ì„œë¥¼ ë§ˆë¬´ë¦¬í•˜ëŠ” ê¸°ìˆ  ì‘ê°€ì…ë‹ˆë‹¤.

ë³´ê³ ì„œì˜ ëª¨ë“  ì„¹ì…˜ì´ ì£¼ì–´ì§ˆ ê²ƒì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ê°„ê²°í•˜ê³  ì„¤ë“ë ¥ ìˆëŠ” ì„œë¡  ë˜ëŠ” ê²°ë¡  ì„¹ì…˜ì„ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ì„œë¡  ë˜ëŠ” ê²°ë¡  ì¤‘ ì–´ëŠ ê²ƒì„ ì‘ì„±í• ì§€ ì§€ì‹œí•  ê²ƒì…ë‹ˆë‹¤.

ë‘ ì„¹ì…˜ ëª¨ë‘ ì„œë¬¸ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

ì•½ 100ë‹¨ì–´ë¥¼ ëª©í‘œë¡œ í•˜ì—¬ ë³´ê³ ì„œì˜ ëª¨ë“  ì„¹ì…˜ì„ ê°„ê²°í•˜ê²Œ ë¯¸ë¦¬ ë³´ì—¬ì£¼ê±°ë‚˜(ì„œë¡ ì˜ ê²½ìš°) ìš”ì•½í•˜ì„¸ìš”(ê²°ë¡ ì˜ ê²½ìš°).

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”. 

ì„œë¡ ì˜ ê²½ìš°, ë§¤ë ¥ì ì¸ ì œëª©ì„ ë§Œë“¤ê³  # í—¤ë”ë¥¼ ì œëª©ì— ì‚¬ìš©í•˜ì„¸ìš”.

ì„œë¡ ì˜ ê²½ìš°, ## ì„œë¡ ì„ ì„¹ì…˜ í—¤ë”ë¡œ ì‚¬ìš©í•˜ì„¸ìš”. 

ê²°ë¡ ì˜ ê²½ìš°, ## ê²°ë¡ ì„ ì„¹ì…˜ í—¤ë”ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.

ë‹¤ìŒì€ ì‘ì„± ì‹œ ì°¸ê³ í•  ì„¹ì…˜ë“¤ì…ë‹ˆë‹¤: {formatted_str_sections}
"""
```

4. **write\_introduction** ë° **write\_conclusion** í•¨ìˆ˜: ì„œë¡  ë° ê²°ë¡  ì‘ì„±

* **ì—­í• **: ë³´ê³ ì„œì— ì„œë¡  ë° ê²°ë¡ ì„ ì¶”ê°€í•´ êµ¬ì¡°í™”.

```
def write_introduction(state: ResearchGraphState):
    # ì „ì²´ ì„¹ì…˜ ì„¸íŠ¸
    sections = state["sections"]
    topic = state["topic"]

    # ëª¨ë“  ì„¹ì…˜ì„ í•˜ë‚˜ë¡œ ì—°ê²°
    formatted_str_sections = "\n\n".join([f"{section}" for section in sections])
    
    # ì„¹ì…˜ì„ ìµœì¢… ë³´ê³ ì„œë¡œ ìš”ì•½
    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    
    intro = llm.invoke([instructions]+[HumanMessage(content=f"ë³´ê³ ì„œ ì„œë¡ ì„ ì‘ì„±í•˜ì„¸ìš”")]) 
    return {"introduction": intro.content}
```
```
def write_conclusion(state: ResearchGraphState):
    # ì „ì²´ ì„¹ì…˜ ì„¸íŠ¸
    sections = state["sections"]
    topic = state["topic"]

    # ëª¨ë“  ì„¹ì…˜ì„ í•˜ë‚˜ë¡œ ì—°ê²°
    formatted_str_sections = "\n\n".join([f"{section}" for section in sections])
    
    # ì„¹ì…˜ì„ ìµœì¢… ë³´ê³ ì„œë¡œ ìš”ì•½
    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    
    conclusion = llm.invoke([instructions]+[HumanMessage(content=f"ë³´ê³ ì„œ ê²°ë¡ ì„ ì‘ì„±í•˜ì„¸ìš”")]) 
    return {"conclusion": conclusion.content}
```

* `intro_conclusion_instructions`ì— ë”°ë¼, ì„œë¡ ì€ ë³´ê³ ì„œì˜ ê°„ê²°í•œ ìš”ì•½ì„, ê²°ë¡ ì€ ìš”ì•½ ë° ë§ˆë¬´ë¦¬ ë‚´ìš©ì„ ë‹´ìŠµë‹ˆë‹¤.
* `write_introduction` ë° `write_conclusion`ì€ ê°ê° `introduction`, `conclusion` í•„ë“œì— ì €ì¥.

5. **finalize\_report** í•¨ìˆ˜: ìµœì¢… ë³´ê³ ì„œ ê²°í•© ë° ì™„ë£Œ

* **ì—­í• **: ì„œë¡ , ë³¸ë¬¸, ê²°ë¡ ì„ í•˜ë‚˜ì˜ ì™„ì„±ëœ ë³´ê³ ì„œë¡œ ê²°í•©í•˜ëŠ” â€œë¦¬ë“€ìŠ¤â€ ë‹¨ê³„.

```
def finalize_report(state: ResearchGraphState):
    """ ì´ëŠ” ëª¨ë“  ì„¹ì…˜ì„ ìˆ˜ì§‘í•˜ê³  ê²°í•©í•œ ë‹¤ìŒ ì„œë¡ /ê²°ë¡ ì„ ì‘ì„±í•˜ê¸° ìœ„í•´ ê·¸ë“¤ì„ ë°˜ì˜í•˜ëŠ” "ë¦¬ë“€ìŠ¤" ë‹¨ê³„ì…ë‹ˆë‹¤ """
    # ì „ì²´ ìµœì¢… ë³´ê³ ì„œ ì €ì¥
    content = state["content"]
    if content.startswith("## í†µì°°"):
        content = content.strip("## í†µì°°")
    if "## ì¶œì²˜" in content:
        try:
            content, sources = content.split("\n## ì¶œì²˜\n")
        except:
            sources = None
    else:
        sources = None

    final_report = state["introduction"] + "\n\n---\n\n" + content + "\n\n---\n\n" + state["conclusion"]
    if sources is not None:
        final_report += "\n\n## ì¶œì²˜\n" + sources
    return {"final_report": final_report}
```

* `content`, `introduction`, `conclusion`, `sources`ë¥¼ í•©ì³ ìµœì¢… ë³´ê³ ì„œ(`final_report`)ì— ì €ì¥í•©ë‹ˆë‹¤.

---

6. **StateGraph** ë…¸ë“œ ë° ì—£ì§€ ì •ì˜

* **ì—­í• **: ì¸í„°ë·° ìƒì„±, í”¼ë“œë°± ì²˜ë¦¬, ì¸í„°ë·° ì§„í–‰, ë³´ê³ ì„œ ì‘ì„±, ì„œë¡  ë° ê²°ë¡  ì‘ì„±, ìµœì¢… ë³´ê³ ì„œ ì™„ì„±ì„ ìœ„í•œ ë…¸ë“œì™€ ì—£ì§€ ì •ì˜.

```
# ë…¸ë“œì™€ ì—£ì§€ ì¶”ê°€ 
builder = StateGraph(ResearchGraphState)
builder.add_node("create_analysts", create_analysts)
builder.add_node("human_feedback", human_feedback)
builder.add_node("conduct_interview", interview_builder.compile())
builder.add_node("write_report",write_report)
builder.add_node("write_introduction",write_introduction)
builder.add_node("write_conclusion",write_conclusion)
builder.add_node("finalize_report",finalize_report)

# ë¡œì§
builder.add_edge(START, "create_analysts")
builder.add_edge("create_analysts", "human_feedback")
builder.add_conditional_edges("human_feedback", initiate_all_interviews, ["create_analysts", "conduct_interview"])
builder.add_edge("conduct_interview", "write_report")
builder.add_edge("conduct_interview", "write_introduction")
builder.add_edge("conduct_interview", "write_conclusion")
builder.add_edge(["write_conclusion", "write_report", "write_introduction"], "finalize_report")
builder.add_edge("finalize_report", END)
```

* `add_conditional_edges`ë¡œ `human_feedback` ì¡°ê±´ì„ ì¶©ì¡±í•  ê²½ìš° ìƒˆë¡œìš´ ë¶„ì„ê°€ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì¸í„°ë·°ë¥¼ ì‹œì‘í•˜ë„ë¡ êµ¬ì„±.
* ì—¬ê¸°ì„œ `interview_builder`ë¥¼ ì„œë¸Œê·¸ë˜í”„ë¡œ ì²˜ë¦¬í•œ ë°©ì‹ì€ ì¸í„°ë·° ìˆ˜í–‰ ê³¼ì •ì„ ë…ë¦½ì ì¸ ê·¸ë˜í”„ë¡œ êµ¬ì„±í•˜ì—¬ ëª¨ë“ˆí™”í•˜ê³ , ì´ë¥¼ ì£¼ ê·¸ë˜í”„ì¸ StateGraphì˜ íŠ¹ì • ë…¸ë“œë¡œ ì»´íŒŒì¼í•˜ì—¬ ì¬ì‚¬ìš©í•œ ê²ƒì…ë‹ˆë‹¤.
  + ì´ ê³¼ì •ì€ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ë¶„ë¦¬í•˜ì—¬ ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ í•˜ê³ , StateGraphì˜ ë…¸ë“œ ê°„ ë‹¨ê³„ë³„ íë¦„ì„ ë” ì‰½ê²Œ ì„¤ì •í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.
  + `interview_builder`ëŠ” ì¸í„°ë·° ìˆ˜í–‰ì˜ ê° ë‹¨ê³„ë¥¼ í¬í•¨í•˜ëŠ” ì‘ì€ ê·¸ë˜í”„ë¡œ, ë…ë¦½ì ì¸ **StateGraph ì¸ìŠ¤í„´ìŠ¤ë¡œ ì‘ì„±**ë©ë‹ˆë‹¤.
  + `interview_builder` ì„œë¸Œê·¸ë˜í”„ëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ë§Œë“  `ask_question`, `search_web`, `search_wikipedia`, `answer_question`, `save_interview`, `write_section` ë…¸ë“œì™€ ì´ë“¤ì„ ì‡ëŠ” ì—£ì§€ë¡œ êµ¬ì„±ë˜ì–´, ì¸í„°ë·°ì™€ ê´€ë ¨ëœ ëª¨ë“  ë¡œì§ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

7. ê·¸ë˜í”„ ì‹¤í–‰ ë° í™•ì¸

* **ì—­í• **: ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•˜ê³  ê° ë‹¨ê³„ì˜ ìƒíƒœë¥¼ ì‹œê°í™”í•˜ì—¬ ê²€ì‚¬í•©ë‹ˆë‹¤.

```
# ì»´íŒŒì¼
memory = MemorySaver()
graph = builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)
display(Image(graph.get_graph(xray=1).draw_mermaid_png()))
```

![](https://velog.velcdn.com/images/euisuk-chung/post/41f538fb-c7ec-4b6a-9ac1-eeea6b719472/image.png)

```
# ì…ë ¥
max_analysts = 3 
topic = "LLMOps í”Œë«í¼ êµ¬ì¶•"
thread = {"configurable": {"thread_id": "1"}}

# ì²« ë²ˆì§¸ ì¤‘ë‹¨ê¹Œì§€ ê·¸ë˜í”„ ì‹¤í–‰
for event in graph.stream({"topic":topic,
                           "max_analysts":max_analysts}, 
                          thread, 
                          stream_mode="values"):
    
    analysts = event.get('analysts', '')
    if analysts:
        for analyst in analysts:
            print(f"ì´ë¦„: {analyst.name}")
            print(f"ì†Œì†: {analyst.affiliation}")
            print(f"ì—­í• : {analyst.role}")
            print(f"ì„¤ëª…: {analyst.description}")
            print("-" * 50)  
```

* `graph.stream`ìœ¼ë¡œ ê·¸ë˜í”„ê°€ íë¦„ì— ë”°ë¼ ë‹¨ê³„ë³„ë¡œ ì§„í–‰ë˜ë©°, ìƒíƒœì— ì €ì¥ëœ ë¶„ì„ê°€ ì •ë³´ë„ ì¶œë ¥ë©ë‹ˆë‹¤.

```
# ë‚˜ë¨¸ì§€ë„ ëê¹Œì§€ ì‹¤í–‰í•´ì¤ë‹ˆë‹¤
graph.update_state(thread, {"human_analyst_feedback": 
                            None}, as_node="human_feedback")
                            
# ê³„ì†
for event in graph.stream(None, thread, stream_mode="updates"):
    print("--ë…¸ë“œ--")
    node_name = next(iter(event.keys()))
    print(node_name)
    
```

* ì˜ë„í•œ ê²ƒì²˜ëŸ¼ `conduct_interview`ë“¤ì´ ë³‘ë ¬ì ìœ¼ë¡œ ìˆ˜í–‰ë˜ê³ , `write ì‘ì—…ë“¤`ì´ ìˆ˜í–‰ëœ ë’¤ì—, `finalize_report`ì´ ìˆ˜í–‰ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
--ë…¸ë“œ--
conduct_interview
--ë…¸ë“œ--
conduct_interview
--ë…¸ë“œ--
conduct_interview
--ë…¸ë“œ--
write_introduction
--ë…¸ë“œ--
write_conclusion
--ë…¸ë“œ--
write_report
--ë…¸ë“œ--
finalize_report
```

8. ìµœì¢… ë³´ê³ ì„œ ê²°ê³¼ ì¶œë ¥

* **ì—­í• **: ìµœì¢… ë³´ê³ ì„œë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥.

```
from IPython.display import Markdown
final_state = graph.get_state(thread)
report = final_state.values.get('final_report')
Markdown(report)
```

* `final_report`ì— ì €ì¥ëœ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‹œê°í™”í•˜ì—¬, êµ¬ì¡°ê°€ ì™„ì„±ëœ ë³´ê³ ì„œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](https://velog.velcdn.com/images/euisuk-chung/post/580c1f47-be87-48d0-8686-447f250e9b4e/image.png)

