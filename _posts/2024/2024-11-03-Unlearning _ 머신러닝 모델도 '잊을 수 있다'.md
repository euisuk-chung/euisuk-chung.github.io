---
title: "Unlearning : 머신러닝 모델도 '잊을 수 있다'"
date: "2024-11-03"
tags:
  - "IT지식"
  - "딥러닝"
year: "2024"
---

# Unlearning : 머신러닝 모델도 '잊을 수 있다'

원본 게시글: https://velog.io/@euisuk-chung/machine-unlearning

딥러닝과 머신러닝은 오늘날 다양한 분야에서 놀라운 성과를 거두고 있습니다. 하지만 모델이 학습한 정보 중 **불필요하거나 민감한 정보**를 삭제해야 하는 상황도 발생합니다.

* 예를 들어, 개인정보 보호 규정에 따라 모델이 특정 사용자의 데이터를 삭제해야 하거나, 학습 과정에서 발생한 **편향(Bias)**을 교정해야 할 수 있습니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/7115dbc8-78c7-497a-8887-9e3e90ab0d70/image.png)

이러한 필요를 충족하는 개념이 바로 **언러닝(Unlearning)**입니다.

> 🤔 머신러닝 모델은 학습된 데이터로부터 패턴과 정보를 도출하지만, 일부 데이터가 `제거`되거나 `수정`되어야 할 경우 **새로운 모델 재학습 비용**이 문제가 됩니다.

> 💡 `언러닝`은 이러한 **재학습의 비효율성을 줄이고**, **특정 데이터만 효과적으로 '`잊도록`' 하는 기법을 제공**합니다.

---

**1. 언러닝(Unlearning)이란?**
-------------------------

언러닝은 머신러닝 모델이 **학습한 특정 데이터를 잊도록 만드는 기법**입니다.

* **핵심 목표**: 특정 데이터를 학습하지 않은 상태로 돌아가면서도 성능을 유지하거나 개선하는 것입니다.
* **효율성**: 기존의 재학습보다 비용과 시간이 덜 소요됩니다.

언러닝은 데이터 프라이버시와 모델 공정성을 보장하는 데 중요한 역할을 합니다. 이는 AI 모델이 더욱 **투명하고 신뢰할 수 있는 도구**로 나아가는 기반이 됩니다.

> 🎯 아직 어떤 식으로 작동하는지 잘 모르겠다고요? 직관적인 이해를 위해 아래 그림을 살펴보시죠!

![](https://velog.velcdn.com/images/euisuk-chung/post/aea031c1-cab9-47a8-b12a-09afdc0ba1c5/image.png)

> 출처: <https://unlearning-challenge.github.io/>

위 그림은 **언러닝 알고리즘의 검증 과정**을 시각적으로 표현하고 있습니다.

* 이 과정은 다음과 같은 순서로 진행됩니다:

  1. 기존 모델 학습(Pretrained Model) 준비
  2. 특정 데이터(Forgot Set) 지정
  3. 언러닝 수행
  4. Gold Standard 모델 생성
  5. 모델 비교 및 평가
* 각 단계별 설명은 다음과 같습니다:

  **1. 기존 모델 학습(Pretrained Model) 준비**

  + **좌측 상단**: 여러 데이터 포인트(예: 이미지)를 사용하여 **사전 학습된 모델(Pretrained Model)**을 생성합니다.  
    ![](https://velog.velcdn.com/images/euisuk-chung/post/14c6795f-457d-434f-800e-4403d888392f/image.png)
  + 이 단계는 일반적인 머신러닝 모델 학습 과정과 동일합니다.

  **2. 특정 데이터(Forgot Set) 지정**

  + **우측 상단**: 특정 데이터 포인트(예: 이미지)를 **Forget Set**으로 지정합니다.  
    ![](https://velog.velcdn.com/images/euisuk-chung/post/642dcd67-7918-4895-92c8-296198ff44b6/image.png)
  + Forget Set은 모델이 더 이상 기억해서는 안 되는, 즉 **삭제 대상이 되는 데이터**를 의미합니다.

  **3. 언러닝 수행**

  + **중앙**: 지정된 Forget Set을 모델에서 제거하기 위해 **언러닝 알고리즘**이 적용됩니다.  
    ![](https://velog.velcdn.com/images/euisuk-chung/post/34cc9eae-978a-4760-a378-fb2c47e85e4c/image.png)
  + 언러닝 알고리즘은 모델이 Forget Set을 잊도록 만들어 기존 모델을 **언러닝된 모델(Unlearned Model)**로 변환합니다.

  **4. Gold Standard 모델 생성**

  + **좌측 하단**: **Forget Set을 제외**하고 동일한 데이터를 사용하여 새로운 모델을 학습합니다.
  + 이렇게 생성된 모델은 **Gold Standard**라고 하며, 특정 데이터를 잊은 상태에서 학습된 **이상적인 모델**을 의미합니다.

  **5. 모델 비교 및 평가**

  + **우측 하단**: 언러닝 알고리즘이 적용된 **Unlearned Model**과 **Gold Standard** 모델을 비교합니다.
  + 이 과정의 목표는 두 모델의 출력이 얼마나 유사한지를 확인하여 **언러닝의 효과를 평가**하는 것입니다.
  + 여기서 핵심 질문은 **"두 모델이 얼마나 가까운가?"**이며, 이는 언러닝이 성공적으로 수행되었는지를 판단하는 중요한 기준이 됩니다.

### **언러닝 기법의 분류**

1. **정확한 언러닝 (Exact Unlearning)**

   정확한 언러닝은 특정 데이터 포인트의 영향을 **완전히 제거**하는 것을 목표로 합니다. 이 방법은 알고리즘 수준의 재훈련을 통해 언러닝된 데이터가 모델에 전혀 영향을 미치지 않도록 합니다. 하지만 계산 비용이 많이 들고 주로 **단순한 모델**에 적합합니다.

2. **근사 언러닝 (Approximate Unlearning)**

   근사 언러닝은 모델의 매개변수를 제한적으로 업데이트하여 대상 데이터 포인트의 영향을 **최소화**하는 데 중점을 둡니다. 이 방법은 계산 비용과 시간을 줄여 **대규모 복잡한 모델**에도 적용 가능합니다.

---

**2. 언러닝이 필요한 이유**
------------------

### **1. 데이터 프라이버시**

GDPR(유럽연합 일반 데이터 보호 규정)이나 CCPA(캘리포니아 소비자 개인정보 보호법)와 같은 규정이 강화됨에 따라, 사용자는 자신의 데이터를 삭제할 권리를 가집니다. 하지만 단순히 데이터를 삭제하는 것만으로는 충분하지 않습니다. 모델 파라미터에는 **이미 학습된 정보**가 남아 있기 때문입니다. 언러닝은 이를 해결하는 방법을 제공합니다.

예를 들어, 온라인 플랫폼에서 사용자가 자신의 데이터를 삭제 요청했을 때, 해당 데이터를 학습한 AI 모델이 여전히 예측에 활용한다면 이는 프라이버시 침해로 이어질 수 있습니다. 언러닝은 이러한 데이터를 '완전히 잊도록' 합니다.

### **2. 모델 편향 제거**

모델이 특정 그룹이나 패턴에 대해 **편향된 데이터를 학습**했을 때, 공정하지 않은 예측을 하게 됩니다. 예를 들어, 채용 모델이 특정 성별이나 인종에 대해 편향된 결정을 내린다면, 언러닝을 통해 이러한 데이터를 제거하고 **공정한 모델**로 개선할 수 있습니다.

### **3. 모델 업데이트**

시간이 지남에 따라 일부 데이터가 **유효하지 않게** 될 수 있습니다. 예를 들어, 온라인 상거래 추천 모델이 오래된 트렌드를 학습한 경우 이를 잊고 새로운 트렌드에 맞게 업데이트해야 합니다. 언러닝은 기존 데이터 삭제와 모델 최적화를 동시에 해결합니다.

---

**3. 언러닝의 주요 기법**
-----------------

### **1. 모델 재학습 (Re-training)**

가장 직관적인 방법은 민감한 데이터를 제거한 후 **나머지 데이터로 모델을 처음부터 다시 학습**시키는 것입니다. 하지만 이 방법은 비용과 시간이 많이 소모되며 대규모 데이터셋에 비효율적입니다.

### **2. 그라디언트 역전파 수정**

특정 데이터를 '잊게' 하도록 **역방향 그라디언트**를 적용합니다. 손실 함수에 데이터의 기여를 상쇄하는 값을 추가해 **모델 파라미터를 수정**합니다. 이 방법은 일부 파라미터만 조정하므로 효율적입니다.

### **3. 지식 증류 (Knowledge Distillation)**

기존 모델의 지식을 새로운 모델로 전달하되, **특정 정보를 포함하지 않도록** 학습합니다. 이는 경량화된 서브 모델을 생성하고 **효율적인 언러닝**을 달성하는 데 유용합니다.

### **4. SISA 프레임워크**

Bourtoule et al.의 **SISA(Sharding, Isolation, Slicing, and Aggregation)** 프레임워크는 데이터를 여러 **샤드(Shard)**로 나누고 각 샤드에 대해 독립적으로 서브모델을 학습시킵니다. 삭제 요청이 있을 때 해당 데이터가 포함된 서브모델만 재훈련하여 **효율적으로 언러닝**을 수행합니다.

---

**4. 언러닝의 주요 도전 과제**
--------------------

1. **데이터 의존성**: 데이터 간 복잡한 **통계적 패턴**이 무너질 수 있어 모델 성능이 저하됩니다.
2. **모델 복잡성**: 대규모 딥러닝 모델은 **수백만 개의 매개변수**로 인해 특정 데이터의 영향을 추적하기 어렵습니다.
3. **계산 비용**: 반복적 최적화는 비용이 높으며, 데이터셋 크기가 커질수록 문제가 심화됩니다.
4. **평가 및 검증**: 언러닝 성공을 평가하기 위한 **일관된 지표**가 부족합니다.
5. **프라이버시 문제**: 언러닝 과정에서 정보가 유출되거나, **멤버십 추론 공격**이 발생할 수 있습니다.

---

**5. 연구 동향 및 사례**
-----------------

### **1. 차별적 프라이버시 기반 언러닝**

Ginart et al.은 확률적 방법을 사용해 모델 출력의 분포 유사성을 목표로 하는 **프라이버시 언러닝**을 제안했습니다.

### **2. LLM(대규모 언어 모델)에서의 언러닝**

Microsoft의 연구는 LLM에서 **저작권 데이터**를 삭제하기 위해 강화 학습 기반 기법을 사용했습니다. 이는 모델이 특정 정보를 적극적으로 잊도록 유도합니다.

### **3. 회귀 문제 언러닝**

Tarun et al.은 딥러닝 **회귀 모델**에서 언러닝을 다루며 **Blindspot** 및 **가우시안 조정 기법**을 제안했습니다.

---

**6. 결론**
---------

언러닝은 단순한 데이터 삭제를 넘어서 **모델이 특정 데이터를 잊도록 만드는 강력한 기술**입니다. 이는 데이터 프라이버시를 보호하고 AI의 공정성과 신뢰성을 높이는 데 중요한 역할을 합니다.

미래 연구는 대규모 모델에서도 효율적이고 검증 가능한 언러닝 기법을 개발하는 데 초점을 맞출 것입니다. AI 기술이 발전할수록 언러닝은 **필수적인 역량**으로 자리 잡게 될 것입니다.