---
title: "[ê°œë…ì •ë¦¬] ì‹œê³„ì—´ ì¸ê³¼ê´€ê³„ ë¶„ì„: Granger Causality"
date: "2024-07-06"
tags:
  - "Timeseries"
  - "ê°œë…ì •ë¦¬"
year: "2024"
---

# [ê°œë…ì •ë¦¬] ì‹œê³„ì—´ ì¸ê³¼ê´€ê³„ ë¶„ì„: Granger Causality

ì•ˆë…•í•˜ì„¸ìš”ğŸ˜Š ì§€ë‚œ ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œ "ì¸ê³¼ê´€ê³„ì™€ ìƒê´€ê´€ê³„ì˜ ê°œë…"([ë§í¬](https://velog.io/@euisuk-chung/%EA%B0%9C%EB%85%90%EC%A0%95%EB%A6%AC-%EC%83%81%EA%B4%80%EA%B4%80%EA%B3%84-vs-%EC%9D%B8%EA%B3%BC%EA%B4%80%EA%B3%84))ì— ëŒ€í•´ì„œ ì‚´í´ë³´ì•˜ëŠ”ë°ìš”.

ì˜¤ëŠ˜ì€ ì‹œê³„ì—´ ë¶„ì„ì˜ í•µì‹¬ ê°œë… ì¤‘ í•˜ë‚˜ì¸ 'ê·¸ëœì € ì¸ê³¼ê´€ê³„(Granger causality)'ì— ëŒ€í•´ ì•Œì•„ë³´ê³ , ì´ë¥¼ ì‹¤ì œ ë°ì´í„°ì— ì ìš©í•´ë³´ëŠ” ì‹œê°„ì„ ê°€ì ¸ë³´ê² ìŠµë‹ˆë‹¤.

ì‹¤ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ëŠ” Kaggle ë°ì´í„° ì¤‘ í•˜ë‚˜ì¸ `Advertising Sales Dataset`([ë§í¬](https://www.kaggle.com/datasets/yasserh/advertising-sales-dataset?resource=download))ë¡œ, í•´ë‹¹ ë°ì´í„°ë¥¼ í†µí•´ ê´‘ê³  ì˜ˆì‚°ì´ ë§¤ì¶œì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ í™•ì¸í•´ë³´ì‹¤ ìˆ˜ ìˆì„ ê²ë‹ˆë‹¤â­

1. ì¸ê³¼ê´€ê³„ vs ìƒê´€ê´€ê³„
---------------

ë¨¼ì € ë³µìŠµ ì°¨ì›ì—ì„œ ê°„ë‹¨í•˜ê²Œ ì¸ê³¼ê´€ê³„ì™€ ìƒê´€ê´€ê³„ì˜ ì°¨ì´ë¶€í„° ì•Œì•„ë´…ì‹œë‹¤.

**ì¸ê³¼ê´€ê³„ (Causal Relationship)**

* `ì •ì˜`: í•œ ì‚¬ê±´ì´ ë‹¤ë¥¸ ì‚¬ê±´ì„ ì§ì ‘ì ìœ¼ë¡œ ì•¼ê¸°í•˜ëŠ” ê´€ê³„
* `ì˜ˆ`: í¡ì—°ì´ íì•” ë°œë³‘ë¥ ì„ ì¦ê°€ì‹œí‚´

**ìƒê´€ê´€ê³„ (Correlation)**

* `ì •ì˜`: ë‘ ë³€ìˆ˜ ê°„ì˜ ì„ í˜•ì  ê´€ë ¨ì„±ì˜ ì •ë„
* `ì˜ˆ`: ì•„ì´ìŠ¤í¬ë¦¼ íŒë§¤ëŸ‰ê³¼ ë²”ì£„ìœ¨ì´ í•¨ê»˜ ì¦ê°€í•˜ëŠ” ê²½í–¥ (ì‹¤ì œ ì›ì¸ì€ ë”ìš´ ë‚ ì”¨ì¼ ìˆ˜ ìˆìŒ)

**ì°¨ì´ì **

* `ë°©í–¥ì„±`: ì¸ê³¼ê´€ê³„ëŠ” ë°©í–¥ì´ ìˆì§€ë§Œ, ìƒê´€ê´€ê³„ëŠ” ë°©í–¥ì„±ì´ ì—†ìŠµë‹ˆë‹¤.
* `ì›ì¸ê³¼ ê²°ê³¼`: ì¸ê³¼ê´€ê³„ëŠ” ì›ì¸ê³¼ ê²°ê³¼ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì§€ë§Œ, ìƒê´€ê´€ê³„ëŠ” ê·¸ë ‡ì§€ ì•ŠìŠµë‹ˆë‹¤.

2. ê·¸ëœì € ì¸ê³¼ê´€ê³„
-----------

`ê·¸ëœì € ì¸ê³¼ê´€ê³„(Granger causality)`ëŠ” 1969ë…„ í´ë¼ì´ë¸Œ ê·¸ëœì €ê°€ ì œì•ˆí•œ ê°œë…ìœ¼ë¡œ, ì‹œê³„ì—´ ë°ì´í„°ì—ì„œì˜ ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¸ê³¼ê´€ê³„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.

> **ê·¸ëœì € ì¸ê³¼ê´€ê³„ì˜ ì •ì˜**  
> (Def) Xì˜ ê³¼ê±° ì •ë³´ê°€ Yì˜ ë¯¸ë˜ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ë° í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ë„ì›€ì„ ì¤€ë‹¤ë©´, "XëŠ” Yë¥¼ ê·¸ëœì € ì¸ê³¼í•œë‹¤"ê³  ë§í•©ë‹ˆë‹¤.

ğŸ’¯ ì´ëŠ” ìˆ˜í•™ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

P(Y(t+1)âˆ£Y(t),Y(tâˆ’1),...,X(t),X(tâˆ’1),...)â‰ P(Y(t+1)âˆ£Y(t),Y(tâˆ’1),...)P(Y(t+1) | Y(t), Y(t-1), ..., X(t), X(t-1), ...) â‰  P(Y(t+1) | Y(t), Y(t-1), ...)P(Y(t+1)âˆ£Y(t),Y(tâˆ’1),...,X(t),X(tâˆ’1),...)î€ â€‹=P(Y(t+1)âˆ£Y(t),Y(tâˆ’1),...)

ì´ë•Œ PPPëŠ” ì¡°ê±´ë¶€ í™•ë¥ ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

1. ì¢Œë³€ P(**Y(t+1)** | `Y(t), Y(t-1), ...`, `X(t), X(t-1), ...`):

   * **Yì˜ ë¯¸ë˜ ê°’ Y(t+1)ì„ ì˜ˆì¸¡**í•  ë•Œ, `Yì˜ ê³¼ê±° ê°’ë“¤(Y(t), Y(t-1), ...)`ê³¼ `Xì˜ ê³¼ê±° ê°’ë“¤(X(t), X(t-1), ...)`ì„ ëª¨ë‘ ì‚¬ìš©í•œ ì¡°ê±´ë¶€ í™•ë¥ ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
2. ìš°ë³€ P(**Y(t+1)** | `Y(t), Y(t-1), ...`):

   * **Yì˜ ë¯¸ë˜ ê°’ Y(t+1)ì„ ì˜ˆì¸¡**í•  ë•Œ, `Yì˜ ê³¼ê±° ê°’ë“¤(Y(t), Y(t-1), ...)`ë§Œì„ ì‚¬ìš©í•œ ì¡°ê±´ë¶€ í™•ë¥ ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
3. ë¶€ë“±í˜¸ (â‰ ):

   * ë‘ ì¡°ê±´ë¶€ í™•ë¥ ì´ ì„œë¡œ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

> ğŸ’¡ **ìœ„ ìˆ˜ì‹ì˜ ì˜ë¯¸**:
>
> * ë§Œì•½ Xê°€ Yë¥¼ ê·¸ëœì € ì¸ê³¼í•œë‹¤ë©´, Xì˜ ê³¼ê±° ê°’ë“¤ì„ í¬í•¨í•˜ì—¬ ì˜ˆì¸¡í•œ Yì˜ ë¯¸ë˜ ê°’(ì¢Œë³€)ì´ Yì˜ ê³¼ê±° ê°’ë“¤ë§Œìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°(ìš°ë³€)ì™€ ë‹¤ë¥¼ ê²ƒì…ë‹ˆë‹¤.
> * ì¦‰, **Xì˜ ì •ë³´ê°€ Yì˜ ì˜ˆì¸¡ì— ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ì¤€ë‹¤ëŠ” ê²ƒ**ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

> ğŸ’¡ **ì‹¤ì œ ì ìš©**:
>
> * ì´ ê°œë…ì„ í†µê³„ì ìœ¼ë¡œ ê²€ì •í•˜ê¸° ìœ„í•´, ë³´í†µ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‘ ê²½ìš°(X í¬í•¨ vs X ë¯¸í¬í•¨)ì˜ ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
> * F-ê²€ì •ì´ë‚˜ ë‹¤ë¥¸ í†µê³„ì  ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë‘ ëª¨ë¸ ê°„ì˜ ì°¨ì´ê°€ ìœ ì˜ë¯¸í•œì§€ íŒë‹¨í•©ë‹ˆë‹¤.

> âš ï¸ **ì£¼ì˜ì **:
>
> * ì´ëŠ” ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì— ê¸°ë°˜í•œ ì¸ê³¼ê´€ê³„ì´ë©°, ì§„ì •í•œ ì¸ê³¼ê´€ê³„ë¥¼ ì™„ë²½íˆ ì¦ëª…í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.
> * ìˆ¨ê²¨ì§„ ë³€ìˆ˜ë‚˜ ê³µí†µ ì›ì¸ ë“±ì˜ ê°€ëŠ¥ì„±ì„ í•­ìƒ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.

ì´ì²˜ëŸ¼ ìœ„ ìˆ˜ì‹ì€ ê·¸ëœì € ì¸ê³¼ê´€ê³„ì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ë¥¼ ê°„ê²°í•˜ê²Œ í‘œí˜„í•˜ê³  ìˆìœ¼ë©°, ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì—ì„œ ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ ì´í•´í•˜ëŠ” ë° ì¤‘ìš”í•œ ë„êµ¬ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.

3. ê·¸ëœì € ì¸ê³¼ê´€ê³„ vs ì¸ê³¼ê´€ê³„
-------------------

ê·¸ëœì € ì¸ê³¼ê´€ê³„ì™€ ì¼ë°˜ì ì¸ ì¸ê³¼ê´€ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì°¨ì´ê°€ ì¡´ì¬í•©ë‹ˆë‹¤:

1. ì •ì˜:

   * ì¸ê³¼ê´€ê³„: Aê°€ Bì˜ `ì§ì ‘ì ì¸ ì›ì¸`ì´ ë¨
   * ê·¸ëœì € ì¸ê³¼ê´€ê³„: Aì˜ ê³¼ê±° ì •ë³´ê°€ Bì˜ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ë„ì›€ì´ ë¨
2. ê¸°ë°˜:

   * ì¸ê³¼ê´€ê³„: ë…¼ë¦¬ì , ì‹¤í—˜ì  ì¦ê±°ì— ê¸°ë°˜
   * ê·¸ëœì € ì¸ê³¼ê´€ê³„: í†µê³„ì  ì˜ˆì¸¡ë ¥ì— ê¸°ë°˜
3. í•´ì„:

   * ì¸ê³¼ê´€ê³„: "Aê°€ Bë¥¼ ì•¼ê¸°í•œë‹¤"
   * ê·¸ëœì € ì¸ê³¼ê´€ê³„: "Aê°€ Bë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ë„ì›€ì´ ëœë‹¤"

4. ê·¸ëœì € ì¸ê³¼ê´€ê³„ ëª¨í˜•
--------------

### ëª¨í˜•ì˜ ì „ì œ

1. `ì‹œê°„ ì„ í›„ê´€ê³„`: ê³¼ê±°ì˜ ì‚¬ê±´ì€ í˜„ì¬ì˜ ì‚¬ê±´ì„ ìœ ë°œí•  ìˆ˜ ìˆì§€ë§Œ, ë¯¸ë˜ì˜ ì‚¬ê±´ì€ í˜„ì¬ì˜ ì‚¬ê±´ì„ ìœ ë°œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
2. `ì •ìƒì„±`: ë°ì´í„°ëŠ” ì •ìƒì„±(stationary)ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤. ì¦‰, í‰ê· ê³¼ ë¶„ì‚°ì´ ì‹œê°„ì— ë”°ë¼ ì¼ì •í•´ì•¼ í•©ë‹ˆë‹¤.
3. `ì…ë ¥ì‹œì°¨`: ì˜ˆìƒë˜ëŠ” ì‹œì°¨ë§Œí¼ì˜ ê³¼ê±° ë°ì´í„°ë¥¼ ëª¨ë‘ ì…ë ¥ë³€ìˆ˜ë¡œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
4. `ìµœì¢…ì‹œì°¨`: ì ì ˆí•œ ì‹œì°¨ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. ë³´í†µ ì—° í™˜ì‚° ë¹ˆë„ì˜ 2~3ë°°ê¹Œì§€ ê³ ë ¤í•©ë‹ˆë‹¤.

### ëª¨í˜•ì˜ ê²€ì •

ê·¸ëœì € ì¸ê³¼ê´€ê³„ ê²€ì •ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤:

1. ê·€ë¬´ê°€ì„¤ ì„¤ì •: "XëŠ” Yë¥¼ ê·¸ëœì € ì¸ê³¼í•˜ì§€ ì•ŠëŠ”ë‹¤"
2. ì œí•œ ëª¨ë¸ê³¼ ë¹„ì œí•œ ëª¨ë¸ êµ¬ì¶•:
   * ì œí•œ ëª¨ë¸: Y(t) = Î± + Î²1*Y(t-1) + Î²2*Y(t-2) + ... + Î²p\*Y(t-p) + Îµ
   * ë¹„ì œí•œ ëª¨ë¸: Y(t) = Î± + Î²1*Y(t-1) + ... + Î²p*Y(t-p) + Î³1*X(t-1) + ... + Î³p*X(t-p) + Îµ
3. F-í†µê³„ëŸ‰ ê³„ì‚°
4. p-value í™•ì¸ ë° ê²°ë¡  ë„ì¶œ

### íŒŒì´ì¬ ì½”ë“œ ì˜ˆì‹œ

statsmodels ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ëœì € ì¸ê³¼ê´€ê³„ ê²€ì •ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```
import numpy as np
import pandas as pd
from statsmodels.tsa.stattools import grangercausalitytests

# ì˜ˆì‹œ ë°ì´í„° ìƒì„±
np.random.seed(1)
x = np.random.randn(1000)
y = np.random.randn(1000)
y[1:] += 0.5 * x[:-1]  # Xê°€ Yë¥¼ ê·¸ëœì € ì¸ê³¼í•˜ë„ë¡ ì„¤ì •

data = pd.DataFrame({'X': x, 'Y': y})

# ê·¸ëœì € ì¸ê³¼ê´€ê³„ ê²€ì •
result = grangercausalitytests(data[['Y', 'X']], maxlag=5)

# ê²°ê³¼ ì¶œë ¥
for lag, values in result.items():
    print(f"Lag {lag}:")
    print(f"  F-statistic: {values[0]['ssr_ftest'][0]}")
    print(f"  p-value: {values[0]['ssr_ftest'][1]}")
```

5. ëª¨í˜•ì˜ ì‘ìš©
---------

### VARì„ í™œìš©í•œ ì‘ìš©

#### VARì´ë€?

* VAR(Vector Autoregression)ì€ `ì—¬ëŸ¬ ë³€ìˆ˜ì˜ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë™ì‹œì— ëª¨ë¸ë§í•˜ëŠ” ë°©ë²•`ì…ë‹ˆë‹¤.
* ê° ë³€ìˆ˜ê°€ ìì‹ ì˜ ê³¼ê±° ê°’ê³¼ ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì˜ ê³¼ê±° ê°’ì— ì˜í•´ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.

**VAR(p) ëª¨ë¸ (pì°¨ ë²¡í„° ìê¸°íšŒê·€ ëª¨ë¸):**

Yt=c+A1Ytâˆ’1+A2Ytâˆ’2+...+ApYtâˆ’p+ÏµtY\_t = c + A\_1Y\_{t-1} + A\_2Y\_{t-2} + ... + A\_pY\_{t-p} + \epsilon\_tYtâ€‹=c+A1â€‹Ytâˆ’1â€‹+A2â€‹Ytâˆ’2â€‹+...+Apâ€‹Ytâˆ’pâ€‹+Ïµtâ€‹

ì—¬ê¸°ì„œ:

* YtY\_tYtâ€‹ ëŠ” ì‹œì  tì—ì„œì˜ kì°¨ì› ì‹œê³„ì—´ ë²¡í„°
* ccc ëŠ” kì°¨ì› ìƒìˆ˜ ë²¡í„°
* AiA\_iAiâ€‹ ëŠ” k Ã— k ê³„ìˆ˜ í–‰ë ¬
* Ïµt\epsilon\_tÏµtâ€‹ ëŠ” kì°¨ì› ë°±ìƒ‰ ì¡ìŒ ë²¡í„°

#### VARì„ ì–´ë–»ê²Œ í™œìš©í•´ì„œ ì‘ìš©í•˜ëŠ”ê°€?

1. ë³€ìˆ˜ ê°„ ë™ì  ê´€ê³„ ë¶„ì„: VAR ëª¨ë¸ì€ ì—¬ëŸ¬ ë³€ìˆ˜ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ë™ì‹œì— ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. ì¶©ê²©ë°˜ì‘í•¨ìˆ˜ ë¶„ì„: í•œ ë³€ìˆ˜ì˜ ë³€í™”ê°€ ë‹¤ë¥¸ ë³€ìˆ˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹œê°„ì— ë”°ë¼ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. ì˜ˆì¸¡: ì—¬ëŸ¬ ë³€ìˆ˜ì˜ ë¯¸ë˜ ê°’ì„ ë™ì‹œì— ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**íŒŒì´ì¬ ì½”ë“œ ì˜ˆì‹œ:**

```
from statsmodels.tsa.api import VAR
from statsmodels.tsa.stattools import adfuller

# ë°ì´í„° ì •ìƒí™” (í•„ìš”í•œ ê²½ìš°)
def difference(data):
    return data.diff().dropna()

# ADF í…ŒìŠ¤íŠ¸ë¡œ ì •ìƒì„± í™•ì¸
def adf_test(series):
    result = adfuller(series)
    print(f'ADF Statistic: {result[0]}')
    print(f'p-value: {result[1]}')

# VAR ëª¨ë¸ ì ìš©
model = VAR(data)
results = model.fit(maxlags=15, ic='aic')

# ê·¸ëœì € ì¸ê³¼ê´€ê³„ ê²€ì •
granger_results = results.test_causality('Y', 'X', kind='f')
print(granger_results.summary())
```

### ARIMAë¥¼ í™œìš©í•œ ì‘ìš©

#### ARIMAë€?

* ARIMA(AutoRegressive Integrated Moving Average)ëŠ” `ë‹¨ì¼ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ëª¨ë¸ë§`í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
* ìê¸°íšŒê·€(AR), ì°¨ë¶„(I), ì´ë™í‰ê· (MA) ìš”ì†Œë¥¼ ê²°í•©í•˜ì—¬ ë³µì¡í•œ ì‹œê³„ì—´ íŒ¨í„´ì„ í¬ì°©í•©ë‹ˆë‹¤.

**ARIMA(p,d,q) ëª¨ë¸:**

Ï•(B)(1âˆ’B)dXt=Î¸(B)Ïµt\phi(B)(1-B)^d X\_t = \theta(B)\epsilon\_tÏ•(B)(1âˆ’B)dXtâ€‹=Î¸(B)Ïµtâ€‹

ì—¬ê¸°ì„œ:

* BBB ëŠ” í›„í–‰ ì—°ì‚°ì (BXt=Xtâˆ’1BX\_t = X\_{t-1}BXtâ€‹=Xtâˆ’1â€‹)
* ddd ëŠ” ì°¨ë¶„ ì°¨ìˆ˜
* Ï•(B)=1âˆ’Ï•1Bâˆ’Ï•2B2âˆ’...âˆ’Ï•pBp\phi(B) = 1 - \phi\_1B - \phi\_2B^2 - ... - \phi\_pB^pÏ•(B)=1âˆ’Ï•1â€‹Bâˆ’Ï•2â€‹B2âˆ’...âˆ’Ï•pâ€‹Bp (AR ë‹¤í•­ì‹)
* Î¸(B)=1+Î¸1B+Î¸2B2+...+Î¸qBq\theta(B) = 1 + \theta\_1B + \theta\_2B^2 + ... + \theta\_qB^qÎ¸(B)=1+Î¸1â€‹B+Î¸2â€‹B2+...+Î¸qâ€‹Bq (MA ë‹¤í•­ì‹)
* Ïµt\epsilon\_tÏµtâ€‹ ëŠ” ë°±ìƒ‰ ì¡ìŒ ê³¼ì •

#### ARIMAë¥¼ ì–´ë–»ê²Œ í™œìš©í•´ì„œ ì‘ìš©í•˜ëŠ”ê°€?

1. ë‹¨ë³€ëŸ‰ ì‹œê³„ì—´ ë¶„ì„: ê° ë³€ìˆ˜ì˜ ìì²´ì ì¸ ì‹œê³„ì—´ íŠ¹ì„±ì„ ìì„¸íˆ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. ì˜ˆì¸¡: ë‹¨ì¼ ë³€ìˆ˜ì˜ ë¯¸ë˜ ê°’ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. ì´ìƒì¹˜ íƒì§€: ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ë¥¼ í†µí•´ ì´ìƒì¹˜ë¥¼ íƒì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**íŒŒì´ì¬ ì½”ë“œ ì˜ˆì‹œ:**

```
from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt

# ARIMA ëª¨ë¸ ì ìš©
model = ARIMA(data['Y'], order=(1,1,1))
results = model.fit()

# ì˜ˆì¸¡
forecast = results.forecast(steps=10)

# ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(12,6))
plt.plot(data['Y'], label='Observed')
plt.plot(forecast, label='Forecast')
plt.legend()
plt.show()
```

### ëª¨í˜•ì˜ í•´ì„

ê²€ì • ê²°ê³¼ í•´ì„:  
1. `Xê°€ Yì— ì¸ê³¼ì˜í–¥ì„ ì£¼ê³ , YëŠ” Xì— ì¸ê³¼ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ” ê²½ìš°`: Xê°€ Yì˜ ì¸ê³¼ìš”ì¸ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.  
2. `Yê°€ Xì— ì¸ê³¼ì˜í–¥ì„ ì£¼ê³ , XëŠ” Yì— ì¸ê³¼ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ” ê²½ìš°`: Yê°€ Xì˜ ì¸ê³¼ìš”ì¸ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.  
3. `Xì™€ Yê°€ ì„œë¡œ ì¸ê³¼ì˜í–¥ì„ ì£¼ëŠ” ê²½ìš°`: ì œ3ì˜ ì™¸ë¶€ë³€ìˆ˜ê°€ ì˜í–¥ì„ ì¤¬ì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.  
4. `Xì™€ Yê°€ ì„œë¡œ ì¸ê³¼ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ” ê²½ìš°`: ë‘ ë³€ìˆ˜ ê°„ ì¸ê³¼ê´€ê³„ê°€ ì—†ê±°ë‚˜, ë‹¤ë¥¸ í˜•íƒœì˜ ê´€ê³„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

6. ì‹¤ì œ ë°ì´í„° ë¶„ì„ì˜ˆì œ
--------------

ì´ì œ ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ëœì € ì¸ê³¼ê´€ê³„, VAR, ARIMA ëª¨ë¸ì„ ì ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.

### ë°ì´í„° ì†Œê°œ

ìš°ë¦¬ê°€ ì‚¬ìš©í•  ë°ì´í„°ì…‹ì€ TV, ë¼ë””ì˜¤, ì‹ ë¬¸ ê´‘ê³  ì˜ˆì‚°ê³¼ ê·¸ì— ë”°ë¥¸ ë§¤ì¶œ ë°ì´í„°ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ 200ê°œì˜ ê´€ì¸¡ì¹˜ê°€ ìˆìœ¼ë©°, ê° ê´€ì¸¡ì¹˜ëŠ” ë‹¤ìŒ ë³€ìˆ˜ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

1. TV Ad Budget ($): TV ê´‘ê³  ì˜ˆì‚°
2. Radio Ad Budget ($): ë¼ë””ì˜¤ ê´‘ê³  ì˜ˆì‚°
3. Newspaper Ad Budget ($): ì‹ ë¬¸ ê´‘ê³  ì˜ˆì‚°
4. Sales ($): ë§¤ì¶œ

### ë°ì´í„° ì¤€ë¹„ ë° ë¶„ì„

ë¨¼ì €, í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•˜ê³  ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

**í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ**

```
# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import warnings
warnings.filterwarnings('ignore')

from statsmodels.tsa.api import VAR
import statsmodels.tsa.api as smt
from statsmodels.tsa.stattools import grangercausalitytests
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima.model import ARIMA
```

**ë°ì´í„° ë¡œë“œ**

```
# ë°ì´í„° ë¡œë“œ (ë°ì´í„°ëŠ” ì§ì ‘ ë‹¤ìš´ ë°›ì•„ì£¼ì„¸ìš”)
# https://www.kaggle.com/datasets/yasserh/advertising-sales-dataset
df = pd.read_csv("./Data/Advertising Budget and Sales.csv")

print(df.shape)
df.head()
```

![](https://velog.velcdn.com/images/euisuk-chung/post/9b420ec4-c922-4355-824b-e4fe55cb23ee/image.png)

**ì •ê·œí™” ë° ì‹œê°í™”**

```
variables = ['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)', 'Sales ($)']

# ê° ê°’ì˜ ì²« ê°’ìœ¼ë¡œ ì •ê·œí™”
df['Sales ($)'] = df['Sales ($)'] / df['Sales ($)'].iloc[0]
df['TV Ad Budget ($)'] = df['TV Ad Budget ($)'] / df['TV Ad Budget ($)'].iloc[0]
df['Radio Ad Budget ($)'] = df['Radio Ad Budget ($)'] / df['Radio Ad Budget ($)'].iloc[0]
df['Newspaper Ad Budget ($)'] = df['Newspaper Ad Budget ($)'] / df['Newspaper Ad Budget ($)'].iloc[0]
```

> â“ **ì–´? ì œê°€ ì•„ëŠ” ì •ê·œí™”ë‘ ì¡°ê¸ˆ ë‹¤ë¥¸ë°ìš”?** => ë§ìŠµë‹ˆë‹¤
>
> * ì´ëŠ” `ìƒëŒ€ì  ë³€í™” ì •ê·œí™”(ë˜ëŠ” ê¸°ì¤€ì  ì •ê·œí™”)`ë¼ê³  ë¶ˆë¦¬ë©°, ì¼ë°˜ì ì¸ ì •ê·œí™” ë°©ë²•ê³¼ëŠ” ë‹¤ë¥¸ ëª©ì ê³¼ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
> * ì´ ë°©ë²•ì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ì¼ë°˜ ì •ê·œí™”ì™€ì˜ ì°¨ì´ì ì„ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤:

> ğŸ”¶ **ìƒëŒ€ì  ë³€í™” ì •ê·œí™”ì˜ ëª©ì **
>
> * `ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„`: ì‹œê°„ì— ë”°ë¥¸ ë³€í™”ë¥¼ ë” ì‰½ê²Œ íŒŒì•…í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì´ˆê¸° ê°’ ëŒ€ë¹„ ì¦ê°€ ë˜ëŠ” ê°ì†Œë¥¼ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> * `ë³€ìˆ˜ ê°„ ìƒëŒ€ì  ë³€í™” ë¹„êµ`: ì„œë¡œ ë‹¤ë¥¸ ë‹¨ìœ„ë‚˜ ìŠ¤ì¼€ì¼ì„ ê°€ì§„ ë³€ìˆ˜ë“¤ì˜ ë³€í™”ë¥¼ ë¹„êµí•˜ê¸° ì‰½ê²Œ ë§Œë“­ë‹ˆë‹¤.
> * `ê·¸ëœì € ì¸ê³¼ì„± ë¶„ì„ì— ìœ ìš©`: ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒëŒ€ì ì¸ ë³€í™”ë¥¼ ë¹„êµí•˜ê¸° ì‰½ê²Œ ë§Œë“¤ì–´ ì¸ê³¼ê´€ê³„ ë¶„ì„ì— ë„ì›€ì„ ì¤ë‹ˆë‹¤.

> ğŸ”· **ì¼ë°˜ ì •ê·œí™”ì™€ì˜ ì°¨ì´ì **
>
> * `ë°ì´í„° ë³€í™˜ ê´€ì `:  
>   - ìƒëŒ€ì  ë³€í™” ì •ê·œí™”: ì²« ë²ˆì§¸ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë“  ê°’ì„ ë‚˜ëˆ•ë‹ˆë‹¤.  
>   - ì¼ë°˜ ì •ê·œí™”(ì˜ˆ: Min-Max): ì „ì²´ ë°ì´í„° ë²”ìœ„ë¥¼ íŠ¹ì • ë²”ìœ„(ì˜ˆ: 0-1)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
> * `ê²°ê³¼ í•´ì„ ê´€ì `:  
>   - ìƒëŒ€ì  ë³€í™” ì •ê·œí™”: ì´ˆê¸° ê°’ ëŒ€ë¹„ ë³€í™”ìœ¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  
>   - ì¼ë°˜ ì •ê·œí™”: ì „ì²´ ë°ì´í„° ë²”ìœ„ ë‚´ì—ì„œì˜ ìƒëŒ€ì  ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
> * `ë°ì´í„° ë¶„í¬ ê´€ì `:  
>   - ìƒëŒ€ì  ë³€í™” ì •ê·œí™”: ì›ë˜ ë°ì´í„°ì˜ ìƒëŒ€ì  ë³€í™” íŒ¨í„´ì„ ìœ ì§€í•©ë‹ˆë‹¤.  
>   - ì¼ë°˜ ì •ê·œí™”: ë°ì´í„°ì˜ ì „ì²´ì ì¸ ë¶„í¬ë¥¼ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
df.plot(figsize=(15,3))
plt.show()
```

![](https://velog.velcdn.com/images/euisuk-chung/post/c3a336ab-d697-4cb8-bb79-9316aecb12e2/image.png)

```
# matplotlibì˜ ê¸°ë³¸ ìƒ‰ìƒ ìˆœì„œ ì‚¬ìš©
colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

# ê° ë³€ìˆ˜ë¥¼ ë³„ë„ì˜ ì„œë¸Œí”Œë¡¯ìœ¼ë¡œ ê·¸ë¦¬ê¸°
fig, axes = plt.subplots(len(variables), 1, figsize=(15, 3*len(variables)))
fig.suptitle('Normalized Values Over Time (Subplots)', fontsize=16)

for i, var in enumerate(variables):
    axes[i].plot(df.index, df[var], label=var, color=colors[i])
    axes[i].set_title(var)
    axes[i].set_xlabel('Index')
    axes[i].set_ylabel('Normalized Value')
    axes[i].legend()
    axes[i].grid(True)

    # yì¶• ë²”ìœ„ ì„¤ì • (0ë¶€í„° ë°ì´í„°ì˜ ìµœëŒ€ê°’ê¹Œì§€)
    axes[i].set_ylim(0, df[var].max() * 1.1)  # ìµœëŒ€ê°’ì— 10% ì—¬ìœ  ì¶”ê°€

plt.tight_layout()
plt.show()
```

![](https://velog.velcdn.com/images/euisuk-chung/post/48d9e899-390b-451b-a8a6-501059d4cb32/image.png)

### ì •ìƒì„± í™•ì¸

ë³¸ê²©ì ìœ¼ë¡œ `ê·¸ëœì € ì¸ê³¼ê´€ê³„ ê²€ì •`ì„ ìˆ˜í–‰í•˜ê¸°ì— ì•ì„œ ë°ì´í„°ê°€ ì •ìƒì„±(stationary)ì„ ê°€ì§€ëŠ”ì§€ í™•ì¸ì„ í•´ì•¼í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ ë³„ë„ë¡œ ì°¨ë¶„ì„ ìˆ˜í–‰í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.  
(ì•ì— ê°œë… ë‚´ìš© ì°¸ê³ )

> 2. ì •ìƒì„±: ë°ì´í„°ëŠ” ì •ìƒì„±(stationary)ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤. ì¦‰, í‰ê· ê³¼ ë¶„ì‚°ì´ ì‹œê°„ì— ë”°ë¼ ì¼ì •í•´ì•¼ í•©ë‹ˆë‹¤.

```
from statsmodels.tsa.stattools import adfuller, grangercausalitytests

# ADF í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ì •ì˜
def adf_test(timeseries):
    result = adfuller(timeseries, autolag='AIC')
    return pd.Series({'Test Statistic': result[0], 'p-value': result[1], 'Critical Values': result[4]})

adf_results = {var: adf_test(df[var]) for var in variables}

# ADF í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥ ë° í•´ì„
for var, result in adf_results.items():
    print(f"\nADF Test Results for {var}:")
    print(result)
    
    if result['p-value'] <= 0.05:
        print(f"í•´ì„: {var}ëŠ” 5% ìœ ì˜ìˆ˜ì¤€ì—ì„œ ì •ìƒ ì‹œê³„ì—´ì…ë‹ˆë‹¤.")
    else:
        print(f"í•´ì„: {var}ëŠ” 5% ìœ ì˜ìˆ˜ì¤€ì—ì„œ ë¹„ì •ìƒ ì‹œê³„ì—´ì…ë‹ˆë‹¤.")
```

ì•„ë˜ ADF í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë³´ë©´, ëª¨ë“  ë³€ìˆ˜ë“¤ì´ 5% ìœ ì˜ìˆ˜ì¤€ì—ì„œ ì •ìƒ ì‹œê³„ì—´ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ëŠ” ê·¸ëœì € ì¸ê³¼ê´€ê³„ ë¶„ì„ì„ ìœ„í•´ ë³„ë„ì˜ ì°¨ë¶„ì´ í•„ìš”í•˜ì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

```
# ê²°ê³¼
ADF Test Results for TV Ad Budget ($):
Test Statistic                                            -14.158141
p-value                                                          0.0
Critical Values    {'1%': -3.4636447617687436, '5%': -2.876176117...
dtype: object
í•´ì„: TV Ad Budget ($)ëŠ” 5% ìœ ì˜ìˆ˜ì¤€ì—ì„œ ì •ìƒ ì‹œê³„ì—´ì…ë‹ˆë‹¤.

ADF Test Results for Radio Ad Budget ($):
Test Statistic                                            -14.129897
p-value                                                          0.0
Critical Values    {'1%': -3.4636447617687436, '5%': -2.876176117...
dtype: object
í•´ì„: Radio Ad Budget ($)ëŠ” 5% ìœ ì˜ìˆ˜ì¤€ì—ì„œ ì •ìƒ ì‹œê³„ì—´ì…ë‹ˆë‹¤.

ADF Test Results for Newspaper Ad Budget ($):
Test Statistic                                            -13.344195
p-value                                                          0.0
Critical Values    {'1%': -3.4636447617687436, '5%': -2.876176117...
dtype: object
í•´ì„: Newspaper Ad Budget ($)ëŠ” 5% ìœ ì˜ìˆ˜ì¤€ì—ì„œ ì •ìƒ ì‹œê³„ì—´ì…ë‹ˆë‹¤.

ADF Test Results for Sales ($):
Test Statistic                                            -13.990162
p-value                                                          0.0
Critical Values    {'1%': -3.4636447617687436, '5%': -2.876176117...
dtype: object
í•´ì„: Sales ($)ëŠ” 5% ìœ ì˜ìˆ˜ì¤€ì—ì„œ ì •ìƒ ì‹œê³„ì—´ì…ë‹ˆë‹¤.
```

### ê·¸ëœì € ì¸ê³¼ê´€ê³„ ê²€ì •

ê·¸ë ‡ë‹¤ë©´ ì´ì œ ê·¸ëœì € ì¸ê³¼ê´€ê³„ ê²€ì •ì„ í†µí•´ ê° ê´‘ê³  ì±„ë„ì˜ ì˜ˆì‚°ì´ ë§¤ì¶œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.

```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import grangercausalitytests
from statsmodels.tsa.api import VAR
from statsmodels.tools.eval_measures import aic, bic

def optimal_lag(data, max_lag):
    model = VAR(data)
    results = {}
    for lag in range(1, max_lag + 1):
        result = model.fit(lag)
        results[lag] = result.aic
    return min(results, key=results.get)

def granger_causality(data, variables, max_lag=12, alpha=0.05):
    results = {}
    for i in range(len(variables)):
        for j in range(len(variables)):
            if i != j:
                pair = (variables[i], variables[j])
                opt_lag = optimal_lag(data[[variables[i], variables[j]]], max_lag)
                granger_result = grangercausalitytests(data[[variables[i], variables[j]]], maxlag=opt_lag, verbose=False)
                p_values = [granger_result[lag][0]['ssr_ftest'][1] for lag in range(1, opt_lag+1)]
                
                results[pair] = {
                    'optimal_lag': opt_lag,
                    'p_values': p_values,
                    'significant': any(p < alpha for p in p_values)
                }
                
                plt.figure(figsize=(10, 6))
                plt.plot(range(1, opt_lag+1), p_values, marker='o')
                plt.axhline(y=alpha, color='r', linestyle='--')
                plt.title(f'Granger Causality: {variables[i]} -> {variables[j]}')
                plt.xlabel('Lag')
                plt.ylabel('p-value')
                plt.show()
    
    return results

# ê·¸ëœì € ì¸ê³¼ê´€ê³„ ë¶„ì„ ìˆ˜í–‰
results = granger_causality(df, variables)

# ê²°ê³¼ ì¶œë ¥
for pair, result in results.items():
    print(f"\nGranger Causality: {pair[0]} -> {pair[1]}")
    print(f"Optimal lag: {result['optimal_lag']}")
    print(f"Significant: {result['significant']}")
    print(f"p-values: {result['p_values']}")
```

**ê²°ê³¼í•´ì„**  
1. ìœ ì˜ë¯¸í•œ ê·¸ëœì € ì¸ê³¼ê´€ê³„:

* TV Ad Budget(X) -> Radio Ad Budget (Y): `2 lag`ì—ì„œ ìœ ì˜ë¯¸í•¨.
* TV Ad Budget(X) -> Sales (Y): `2 lag`ì—ì„œ ìœ ì˜ë¯¸í•¨.

2. ë‹¤ë¥¸ ê´€ê³„ë“¤:

* ëŒ€ë¶€ë¶„ì˜ ê´€ê³„ê°€ í†µê³„ì ìœ¼ë¡œ ë¬´ì˜ë¯¸í•¨.

3. ì£¼ìš” ì¸ì‚¬ì´íŠ¸:

* `TV ê´‘ê³  ì˜ˆì‚°`ì´ `ë¼ë””ì˜¤ ê´‘ê³  ì˜ˆì‚°`ê³¼ `ë§¤ì¶œ`ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì„.

![](https://velog.velcdn.com/images/euisuk-chung/post/e3dad00a-d7d1-4365-87d4-391d757e0e24/image.png)

ì´ì œ ì´ë¥¼ í™œìš©í•´ì„œ Sales Forecastingì„ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤.

1. VAR ëª¨ë¸(ë˜ëŠ” ARIMA ëª¨ë¸) ì‚¬ìš©:

* TV Ad Budgetê³¼ Salesë¥¼ í¬í•¨í•œ VAR ëª¨ë¸(ë˜ëŠ” ARIMA ëª¨ë¸) êµ¬ì¶•
* ìµœì  lagëŠ” 2ë¡œ ì„¤ì •

2. íŠ¹ì„± ì„ íƒ:

* TV Ad Budget(X)ì„ ë…ë¦½ë³€ìˆ˜, Sales(Y)ë¥¼ ì¢…ì†ë³€ìˆ˜ë¡œ ëª¨ë¸ë§í•´ë³´ê² ìŠµë‹ˆë‹¤.

### Train/Test Split

```
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.api import VAR
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error
from math import sqrt

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv("./Data/Advertising Budget and Sales.csv")
df = df[['TV Ad Budget ($)', 'Sales ($)']]

df['Sales ($)'] = df['Sales ($)'] / df['Sales ($)'].iloc[0]
df['TV Ad Budget ($)'] = df['TV Ad Budget ($)'] / df['TV Ad Budget ($)'].iloc[0]

df.columns = ['tv', 'sales'] # ê°„ë‹¨í•˜ê²Œ ì´ë¦„ ë³€ê²½

# ë°ì´í„° ë¶„í•  (80% í›ˆë ¨, 20% í…ŒìŠ¤íŠ¸)
train_size = int(len(df) * 0.8)
train, test = df[:train_size], df[train_size:]

# ê·¸ë˜í”„ ì„¤ì •
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)
fig.suptitle('Train and Test Data Visualization')

# TV Ad Budget ê·¸ë˜í”„
ax1.plot(df.index[:train_size], train['tv'], label='Train')
ax1.plot(df.index[train_size:], test['tv'], label='Test')
ax1.axvline(x=train_size, color='r', linestyle='--', label='Train/Test Split')
ax1.set_ylabel('TV Ad Budget ($)')
ax1.legend()

# Sales ê·¸ë˜í”„
ax2.plot(df.index[:train_size], train['sales'], label='Train')
ax2.plot(df.index[train_size:], test['sales'], label='Test')
ax2.axvline(x=train_size, color='r', linestyle='--', label='Train/Test Split')
ax2.set_ylabel('Sales ($)')
ax2.legend()

# xì¶• ë ˆì´ë¸” ì„¤ì •
ax2.set_xlabel('Time')

plt.tight_layout()
plt.show()
```

![](https://velog.velcdn.com/images/euisuk-chung/post/ad49feec-aadc-4569-b885-b2f9684c96c5/image.png)

### VAR (Vector Autoregression) ëª¨ë¸

ì´ì œ VAR ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ë“¤ ê°„ì˜ ë™ì  ê´€ê³„ë¥¼ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.

```
# USING VAR
lag = 2

# VAR ëª¨ë¸
model_var = VAR(train)
results_var = model_var.fit(lag)

# VAR ë™ì  ì˜ˆì¸¡
forecast_var = []
forecast_input_var = train.values[-lag:]

for i in range(len(test)):
    fc = results_var.forecast(forecast_input_var, steps=1)
    forecast_var.append(fc[0])
    
    # ì‹¤ì œ test ë°ì´í„°ì˜ ì´ì „ lag ê°’ìœ¼ë¡œ forecast_input_var ì—…ë°ì´íŠ¸
    if i + 1 < len(test):
        forecast_input_var = np.vstack([forecast_input_var[1:], test.iloc[i].values])
    
forecast_var = np.array(forecast_var)
rmse_var_sales = sqrt(mean_squared_error(test['sales'], forecast_var[:, 1]))
```

ë¹„êµë¥¼ ìœ„í•´ SALESë§Œ ê°€ì§€ê³  í•™ìŠµì„ í•œ ARIMA ëª¨ë¸ì„ í•™ìŠµì‹œì¼œë³´ê² ìŠµë‹ˆë‹¤!

### ARIMA (AutoRegressive Integrated Moving Average) ëª¨ë¸

ë§ˆì§€ë§‰ìœ¼ë¡œ, ë§¤ì¶œ ë°ì´í„°ì— ëŒ€í•´ ARIMA ëª¨ë¸ì„ ì ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.

```
train_sales = train['sales']
test_sales = test['sales']

# ARIMA ëª¨ë¸
model_arima = ARIMA(train_sales, order=(lag, 0, 0))
results_arima = model_arima.fit()

# ë™ì  ì˜ˆì¸¡ì„ ìœ„í•œ ARIMA
forecast_arima_dynamic = []
history = train_sales.tolist()

for t in range(len(test_sales)):
    model_arima_dynamic = ARIMA(history, order=(lag, 0, 0))
    model_fit_dynamic = model_arima_dynamic.fit()
    yhat = model_fit_dynamic.forecast(steps=1)[0]
    forecast_arima_dynamic.append(yhat)
    history.append(test_sales.iloc[t])

rmse_arima_sales_dynamic = sqrt(mean_squared_error(test_sales, forecast_arima_dynamic))
```

### ëª¨ë¸ ë¹„êµ

```
print("\nModel Comparison:")
print(f"VAR Model RMSE: {rmse_var_sales:.5f}")
print(f"VAR Model MSE: {mse_var_sales:.5f}")
print(f"VAR Model MAE: {mae_var_sales:.5f}")
print("-"*50)
print(f"ARIMA Model RMSE: {rmse_arima_sales_dynamic:.5f}")
print(f"ARIMA Model MSE: {mse_arima_sales_dynamic:.5f}")
print(f"ARIMA Model MAE: {mae_arima_sales_dynamic:.5f}")

# Model Comparison:
# VAR Model RMSE: 0.23431
# VAR Model MSE: 0.05490
# VAR Model MAE: 0.19481
# --------------------------------------------------
# ARIMA Model RMSE: 0.23493
# ARIMA Model MSE: 0.05519
# ARIMA Model MAE: 0.18524
```

```
# ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(12, 6))
plt.plot(test.index, test.sales, label='Actual Sales', color='black')
plt.plot(test.index, test.tv, label='Actual TV', color='orange', linestyle = '--')

plt.plot(test.index, forecast_var[:, 1], label='VAR Sales Forecast', color='blue')
plt.plot(test.index, forecast_arima_dynamic, label='Dynamic ARIMA Sales Forecast', color='red')
plt.legend()
plt.xlabel('Time')
plt.ylabel('Sales ($)')
plt.title('Sales Forecast Comparison: VAR vs Dynamic ARIMA')
plt.show()
```

![](https://velog.velcdn.com/images/euisuk-chung/post/ba927284-d979-4312-82fb-63019e19c82b/image.png)

**ë¶„ì„ í•´ì„**  
ì œê³µëœ ì„±ëŠ¥ ì§€í‘œì™€ ì‹œê°ì  ê²€í† ë¥¼ ì¢…í•©í•´ ë³¼ ë•Œ, íŠ¹ë³„íˆ ì–´ëŠ í•œ ëª¨ë¸ì´ ë” ìš°ìˆ˜í•˜ë‹¤ê³  ê²°ë¡  ë‚´ë¦¬ê¸°ëŠ” ì–´ë µìŠµë‹ˆë‹¤. ë‘ ëª¨ë¸ ëª¨ë‘ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë³´ì´ê¸° ë•Œë¬¸ì—, ìµœì¢… ëª¨ë¸ ì„ íƒì€ ë‹¤ìŒê³¼ ê°™ì€ ì¶”ê°€ì ì¸ ìš”ì†Œë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤:

1. `ëª¨ë¸ í•´ì„ì„±`: TV Ad Budget ë³€ìˆ˜ê°€ Salesì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹œë‹¤ê³  íŒë‹¨ëœë‹¤ë©´ VAR ëª¨ë¸ì´ ë” ì í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. `ëª¨ë¸ì˜ ëª©ì `: ì˜ˆì¸¡ì˜ ëª©ì ì´ ë¬´ì—‡ì¸ì§€ì— ë”°ë¼ ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¨ìˆœíˆ ê³¼ê±° Sales ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê³ ì í•œë‹¤ë©´ ë™ì  ARIMA ëª¨ë¸ì´ ë” ì í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. `ë³µì¡ë„`: VAR ëª¨ë¸ì€ ë‹¤ë³€ëŸ‰ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ë•Œë¬¸ì— ëª¨ë¸ì´ ë” ë³µì¡í•  ìˆ˜ ìˆìœ¼ë©°, ë™ì  ARIMA ëª¨ë¸ì€ ë‹¨ë³€ëŸ‰ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ë•Œë¬¸ì— ìƒëŒ€ì ìœ¼ë¡œ ë‹¨ìˆœí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. `ë°ì´í„° ê°€ìš©ì„±`: ì¶”ê°€ì ì¸ ì™¸ìƒ ë³€ìˆ˜ê°€ ìˆì„ ê²½ìš° VAR ëª¨ë¸ì´ ìœ ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë”°ë¼ì„œ, ì‹¤ì œ ì‚¬ìš© ëª©ì ê³¼ ìƒí™©ì— ë§ì¶”ì–´ ë‘ ëª¨ë¸ ì¤‘ ì í•©í•œ ê²ƒì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•©ë‹ˆë‹¤.

ê·¸ëœì € ì¸ê³¼ê´€ê³„, VAR, ARIMA ëª¨ë¸ì€ ê°ê° ì¥ë‹¨ì ì´ ìˆìœ¼ë©°, ë°ì´í„°ì˜ íŠ¹ì„±ê³¼ ë¶„ì„ ëª©ì ì— ë”°ë¼ ì ì ˆí•œ ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ë²•ë“¤ì„ ì˜ í™œìš©í•œë‹¤ë©´, ë°ì´í„°ì— ìˆ¨ê²¨ì§„ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°œê²¬í•˜ê³  ë” ë‚˜ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.

ì˜¤ëŠ˜ë„ ë„ì›€ì´ ë˜ì…¨ê¸¸ ë°”ë¼ë©° ì €ë„ ì´ë§Œ í”„ë¡œì íŠ¸ì— ì ìš©í•˜ëŸ¬ ê°€ë³´ê² ìŠµë‹ˆë‹¤! â­