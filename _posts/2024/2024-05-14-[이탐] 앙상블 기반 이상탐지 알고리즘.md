---
title: "[이탐] 앙상블 기반 이상탐지 알고리즘"
date: "2024-05-14"
tags:
  - "머신러닝"
  - "이상탐지"
year: "2024"
---

# [이탐] 앙상블 기반 이상탐지 알고리즘

원본 게시글: https://velog.io/@euisuk-chung/앙상블-기반-이상탐지-알고리즘-zdwnxkcu



앙상블 기반 이상탐지
===========

앙상블 기반 알고리즘은 여러 개의 의사결정 기반 모델을 조합하여 이상치를 탐지합니다. 이 방법은 일반적으로 높은 정확도를 제공합니다.

Isolation Forest
----------------

* **링크**: <https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html>
* **정의**: Isolation Forest는 의사결정 트리의 앙상블을 사용하여 데이터를 분할하고, 정상적인 데이터 포인트보다 이상치를 더 빠르게 '고립'시킵니다. 각 샘플이 고립되는 데 필요한 분할 횟수(경로 길이)를 측정하여 이상치 점수를 계산합니다.
* **적합한 데이터**: 다양한 유형의 이상치를 빠르게 식별할 수 있어 대규모 데이터셋에서 효과적이며, 데이터의 분포가 불균일하거나 다차원일 때 유용합니다.
* **sklearn 함수**: `sklearn.ensemble.IsolationForest`
  
  + **함수 설명**:
    
    - Isolation Forest는 무작위로 특성을 선택하고 그 특성의 임의의 분할 값을 선택하여 데이터를 분할하는 방식으로 동작합니다. 이러한 분할 과정은 트리 구조로 표현될 수 있으며, 샘플을 고립시키는 데 필요한 분할 횟수는 루트 노드에서 단말 노드까지의 경로 길이에 해당합니다.
    - 경로 길이는 데이터 포인트의 정상성을 측정하는 척도로 사용되며, 짧은 경로 길이를 가지는 샘플은 이상치일 가능성이 높습니다.
  + **매개변수**:
    
    - `n_estimators` (int, default=100): 앙상블에 사용할 기본 추정기(트리)의 수입니다.
    - `max_samples` (str, int or float, default='auto'): 각 기본 추정기를 학습할 때 사용할 샘플의 수입니다. 'auto'는 min(256, n\_samples)로 설정됩니다.
    - `contamination` (str or float, default='auto'): 데이터셋의 이상치 비율을 나타냅니다. 'auto'는 원 논문에서 제안된 값을 사용합니다.
    - `max_features` (int or float, default=1.0): 각 기본 추정기를 학습할 때 사용할 특성의 수입니다.
    - `bootstrap` (bool, default=False): True로 설정하면 부트스트랩 샘플링을 사용합니다.
    - `n_jobs` (int, default=None): 병렬로 실행할 작업의 수를 지정합니다. -1로 설정하면 모든 프로세서를 사용합니다.
    - `random_state` (int, RandomState instance or None, default=None): 난수 생성을 제어하여 결과를 재현 가능하게 합니다.
    - `verbose` (int, default=0): 학습 과정의 진행 상황을 출력합니다.
    - `warm_start` (bool, default=False): True로 설정하면 이전 호출의 결과를 초기화에 사용하여 더 많은 추정기를 추가합니다.
  + **속성**:
    
    - `estimators_`: 학습된 추정기의 리스트입니다.
    - `estimators_features_`: 각 추정기에 대해 선택된 특성의 부분 집합입니다.
    - `estimators_samples_`: 각 추정기에 대해 선택된 샘플의 부분 집합입니다.
    - `max_samples_`: 실제 사용된 샘플의 수입니다.
    - `offset_`: 원 점수에서 결정 함수를 정의하는 데 사용되는 오프셋입니다.
    - `n_features_in_`: fit 동안 본 특성의 수입니다.
    - `feature_names_in_`: fit 동안 본 특성 이름 배열입니다.
  + **메서드**:
    
    - `decision_function(X)`: 기본 분류기의 평균 이상치 점수를 계산합니다.
    - `fit(X[, y, sample_weight])`: 추정기를 학습시킵니다.
    - `fit_predict(X[, y])`: 데이터를 학습하고 해당 데이터에 대한 레이블을 반환합니다.
    - `get_metadata_routing()`: 이 객체의 메타데이터 라우팅을 가져옵니다.
    - `get_params([deep])`: 이 추정기의 파라미터를 가져옵니다.
    - `predict(X)`: 특정 샘플이 이상치인지 여부를 예측합니다.
    - `score_samples(X)`: 원 논문에서 정의된 이상치 점수의 반대를 계산합니다.
    - `set_fit_request(*[, sample_weight])`: fit 메서드에 전달된 메타데이터 요청을 설정합니다.
    - `set_params(**params)`: 이 추정기의 파라미터를 설정합니다.
  + **예시**:
    
    ```
    from sklearn.ensemble import IsolationForest
    import numpy as np
    
    # 예제 데이터
    X = [[-1.1], [0.3], [0.5], [100]]
    
    # Isolation Forest 모델 생성 및 적합
    clf = IsolationForest(random_state=0).fit(X)
    
    # 예측 라벨 출력
    print(clf.predict([[0.1], [0], [90]]))
    
    # 각 샘플의 점수 출력
    print(clf.score_samples(X))
    ```

✍️ 이 예제는 Isolation Forest를 사용하여 간단한 데이터셋에 대한 이상치 탐지를 수행하는 방법을 보여줍니다. Isolation Forest는 고차원 데이터에서 효과적으로 이상치를 탐지하며, 특히 대규모 데이터셋에서 빠르고 효율적으로 동작합니다.

