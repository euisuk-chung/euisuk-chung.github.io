---
title: "[íŒŒì´í† ì¹˜] íŒŒì´í† ì¹˜ë¡œ CNN ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ì! (ê¸°ì´ˆí¸ + DataLoader ì‚¬ìš©ë²•)"
date: "2021-11-26"
tags:
  - "PyTorch"
  - "ë”¥ëŸ¬ë‹"
year: "2021"
---

# [íŒŒì´í† ì¹˜] íŒŒì´í† ì¹˜ë¡œ CNN ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ì! (ê¸°ì´ˆí¸ + DataLoader ì‚¬ìš©ë²•)

MNIST ë°ì´í„° - CNN ì‹¤ìŠµ
==================

ì˜¤ëŠ˜ì€ MNIST ë°ì´í„°ë¡œ Convolutional Neural Network(ì´í•˜ CNN)ì„ êµ¬í˜„í•˜ê³  ëŒë ¤ë³´ëŠ” ì‹œê°„ì„ ê°–ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤!

ë¨¼ì €, CNNì€ í¬ê²Œ ì•„ë˜ì™€ ê°™ì€ êµ¬ì„±ìš”ì†Œë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.

* **í•©ì„±ê³± ì—°ì‚°(Convolution)** : ì´ë¯¸ì§€ì˜ íŠ¹ì„±ì„ ì¶”ì¶œí•˜ëŠ” ê³„ì¸µ
* **ë§¥ìŠ¤í’€ë§(Max Pooling)** : ì¶”ì¶œëœ íŠ¹ì„± ì¤‘ ì¤‘ìš”í•œ ì •ë³´ë§Œì„ ì¶•ì•½í•˜ì—¬ ì „ë‹¬
* **ì™„ì „ì—°ê²° ì‹ ê²½ë§(Fully Connected Network)** : ì¶”ì¶œëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ê³„ì¸µ

![CNN](https://velog.velcdn.com/images%2Feuisuk-chung%2Fpost%2Fd54a1393-dd17-4ddd-99a9-212e2561f3d7%2Fimage.png)

---

### Import Library

```
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.init as init

import torchvision.datasets as datasets
import torchvision.transforms as transforms

from torch.utils.data import DataLoader

import numpy as np
import matplotlib.pyplot as plt
```

---

### Set Hyperparameter

```
batch_size = 100
learning_rate = 0.0002
num_epoch = 10
```

---

### Load MNIST Data

```
mnist_train = datasets.MNIST(root="../Data/", train=True, transform=transforms.ToTensor(), download=True)
mnist_test = datasets.MNIST(root="../Data/", train=False, transform=transforms.ToTensor(), download=True)
```

---

### Define Loaders

```
train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)
test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)
```

---

### Define CNN(Base) Model

```
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        
        self.layer = nn.Sequential(
            nn.Conv2d(1, 16, 5),
            nn.ReLU(),
            nn.Conv2d(16, 32, 5),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, 5),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)          
        )
        self.fc_layer = nn.Sequential(
            nn.Linear(64 * 3 * 3, 100),                                              
            nn.ReLU(),
            nn.Linear(100, 10)                                                   
        )       
        
    def forward(self, x):
        out = self.layer(x)
        out = out.view(batch_size, -1)
        out = self.fc_layer(out)
        return out
```

---

### Define Device & Model

```
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = CNN().to(device)
```

---

### Define Loss & Optimizer

```
loss_func = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
```

---

### ğŸ‹ï¸ Train Model

ì´ì œ í•™ìŠµì„ ì‹œì‘í•´ë³´ê² ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •í•˜ê¸° ìœ„í•´ `model.train()`ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.

#### ğŸ”§ `model.train()`ì´ë€?

`model.train()`ì€ PyTorch ëª¨ë¸ì„ **í•™ìŠµ ëª¨ë“œ(training mode)**ë¡œ ì „í™˜í•©ë‹ˆë‹¤.  
ì´ëŠ” Dropout, BatchNorm ê°™ì€ **í•™ìŠµ ì¤‘ì—ë§Œ í™œì„±í™”ë˜ëŠ” ë ˆì´ì–´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ë™ì‘**ì‹œí‚¤ê¸° ìœ„í•´ í•„ìˆ˜ì ìœ¼ë¡œ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:

* **Dropout**ì€ í•™ìŠµ ì‹œ ì¼ë¶€ ë‰´ëŸ°ì„ ë¬´ì‘ìœ„ë¡œ êº¼ì„œ ê³¼ì í•©ì„ ë°©ì§€í•˜ì§€ë§Œ,
* **Batch Normalization**ì€ ë°°ì¹˜ì˜ í†µê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.

`model.train()`ì„ í˜¸ì¶œí•˜ì§€ ì•Šìœ¼ë©´ ì´ëŸ¬í•œ í•™ìŠµ íŠ¹í™” ê¸°ëŠ¥ì´ êº¼ì§„ ì±„ë¡œ í•™ìŠµì´ ì§„í–‰ë˜ê¸° ë•Œë¬¸ì— **ëª¨ë¸ì˜ ì„±ëŠ¥ì´ í˜„ì €íˆ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**

---

```
loss_arr = []

for i in range(num_epoch):
    model.train()  # í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜
    
    for j, [image, label] in enumerate(train_loader):
        x = image.to(device)
        y = label.to(device)

        optimizer.zero_grad()

        output = model(x)
        loss = loss_func(output, y)

        loss.backward()
        optimizer.step()

        if j % 1000 == 0:
            print(f"Epoch {i+1}, Step {j}: Loss = {loss.item():.4f}")
            loss_arr.append(loss.cpu().detach().numpy())
```

---

### ğŸ§ª Test Model

í•™ìŠµì´ ì™„ë£Œëœ ëª¨ë¸ì„ ë°”íƒ•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ì—¬ ì •í™•ë„ë¥¼ í‰ê°€í•´ë´…ë‹ˆë‹¤. ì´ë•ŒëŠ” ë‹¤ìŒ ë‘ ê°€ì§€ ì„¤ì •ì„ ë°˜ë“œì‹œ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

#### 1ï¸âƒ£ `model.eval()`ì´ë€?

```
model.eval()
```

* ëª¨ë¸ì„ **í‰ê°€ ëª¨ë“œ(Evaluation Mode)**ë¡œ ì „í™˜í•©ë‹ˆë‹¤.
* Dropout, BatchNorm ë“±ì˜ ë ˆì´ì–´ê°€ í•™ìŠµ ì‹œì™€ëŠ” ë‹¤ë¥´ê²Œ ì‘ë™í•˜ë„ë¡ ì„¤ì •ë©ë‹ˆë‹¤.
* ì˜ˆì¸¡ ì‹œì—ëŠ” ëª¨ë“  ë‰´ëŸ°ì„ í™œìš©í•˜ê³ , BatchNormì€ ì €ì¥ëœ í‰ê· ê³¼ ë¶„ì‚°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì¦‰, **í•™ìŠµê³¼ ì¶”ë¡ ì˜ ëª¨ë“œê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì—**, í‰ê°€ ì „ì— ë°˜ë“œì‹œ `model.eval()`ì„ í˜¸ì¶œí•´ì•¼ ì •í™•í•œ ì„±ëŠ¥ í‰ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

#### 2ï¸âƒ£ `with torch.no_grad()`ë€?

```
with torch.no_grad():
```

* Pytorchì˜ **Autograd ì—”ì§„ì„ êº¼ì„œ gradient ê³„ì‚°ì„ í•˜ì§€ ì•Šë„ë¡** ì„¤ì •í•©ë‹ˆë‹¤.
* í…ŒìŠ¤íŠ¸ë‚˜ ì¶”ë¡  ì‹œì—ëŠ” ê¸°ìš¸ê¸° ê³„ì‚°ì´ í•„ìš” ì—†ê¸° ë•Œë¬¸ì— ë©”ëª¨ë¦¬ì™€ ì†ë„ ì¸¡ë©´ì—ì„œ íš¨ìœ¨ì ì…ë‹ˆë‹¤.
* ë˜í•œ, GPU ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ê³  ì—°ì‚° ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

#### âœ… ì „ì²´ í…ŒìŠ¤íŠ¸ ì½”ë“œ

```
correct = 0
total = 0

model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì „í™˜

with torch.no_grad():  # gradient ë¹„í™œì„±í™”
    for image, label in test_loader:
        x = image.to(device)
        y = label.to(device)

        output = model(x)
        _, output_index = torch.max(output, 1)

        total += label.size(0)
        correct += (output_index == y).sum().float()

    print("Accuracy of Test Data: {:.2f}%".format(100 * correct / total))
```

---

### ë§ˆë¬´ë¦¬ ğŸ“

ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” MNIST ë°ì´í„°ì…‹ì„ í™œìš©í•´ CNN ëª¨ë¸ì„ êµ¬ì„±í•˜ê³  í•™ìŠµë¶€í„° í…ŒìŠ¤íŠ¸ê¹Œì§€ ì „ ê³¼ì •ì„ ì§„í–‰í•´ë³´ì•˜ìŠµë‹ˆë‹¤.

íŠ¹íˆ, PyTorchì—ì„œ ëª¨ë¸ì˜ í•™ìŠµê³¼ í‰ê°€ ì‹œì ì— ë”°ë¼ ë°˜ë“œì‹œ í˜¸ì¶œí•´ì•¼ í•˜ëŠ” `model.train()`, `model.eval()`, `torch.no_grad()`ì˜ ì˜ë¯¸ì™€ ì—­í• ì„ ëª…í™•íˆ ì´í•´í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

ì´ëŸ¬í•œ ê¸°ë³¸ì ì¸ íë¦„ì„ ì˜ ìµí˜€ë‘ë©´, í–¥í›„ ë³µì¡í•œ ëª¨ë¸ì—ì„œë„ í›¨ì”¬ íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í—˜ì„ ì§„í–‰í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤ ğŸ˜Š

ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆë‹¤ë©´ ëŒ“ê¸€ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš” ğŸ™Œ

ê¸´ ê¸€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!