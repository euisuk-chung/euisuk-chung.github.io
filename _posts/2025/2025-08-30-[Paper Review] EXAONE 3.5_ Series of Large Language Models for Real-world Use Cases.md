---
title: "[Paper Review] EXAONE 3.5: Series of Large Language Models for Real-world Use Cases"
date: "2025-08-30"
year: "2025"
---

# [Paper Review] EXAONE 3.5: Series of Large Language Models for Real-world Use Cases

원본 게시글: https://velog.io/@euisuk-chung/Paper-Review-EXAONE-3.5-Series-of-Large-Language-Models-for-Real-world-Use-Cases

> <https://arxiv.org/pdf/2412.04862>

```
AN, Soyoung, et al. EXAONE 3.5: Series of Large Language Models for Real-world Use Cases. arXiv e-prints, 2024, arXiv: 2412.04862.
```

Abstract
--------

이 기술 보고서는 LG AI Research에서 개발하고 공개한 EXAONE 3.5 instruction-tuned 언어 모델들을 소개합니다. EXAONE 3.5 언어 모델은 32B, 7.8B, 2.4B의 세 가지 구성으로 제공됩니다. 이 모델들은 다음과 같은 뛰어난 능력을 특징으로 합니다: 1) 실제 시나리오에서 탁월한 instruction following 능력으로 7개 benchmark에서 최고 점수 달성, 2) 뛰어난 long-context 이해력으로 4개 benchmark에서 최고 성능 달성, 3) 9개 일반 benchmark에서 유사한 크기의 최신 오픈 모델들과 비교하여 경쟁력 있는 결과 달성. EXAONE 3.5 언어 모델은 연구 목적으로 누구나 사용할 수 있으며 <https://huggingface.co/LGAI-EXAONE> 에서 다운로드할 수 있습니다. 상업적 이용을 위해서는 LG AI Research의 공식 연락처로 문의하시기 바랍니다: contact\_us@lgresearch.ai.

1. 서론
-----

78억 매개변수를 가진 EXAONE 3.0 instruction-tuned 대규모 언어 모델은 한국어와 영어에서 강력한 이중언어 능력과 탁월한 실제 성능 및 instruction-following 숙련도를 보여주었습니다. 출시 이후, 학술계와 산업계에서 다양한 피드백을 받았습니다. 예를 들어, 학술 연구자들은 고성능 컴퓨팅 인프라에 대한 제한적인 접근으로 인해 저사양 GPU에서 훈련하고 배포할 수 있는 더 작은 모델의 필요성을 강조했습니다. 산업계에서는 비용 효율성을 유지하면서도 향상된 성능을 제공하는 더 큰 모델과 기기 내 배포에 적합한 더 작은 모델에 대한 강한 수요를 표현했습니다. 또한, 참조 문서나 웹 검색 결과를 기반으로 답변을 생성하는 retrieval-augmented generation (RAG) 기술의 채택이 증가하면서, 더 긴 context를 효과적으로 처리할 수 있는 모델에 대한 상당한 수요가 있었습니다.

이 보고서에서는 사용자의 다양한 요구를 충족하기 위해 개발된 24억에서 320억 매개변수에 이르는 instruction-tuned 언어 모델 컬렉션인 EXAONE 3.5 언어 모델들을 소개합니다. EXAONE 3.5 언어 모델들은 다음을 포함합니다: 1) 소형 또는 자원이 제한된 기기에서의 배포에 최적화된 24억 모델, 2) 이전 버전과 크기는 동일하지만 향상된 성능을 제공하는 78억 모델, 3) 탁월한 성능을 제공하는 320억 모델. 모든 모델은 최대 32K 토큰의 long-context 처리를 지원합니다. 각 모델은 실제 사용 사례와 long-context 처리에서 최신 성능을 보여주며, 유사한 크기의 최근 출시된 모델들과 비교하여 일반 도메인에서 경쟁력을 유지합니다.

EXAONE 3.5 언어 모델들의 출시를 통해 연구자들이 생성형 AI의 경계를 넓히고 인간의 삶을 향상시키는 혁신적인 애플리케이션 개발에 영감을 받기를 희망합니다. 이는 LG AI Research의 사명인 "더 나은 삶을 위한 AI 발전"과 일치합니다.

2. 모델 훈련
--------

이 섹션에서는 모델 구성에 대한 상세한 정보와 pre-training 및 post-training 단계에서 사용된 방법들, 그리고 각 훈련 단계별 데이터셋 구성 과정을 설명합니다.

### 2.1 모델 구성

EXAONE 3.5 언어 모델들은 최신 decoder-only Transformer 아키텍처를 기반으로 하며, 자세한 구성은 Table 1에 설명되어 있습니다. 이 모델들은 구조적으로 EXAONE 3.0 78억 모델과 동일하지만 주로 크기 관련 구성에서 차이가 있습니다. 주목할 점은 EXAONE 3.5 언어 모델들이 long-context fine-tuning을 채택하여 최대 context 길이를 EXAONE 3.0의 4,096 토큰에서 32,768 토큰으로 확장했다는 것입니다. 세 모델 모두 대략 50% 한국어와 50% 영어로 구성된 동일한 어휘를 공유합니다.

**Table 1: EXAONE 3.5 언어 모델들의 구성**

| 모델 크기 | 32B | 7.8B | 2.4B |
| --- | --- | --- | --- |
| d\_model | 5,120 | 4,096 | 2,560 |
| 레이어 수 | 64 | 32 | 30 |
| Pre-normalization | True | True | True |
| Non-linearity | SwiGLU | SwiGLU | SwiGLU |
| Feedforward dimension | 27,392 | 14,336 | 7,168 |
| Head type | GQA | GQA | GQA |
| Head 수 | 40 | 32 | 32 |
| KV head 수 | 8 | 8 | 8 |
| Head 크기 | 128 | 128 | 80 |
| 최대 시퀀스 길이 | 32,768 | 32,768 | 32,768 |
| RoPE theta | 1,000,000 | 1,000,000 | 1,000,000 |
| Tokenizer | BBPE | BBPE | BBPE |
| 어휘 크기 | 102,400 | 102,400 | 102,400 |
| Tied word embedding | False | False | True |

### 2.2 Pre-training

Pre-training 코퍼스 데이터의 양과 계산 자원은 Table 2에 표시되어 있습니다. 데이터 구성과 모델 훈련 접근법은 두 단계로 구성됩니다: 1) 일반 도메인에서의 성능 향상을 목표로 가능한 한 다양한 소스에서 수집하고 처리된 대규모 훈련 코퍼스를 기반으로 1단계 pre-training을 수행합니다. 그 후, 2) 평가를 통해 강화가 필요한 도메인에 대해 더 많은 데이터를 수집하여 2단계 pre-training을 수행합니다. 예를 들어, 2단계에서는 long-context 이해 능력 향상에 중점을 둡니다.

**Table 2: EXAONE 3.5 언어 모델 구축을 위한 훈련 데이터 코퍼스 크기 및 계산량**

| 모델 크기 | 32B | 7.8B | 2.4B |
| --- | --- | --- | --- |
| 훈련 토큰 | 6.5T | 9T | 6.5T |
| 계산량 (FLOPs) | 1.25 × 10²⁴ | 4.21 × 10²³ | 9.36 × 10²² |

#### 2.2.1 Context 길이 확장

Context 길이를 확장하기 위해 long-context fine-tuning 기술을 사용합니다. 모델이 1단계 pre-training에서 학습한 내용을 잊어버리는 catastrophic forgetting 문제를 완화하기 위해 replay-based 방법을 적용합니다. 구체적으로, 2단계 pre-training 중에는 1단계에서 사용된 데이터의 일부를 재사용합니다. 최대 context 길이를 초과하는 문서들이 1단계에서는 더 작은 청크로 분할되었지만, 2단계에서는 모델의 context 길이를 확장하기 위해 원본 코퍼스를 청크로 나누지 않고 훈련합니다.

#### 2.2.2 Decontamination

대규모 웹 크롤링 코퍼스의 특성상, test-set 예제들이 종종 훈련 코퍼스에 나타납니다. 이러한 오염된 예제들은 일반화 성능을 해치고 테스트 메트릭을 혼란스럽게 하여 사용자에게 불공정한 평가를 제시할 가능성이 있습니다. 오염된 예제들이 EXAONE 3.5 언어 모델들의 일반화 성능을 저해하는 것을 방지하기 위해, 모든 대상 benchmark 테스트 데이터에 대해 엄격한 decontamination 과정을 적용하고 훈련 파이프라인에서 오염된 예제들을 제거했습니다.

더 엄격한 기준을 적용한 간단하지만 강력한 substring-level matching 방법을 사용했습니다. 전체 decontamination 과정은 Appendix C의 Figure 4에 설명되어 있습니다. 먼저 알파벳과 숫자를 제외한 모든 다른 문자를 제거하여 모든 test-set 예제들을 정규화한 다음, sliding window 크기 S = 50과 stride 1을 사용하여 모든 고유한 substring을 추출합니다. 훈련 예제가 오염되었는지 판단하기 위해, 정규화된 훈련 예제에서 N = 10개의 substring을 무작위로 샘플링하여 substring pool에 존재하는지 확인합니다.

#### 2.2.3 훈련 비용

대규모 언어 모델(LLM)의 pre-training 계산 비용을 고려할 때, 제한된 자원으로 가능한 한 높은 성능을 달성하여 훈련을 효율적으로 만드는 것이 필요합니다. Table 3은 EXAONE 3.5 32B 언어 모델과 유사한 크기의 다른 모델들 간의 pre-training에 필요한 총 계산량을 비교합니다. 총 계산량을 모델 크기와 훈련 토큰 수의 곱으로 단순 근사할 때, 예를 들어 Qwen 2.5 32B는 EXAONE 3.5 32B보다 2.77배 많은 계산이 필요합니다. EXAONE 3.5 언어 모델들의 주목할 만한 특징 중 하나는 다른 베이스라인 모델들보다 낮은 비용으로 훈련되었음에도 불구하고 높은 성능을 보여준다는 것입니다(Section 3 참조).

**Table 3: 모델 구축을 위한 총 계산량 비교**

| 모델 | 모델 크기 | 훈련 토큰 | 계산량 (비율) |
| --- | --- | --- | --- |
| EXAONE 3.5 | 32B | 6.5T | 1.00 |
| Qwen 2.5 | 32B | 18T | 2.77 |
| Gemma 2 | 27B | 13T | 1.69 |
| Yi 1.5 | 34B | 3.6T | 0.59 |

### 2.3 Post-training

Pre-training 이후, 모델들은 instruction-following 능력을 강화하고 인간의 선호도와 일치시키기 위한 추가 과정을 거치며, 이는 supervised fine-tuning (SFT)과 preference optimization으로 잘 알려져 있습니다.

#### 2.3.1 Supervised Fine-tuning

새롭거나 보지 못한 instruction에서 잘 수행하기 위해, 모델은 다양한 도메인에서 다양한 난이도의 instruction-response 데이터셋 쌍으로 훈련되어야 합니다. 따라서 광범위한 분야를 다루는 훈련 데이터를 구축하기 위해, Figure 1에 표시된 바와 같이 분류 체계를 사용하여 800만 웹 코퍼스에서 핵심 지식을 추출했습니다. 그 다음 추출된 지식 분류를 기반으로 instruction-tuning 데이터셋을 생성했습니다. 마지막으로, instruction evolution 방법을 활용하여 다양한 복잡성과 난이도를 가진 instruction들이 생성될 수 있도록 복잡성 수준을 다양화했습니다.

#### 2.3.2 Preference Optimization

DPO와 SimPO와 같은 Direct alignment algorithms (DAAs)를 사용하여 supervised fine-tuning 후 모델을 훈련시켜 인간의 선호도와 일치시킵니다. 합성 데이터와 사전 수집된 데이터를 사용하여 훈련을 위한 preference 데이터를 생성합니다. 응답 생성을 위해, preference 데이터에서 가져온 프롬프트 x에 대해 여러 모델에서 N개의 응답을 샘플링하고 reward 모델의 점수를 기반으로 최고 응답을 yw로, 최악 응답을 yl로 선택하여 preference 데이터 {x, yw, yl}를 생성합니다. Preference 데이터를 검증하기 위해, 추가 reward 모델을 사용하여 두 reward 모델의 순위를 기반으로 일치도를 계산하고 임계값 이하의 일치도를 가진 데이터를 필터링합니다. 우리의 preference optimization은 M0가 SFT 모델에서 초기화되는 여러 단계로 구성되어 DAAs를 통해 모델 M1과 M2를 순차적으로 훈련합니다. 이러한 단계별 파이프라인을 통해 DAAs 훈련 과정 중 발생할 수 있는 over-optimization을 완화할 수 있습니다.

### 2.4 데이터 컴플라이언스

AI 모델 개발에는 대량의 데이터가 필요하며, 이 데이터의 획득과 활용은 저작권 침해, 지적 재산권 침해, 개인정보 보호 위반 등 다양한 법적 문제로 이어질 수 있습니다. 이러한 위험을 최소화하기 위해, LG AI Research는 데이터 수집, AI 모델 훈련, 정보 제공의 전체 과정에 걸쳐 AI Compliance 검토를 수행합니다. 더 자세한 정보는 EXAONE 3.0 기술 보고서와 LG AI 윤리 원칙을 참조하시기 바랍니다.

3. 평가
-----

이 섹션에서는 다양한 benchmark 데이터셋에서 EXAONE 3.5 언어 모델들의 평가 설정과 결과를 제시합니다. 우리 모델들의 benchmark 성능을 비교하기 위해 최근 출시된 오픈 언어 모델들을 베이스라인으로 선택했습니다. 모든 베이스라인과 그들의 상세한 정보는 Appendix D.1에 설명되어 있습니다.

### 3.1 Benchmarks

사용자 의도의 다양한 특성을 고려할 때, instruction-tuned 모델이 무엇이든 사용자의 쿼리에 맞춰 응답을 생성하는 것이 중요합니다. 포괄적이고 다양한 시나리오에서 우리 모델들을 평가하기 위해, 몇 가지 자체 benchmark와 함께 12개 이상의 평가 benchmark를 선택했습니다. Table 4는 세 개의 카테고리로 그룹화할 수 있는 모든 benchmark를 요약합니다:

• **실제 사용 사례 (Section 3.3)**: 다양한 사용자 instruction을 이해하고 수행하는 능력이 필요한 benchmark들  
• **Long Context (Section 3.4)**: long context를 이해하는 능력을 평가하는 benchmark들  
• **일반 도메인 (Section 3.5)**: LLM들이 가져야 할 일반 도메인 능력을 포괄하는 benchmark들. 구체적으로, 이 카테고리는 수학 문제를 푸는 능력, 소스 코드를 작성하는 능력, LLM에 내장된 parametric knowledge를 측정하는 benchmark들을 포함합니다.

### 3.2 전체 성능

세 카테고리에 대한 전체 성능 결과가 Table 5에 제시되어 있습니다. 32B와 78억 크기의 EXAONE 3.5 언어 모델들은 베이스라인 모델들과 비교하여 실제 사용 사례와 Long Context 카테고리에서 최고 성능을 보이며, 일반 도메인 카테고리에서는 경쟁력 있는 결과를 보여줍니다. 가장 작은 모델인 EXAONE 3.5 24억은 세 카테고리 모두에서 유사한 크기의 베이스라인들을 능가하여 강력한 성능을 보여줍니다. 놀랍게도, 24억 모델은 작은 크기에도 불구하고 일반 도메인에서 Qwen 2.5 7B를 제외하고는 더 큰 크기(<90억)의 베이스라인들과 비교해도 더 나은 성능을 보였습니다. 최근 smaller large language models (sLLM)에 대한 수요 증가를 고려할 때, EXAONE 3.5 24억 모델이 학술적 및 산업적 사용에서 높은 경쟁력을 갖출 수 있다고 믿습니다.

### 3.3 실제 사용 사례

실제 사용 사례 카테고리의 경우, 사용자가 챗봇 모델에 제출할 수 있는 실제 쿼리를 나타내는 7개의 benchmark를 컴파일했습니다. MT-BENCH, KOMT-BENCH, LOGICKOR에서는 multi-turn으로 구성된 모델의 응답이 judge 모델에 의해 평가됩니다. ARENA-HARD와 ALPACAEVAL의 경우, 대상 언어 모델의 응답이 참조 모델(각각 gpt-4-0314와 gpt-4-1106-preview)의 응답과 judge 모델에 의해 비교되어 승률을 기록합니다. LIVEBENCH (ver. 2024-08-31)와 IFEVAL (prompt-strict)는 모델의 응답이 ground-truth 응답과 일치시켜 사용자 instruction에 얼마나 잘 부합하는지 평가합니다.

Table 6에 제시된 바와 같이, 우리의 세 모델은 32B 모델의 LIVEBENCH를 제외하고는 유사한 크기의 모든 베이스라인에서 모든 benchmark에서 최고 성능을 보였습니다. 또한, 영어와 한국어 benchmark 모두에서 다른 모델들을 능가함으로써 EXAONE 3.5 언어 모델들의 뛰어난 이중언어 능력을 보여줍니다.

### 3.4 Long Context

Long context를 처리하고 이해하는 능력은 더 복잡한 시나리오에서의 활용을 가능하게 하므로 현대 LLM들에게 점점 중요해지고 있습니다. EXAONE 3.5 언어 모델들의 long context 성능을 보여주기 위해, long context 입력을 위한 합성 작업을 위해 설계된 benchmark와 함께 다양한 retrieval-augmented generation (RAG) benchmark들을 사용하여 모델들을 평가합니다.

#### 3.4.1 Needle-in-a-Haystack

Needle-in-a-Haystack (NIAH)는 모델이 긴 문서 내의 무작위 위치에 숨겨진 정보를 얼마나 효과적으로 찾고 검색할 수 있는지 평가하는 benchmark 역할을 합니다. 32K 토큰까지 long context에서 정보를 처리하고 검색하는 모델들의 능력을 종합적으로 평가했습니다. 또한, NIAH를 한국어로 확장하여 영어와 한국어 context 모두에서 모델들의 long context 처리 능력을 평가하는 데 활용했습니다.

Figure 3은 우리 모델들이 영어와 한국어 모두에서 테스트된 모든 문서 깊이와 context 길이에서 대상 정보 검색에 거의 완벽한 정확도를 달성한다는 것을 보여줍니다. 이러한 결과는 특히 정확한 정보 검색과 복잡한 추론을 요구하는 작업에서 강력한 long context 처리 능력을 강조합니다.

#### 3.4.2 Long Context Understanding

Long context 이해 능력을 평가하기 위해, LONGBENCH와 LONGRAG를 포함한 benchmark들을 사용하여 모델들을 평가했습니다. LongRAG에서 unanswerable case를 확장하여 더 도전적으로 만들었습니다. 또한 한국어에서의 long context 이해를 평가하기 위해 LONGRAG의 한국어 버전인 KO-LONGRAG를 구축했습니다. 실제 웹 검색 결과를 사용하여 어려운 질문에 답변해야 하는 더 현실적인 RAG 시나리오를 위해 KO-WEBRAG benchmark를 구축했습니다.

Table 7에 표시된 바와 같이, EXAONE 3.5 언어 모델들은 32B와 78억 모델의 LongBench를 제외하고는 다른 모델들보다 뛰어난 성능을 보였습니다. benchmark 전체의 평균에서 우리의 세 모델은 모든 베이스라인을 능가하여, 복잡하고 확장된 context를 효과적으로 처리하는 능력을 확인했습니다.

### 3.5 일반 도메인

언어 모델들은 이제 수학 문제 해결이나 소스 코드 프로그램 작성과 같은 다양한 일반 도메인에서 인간 수준의 능력을 달성하는 것이 기대됩니다. 일반 도메인에서의 전체 성능을 평가하기 위해, 세 가지 주요 도메인에서 9개의 benchmark를 선택했습니다: 1) 수학을 위한 GSM8K (CoT)와 MATH (CoT), 2) 코딩을 위한 HUMANEVAL (Evalplus base)와 MBPP (Evalplus base), 3) LLM에 내장된 지식량을 평가하기 위한 MMLU (CoT), KMMLU (CoT), GPQA (CoT), ARC-C, BBH (CoT).

챗봇 모델이 일반적으로 사용자로부터 단일 쿼리를 받는 실제 시나리오를 더 잘 시뮬레이션하기 위해, 일반 도메인 카테고리의 모든 benchmark를 0-shot 설정을 사용하여 평가했습니다. 이를 위해 특정 답변 형식을 요구하는 instruction으로 언어 모델들에 프롬프트를 제공하고 응답에서 최종 답변을 파싱했습니다. 공정한 비교를 위해, 모든 모델에서 동일한 프롬프트를 사용했습니다.

Table 8은 일반 도메인 카테고리의 benchmark들에서 EXAONE 3.5 언어 모델들과 베이스라인 모델들의 결과를 보여줍니다. benchmark 전체의 평균에서, 32B와 78억 크기의 EXAONE 3.5 언어 모델들은 유사한 크기의 베이스라인들과 비교하여 경쟁력 있는 성능을 보여줍니다. 반면, EXAONE 3.5 24억 모델은 평균 점수에서 모든 베이스라인을 능가했습니다.

4. 책임감 있는 AI
------------

EXAONE 3.5 언어 모델들은 광범위한 사용자들에게 제공될 것의 특성을 고려하여 데이터 거버넌스, 윤리적 고려사항, 위험 관리를 포괄하는 책임감 있는 AI 개발 프레임워크에 따라 개발되었습니다. 오픈 모델의 특성상 결국 다양한 도메인에서 광범위하게 사용될 것이므로, LG AI 윤리 원칙에서 요구하는 인간성, 공정성, 안전성, 책임성, 투명성을 보장하면서 사회적 이익을 최대화하는 것을 목표로 합니다.

### 4.1 이익

EXAONE 3.5 언어 모델들은 AI 연구 발전을 목표로 연구 목적으로 개방되어 있습니다. EXAONE 3.0 78억 모델 출시 이후 받은 피드백을 바탕으로, 이제 24억, 78억, 320억의 더 다양한 크기의 모델을 제공합니다. 이를 통해 연구자들이 연구 목적과 컴퓨팅 환경에 최적화된 모델을 선택할 수 있게 됩니다. 이러한 유연성이 기초 연구부터 도메인 특화 애플리케이션까지 광범위한 스펙트럼을 지원하기를 희망합니다. 또한 이전 버전보다 상당한 성능 향상을 기반으로 생성형 AI의 발전에 긍정적으로 기여할 것으로 기대됩니다.

출시의 신뢰성을 보장하기 위해, 고품질 데이터를 보장하는 표준화된 데이터 컴플라이언스 프로토콜을 구현했습니다. 이러한 표준화된 접근법은 연구자들이 향후 다양한 연구 분야에서 모델을 사용할 수 있는 신뢰할 수 있는 기반을 제공합니다.

외부 사용자들이 다양한 도메인에서 EXAONE 3.5 언어 모델들을 활용할 수 있지만, 구체적인 사용자 요구를 정확히 식별하는 것은 어려웠습니다. 이를 해결하기 위해, 광범위한 도메인에서의 적용 가능성에 대한 광범위한 검토를 수행했습니다. 또한, 비즈니스 및 연구 팀을 포함한 LG 계열사들과 긴밀히 협력하여 특정 사용자 요구사항에 더 잘 맞추었습니다.

### 4.2 위험과 완화

오픈 모델은 AI 커뮤니티에 긍정적으로 기여할 수 있지만, 책임감 있는 사용을 보장하는 데 어려움이 있습니다. 사회적으로 소외된 집단에 대한 의도하지 않은 불평등과 차별, 유해한 콘텐츠 생성, 사용자의 악의적 오용과 같은 잠재적 위험을 식별하기 위해 AI 윤리 영향 평가를 수행했습니다. 이 평가를 통해 식별된 잠재적 위험을 완화하기 위해 다양한 정책과 연구 이니셔티브를 채택했습니다.

첫째, 데이터 측면에서는 개인정보 보호와 보안을 강화하기 위해 모든 후보 데이터셋에 대한 법적 위험 평가를 실시했습니다. 결과를 바탕으로 각 데이터셋의 훈련 적합성을 결정하고 적격한 데이터셋에서 민감한 데이터를 제거하는 비식별화 과정을 수행했습니다. 훈련 데이터의 편향을 최소화하고 데이터 품질을 보장하기 위해, 모든 전처리 단계를 문서화하고 표준화된 데이터 처리 프로토콜을 채택했습니다. 모든 데이터의 대표성을 검증하는 실질적인 어려움을 고려하여, 소규모 데이터 샘플에 대한 정성적 평가를 수행했습니다. 정량적 평가를 위해서는 모델 훈련 완료 후 성능 평가를 통해 데이터 부분집합을 검증하여 데이터 관련 위험을 최소화하려고 노력했습니다. 또한, 모델 개발에 사용된 오픈소스 라이브러리들을 신중히 검토했습니다.

AI 윤리적 고려사항과 규제 요구사항의 수준은 사용자의 다양한 요구와 특성(예: 거주 국가, 연령 등)에 따라 달라질 수 있습니다. 이를 해결하기 위해, 글로벌 AI 규제를 지속적으로 모니터링하고 잠재적인 규제 위반을 피하기 위해 필요에 따라 즉각적인 조치를 취할 것입니다. AI 모델의 의사결정 과정의 투명성 부족은 사용자와 이해관계자들 사이의 신뢰를 감소시킬 수 있습니다. 이러한 한계를 해결하기 위해, 우리는 약점과 개선 영역을 식별하기 위해 모델의 성능을 지속적으로 분석하고 평가합니다. AI 모델의 의사결정 과정을 완전히 설명하는 것은 여전히 어렵지만, 지속적인 연구를 통해 설명 가능성을 발전시키기 위해 노력하고 있습니다.

### 4.3 안전성

한국 과학기술정보통신부와 한국정보화진흥원(NIA)에서 제공하는 제3자 데이터셋인 한국어 대규모 언어 모델 신뢰성 벤치마크 데이터를 사용하여 EXAONE 3.5 언어 모델들의 윤리와 보안에 대한 포괄적인 평가를 수행했습니다. 이 데이터셋은 언어 모델의 무해성을 평가하기 위해 특별히 설계되었습니다. 평가 결과는 Table 9에 제시되어 있습니다. 성능을 측정하기 위해, 모델에게 5개 옵션 중 하나를 선택하도록 요청했습니다. 선택된 옵션이 정답 집합에 포함되면 정답으로 점수를 매겼습니다. 제공된 데이터셋에서 처음 두 옵션은 "거짓"으로, 나머지 세 개는 "참"으로 라벨이 붙어 있었습니다. 옵션 순서로 인한 잠재적 편향을 완화하기 위해, 각 평가마다 옵션 순서를 무작위로 섞었습니다. 실험 결과는 유해한 반응을 필터링하는 데 효과성을 보여주었지만, 여전히 개선의 여지가 있습니다.

5. 한계
-----

EXAONE 3.5 언어 모델들은 기존의 모든 언어 모델들과 마찬가지로 특정한 한계가 있으며 때때로 부적절한 응답을 생성할 수 있습니다. 언어 모델은 토큰의 출력 확률을 기반으로 응답을 생성하며, 이는 훈련 데이터에서의 학습 중에 결정됩니다. 훈련 데이터에서 개인적, 유해한, 편향된 정보를 제외하기 위해 모든 노력을 기울였지만, 일부 문제가 있는 콘텐츠가 여전히 포함되어 바람직하지 않은 응답으로 이어질 수 있습니다. EXAONE 3.5 언어 모델들이 생성하는 텍스트는 LG AI Research의 견해를 반영하지 않는다는 점을 유의하시기 바랍니다.

• 개인적, 유해한 또는 기타 부적절한 정보를 포함하는 부적절한 답변이 생성될 수 있습니다.  
• 나이, 성별, 인종 등과 관련된 편향된 응답이 생성될 수 있습니다.  
• 생성된 응답은 훈련 데이터의 통계에 크게 의존하므로, 의미적으로나 구문적으로 잘못된 문장이 생성될 수 있습니다.  
• 모델들이 최신 정보를 반영하지 않으므로, 응답이 거짓이거나 모순적일 수 있습니다.

LG AI Research는 EXAONE 3.5 언어 모델들로부터 발생할 수 있는 잠재적 위험을 줄이기 위해 노력합니다. 사용자들은 EXAONE 3.5 언어 모델들을 사용할 때 LG AI의 윤리 원칙을 위반하는 부적절한 출력 생성을 유도할 수 있는 악의적 활동(예: 불법 정보 입력)에 참여해서는 안 됩니다.

6. 배포
-----

Appendix의 Section B는 EXAONE 3.5 언어 모델들 사용을 위한 라이선스 정보를 제공합니다. 언어 모델의 법적 활용을 위해서는 라이선스 정보를 이해하는 것이 필수적입니다.

7. 결론
-----

학계와 산업계의 증가하는 관심에 응답하여, 실제 사용 사례와 long-context 이해에서 뛰어난 성능을 보이는 EXAONE 3.5 언어 모델들을 출시하게 되어 기쁩니다. 이 모델들은 세 가지 크기(32B, 7.8B, 2.4B)로 제공됩니다.

실제 사용 사례 시나리오에서 우리 모델들의 성능을 검증하기 위해, 다양한 instruction 이해가 필요한 7개의 benchmark에서 모델들을 평가했습니다. Long-context 이해를 평가하기 위해, 4개의 benchmark에서 모델들을 평가했습니다. 우리 모델들은 두 카테고리 모두에서 일관되게 뛰어난 성능을 보였습니다. 또한, 우리 모델들은 수학 문제 해결과 코드 작성을 포함한 일반 도메인에서 경쟁력 있는 성능을 보였습니다. 특히, 우리의 24억 모델은 일반 도메인에서 평균 점수 1위를 차지했습니다.

우리 모델들은 연구 목적으로 모든 분들에게 제공되며, 모델 개선에 도움이 될 피드백을 환영합니다. 피드백이 있거나 우리 모델들과의 상업적 기회 탐색에 관심이 있으시면 contact\_us@lgresearch.ai로 연락해 주시기 바랍니다.