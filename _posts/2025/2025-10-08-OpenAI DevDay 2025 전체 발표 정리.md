---
title: "OpenAI DevDay 2025 전체 발표 정리"
date: "2025-10-08"
year: "2025"
---

# OpenAI DevDay 2025 전체 발표 정리


> <https://x.com/OpenAI/status/1974972945949987096>

DevDay Introduction - 개막 인사
---------------------------

샌프란시스코 Fort Mason에서 **OpenAI DevDay 2025**가 개최되었습니다. Sam Altman CEO는 OpenAI가 시작된 도시이자 AI의 미래를 구축하기로 약속한 샌프란시스코에서 개발자들을 환영했습니다. 2023년 첫 DevDay 이후 거의 2년이 지난 시점에서, 그간의 여정을 돌아보고 새로운 발표를 준비하는 개막 순서였습니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/63749475-9d75-42a2-9f8e-21e65f5fc471/image.png)

> <https://youtu.be/hS1YqcewH0c>

---

OpenAI Growth - 폭발적인 성장 지표
--------------------------

### 2023년 첫 DevDay 당시

* **개발자 수**: 200만 명
* **주간 ChatGPT 사용자**: 1억 명
* **API 토큰 처리량**: 분당 3억 개

![](https://velog.velcdn.com/images/euisuk-chung/post/6ad58999-f531-4ca0-9c0c-99bc2846ec2e/image.png)

### 2025년 현재

* **개발자 수**: 400만 명 (2배 증가)
* **주간 ChatGPT 사용자**: 8억 명 이상 (8배 증가)
* **API 토큰 처리량**: 분당 60억 개 (20배 증가)

![](https://velog.velcdn.com/images/euisuk-chung/post/7f1b8575-e173-4fe2-be29-25c5ba901c20/image.png)

> 이러한 수치들의 변화량은 AI가 "사람들이 가지고 놀던 것"에서 "사람들이 매일 개발하는 도구"로 완전히 전환되었음을 보여줍니다.

---

Announcement Overview - 오늘의 발표 개요
---------------------------------

![](https://velog.velcdn.com/images/euisuk-chung/post/1f2f82d4-01d3-4cde-84de-6347e872f699/image.png)

Sam Altman은 개발자들의 피드백을 철저히 반영한 **네 가지 핵심 발표**를 예고했습니다:

![](https://velog.velcdn.com/images/euisuk-chung/post/5ab2bc5c-a432-4a2f-8143-1f11865c8473/image.png)

### 1. ChatGPT 내 앱 구축

* ChatGPT 안에서 앱을 만들 수 있는 방법
* 대규모 배포(distribution) 지원

### 2. 에이전트 개발 혁신

* 에이전트 구축을 더 빠르고 효과적으로

### 3. 소프트웨어 작성 혁신

* 반복적인 코딩 작업을 AI가 담당
* 개발자는 시스템과 창의성에 집중

### 4. 모델 및 API 업데이트

* 모든 개발 작업을 뒷받침할 기반 기술

Sam은 "이것은 역사상 빌더가 되기에 최고의 시기"라며, "아이디어에서 제품까지 이렇게 빠른 적이 없었다"고 강조했습니다.

---

Apps in ChatGPT - ChatGPT 앱 생태계
-------------------------------

### ChatGPT의 진화 방향

OpenAI는 ChatGPT를 사람들이 더 생산적이고, 더 창의적이며, 더 빠르게 배울 수 있도록 돕는 도구로 만들어왔습니다.

첫 DevDay 이후 지속적으로 개발자에게 ChatGPT를 개방해왔으며:

* **GPTs 출시**: 맞춤형 챗봇 생성 기능
* **MCP 표준 채택**: Model Context Protocol로 다양한 애플리케이션 연결
* **학습과 실험**: 어떤 것은 성공하고 어떤 것은 실패했지만, 많은 것을 배움

### 새로운 비전: Apps inside ChatGPT

이제 개발자들은 ChatGPT 안에 완전한 앱을 구축할 수 있습니다.  
이는 다음과 같은 특징을 가진 차세대 애플리케이션을 가능하게 합니다:

* **대화형(Interactive)**: 사용자와 자연스러운 대화 가능
* **적응형(Adaptive)**: 컨텍스트에 따라 동적으로 반응
* **개인화(Personalized)**: 사용자별 맞춤 경험 제공
* **채팅 가능(Chattable)**: 모든 기능이 대화로 제어 가능

---

Apps SDK Launch - Apps SDK 정식 출시
--------------------------------

### Apps SDK의 핵심 기능

프리뷰로 제공되는 **Apps SDK**는 완전한 풀스택 개발을 지원합니다:

![](https://velog.velcdn.com/images/euisuk-chung/post/924a6707-3d8d-459d-a339-ac9736877cf4/image.png)

![](https://velog.velcdn.com/images/euisuk-chung/post/6e09d6b3-4c70-414d-966a-1702345faa92/image.png)

> <https://developers.openai.com/apps-sdk/>

**1. 백엔드 통합**

* 데이터 연결: 실시간 데이터베이스 및 API 연동
* 액션 트리거: 외부 서비스 호출 및 트랜잭션 실행
* 비즈니스 로직: 서버 사이드 처리 완전 제어

**2. 프론트엔드 렌더링**

* 완전한 대화형 UI 구현
* HTML/CSS/JavaScript 전체 스택 활용
* 반응형 컴포넌트 설계

**3. MCP 기반 아키텍처**

* Model Context Protocol 표준 기반
* 백엔드 로직과 프론트엔드 UI에 대한 완전한 제어
* 오픈 표준으로 누구나 통합 가능

![](https://velog.velcdn.com/images/euisuk-chung/post/a7b33f3f-3b79-4b18-ade2-d17f44da829d/image.png)

### 배포 및 도달 범위

Apps SDK로 구축한 앱은:

* **수억 명의 ChatGPT 사용자**에게 즉시 도달
* 개발자의 제품 확장에 있어 "big deal"이 될 것
* 기존 제품 구독자는 대화 내에서 바로 로그인 가능

### 수익화 계획

향후 다양한 수익화 방법 지원 예정:

* 기존 구독 모델 연동
* **Agentic Commerce Protocol**: ChatGPT 내 즉시 결제 기능
* 추가 수익화 옵션은 순차적으로 공개 예정

### 예시

![](https://velog.velcdn.com/images/euisuk-chung/post/fc63269d-62ba-4ca6-9dd3-dc3023106309/image.png)

> Example - Figma App

![](https://velog.velcdn.com/images/euisuk-chung/post/902e6d8f-ca5e-45df-a295-4df2e77e3f8e/image.png)

> Example - Spotify App

---

Live Demo Start - 실시간 데모 시작
---------------------------

Alexi(ChatGPT 소프트웨어 엔지니어)가 무대에 올라 실제 작동하는 앱들을 직접 시연했습니다.

* 그는 "이 앱들의 마법은 풍부한 대화형 비주얼과 ChatGPT의 파워를 결합하는 것"이라고 소개했습니다.

### Coursera Demo - 교육 앱 통합 사례

**첫 번째 사용: 앱 연결**

사용자가 아래와 같이 요청하면:

> 👤 **사용자** : "Coursera, teach me something about machine learning"

1. **최초 동의(Consent)**: 처음 사용 시 Coursera 앱 연결 동의 필요
2. **자동 로그인**: 이후부터는 즉시 접근 가능
3. **앱 발견**: 사용자가 직접 요청하거나, ChatGPT가 대화 맥락에 따라 자동 제안

![](https://velog.velcdn.com/images/euisuk-chung/post/7ca66b1d-9fa6-4fab-b10f-86f06b8302a5/image.png)

**인라인 비디오 경험**

Coursera 앱은 대화 내에서 **인라인**으로 표시(채팅 내부에서 동영상 시청 가능)되며:

* **비디오 재생**: 웹에서 렌더링 가능한 모든 콘텐츠 지원
* **Picture-in-Picture**: 비디오가 화면 상단에 고정
* **동시 대화**: 비디오를 보면서 동시에 대화 가능

![](https://velog.velcdn.com/images/euisuk-chung/post/af1a2a3f-05ab-42c2-bd8b-83d38a9acb62/image.png)

**Talking to Apps: 컨텍스트 인식**

가장 혁신적인 기능은 "Talking to Apps"입니다:

> 👤 **사용자**: "Can you explain more about what they are saying right now"

![](https://velog.velcdn.com/images/euisuk-chung/post/15d123e4-8f16-4290-af17-dd7737c4b664/image.png)

Apps SDK는 앱이 **현재 사용자가 보고 있는 컨텍스트**를 ChatGPT에 노출하는 API를 제공합니다.

이를 통해:

* ChatGPT가 **비디오의 특정 시점**을 정확히 이해
* 사용자가 별도 설명 없이도 질문 가능
* **데이터 준비 단계**에 대한 설명 등 컨텍스트 기반 답변 제공

이는 ChatGPT를 활용한 학습 경험이 더욱 풍부해지는 사례로, 전 세계 사용자를 위한 새로운 교육 경험을 가능하게 합니다.

---

### Canva Demo - 창작 도구 통합

**대화 기반 디자인 워크플로우**

사용자가 동생의 반려견 산책 사업을 위한 아이디어를 브레인스토밍하던 중:

* 원하는 사업체 명(Walk This Wag)으로 포트폴리오 제작을 해보고자 함.

> 👤 **사용자**: "Canva, make me a portfolio with this "Walk This Wag" name. I want it to be colorful, whimsical and bright, and ask Coursera for a typing course, prefer sans-serif font."

![](https://velog.velcdn.com/images/euisuk-chung/post/c5733719-f9eb-4dce-9f0f-3c71cde98373/image.png)

**인라인에서 전체화면으로**

Canva가 여러 포스터 옵션을 생성하면:

![](https://velog.velcdn.com/images/euisuk-chung/post/ba700cbb-e1a7-4fa8-ad1d-466effe93044/image.png)

1. **인라인 뷰**: 대화 내에서 여러 디자인 옵션 확인
2. **전체화면 확장**: 특정 포스터를 클릭하여 상세 보기
3. **ChatGPT를 통한 수정**: "좀 더 밝게", "폰트 변경" 등 자연어로 요청
4. **이미지 생성 경험과 유사**: 기존 DALL-E 워크플로우와 일관된 경험

**실시간 콘텐츠 변환**

![](https://velog.velcdn.com/images/euisuk-chung/post/76a15d76-5739-4745-bea7-dc67b6a93aad/image.png)

> 👤 **사용자**: "Canva please make this poster into a pitch deck, we're trying to raise a seed round for dog walking."

몇 초 만에 포스터가 완전한 프레젠테이션 슬라이드 덱으로 변환됩니다.

이는:

* **마케팅 자료 제작**: OpenAI 마케팅 자산 생성
* **데모 준비**: DevDay 발표용 자료
* **창업 자료**: 시드 라운드 피칭 덱

![](https://velog.velcdn.com/images/euisuk-chung/post/4ece8874-27a1-4c49-a627-6bfa5fe38609/image.png)

모든 것이 대화 내에서 실시간으로 이뤄집니다.

---

### Zillow Demo - 복합 워크플로우 사례

**컨텍스트 연속성**

* ChatGPT는 이전 대화를 기억 기능을 활용하여, 반려견 산책 사업 위치를 추천함.

![](https://velog.velcdn.com/images/euisuk-chung/post/206e8afb-8589-46c3-a0fd-95e26595faaf/image.png)

* 새 대화에서도 원하는 답변을 충실하게 답하는 것을 볼 수 있음.

> 👤 **사용자**: "Where should we expand?"  
> 🤖 **ChatGPT**: "Pittsburgh!" (매우 열정적으로 추천)

* 이제 시연자는 해당 지역의 집을 추천 받고자 합니다.

> 👤 **사용자**: "zillow, Show me homes for sale there"

![](https://velog.velcdn.com/images/euisuk-chung/post/2143ea21-0b77-4e35-b582-63010d02b462/image.png)

> (참고) Zillow는 미국 최대의 온라인 부동산 마켓플레이스로, 집을 사거나, 임대하거나, 판매하는 데 필요한 매물 정보, 데이터, 계산기 등 다양한 도구를 제공하는 웹사이트 및 서비스입니다.
>
> * 한국의 직방이나 다방과 유사한 플랫폼으로, 미국 부동산 시장의 정보를 통합하고 사용자에게 부동산 거래를 위한 편의성을 제공하는 것을 목표로 합니다.

**동적 데이터 로딩**

Zillow 앱이 호출되면:  
1. **최신 데이터 페칭**: 실시간 부동산 정보 가져오기  
2. **대화형 지도 임베딩**: ChatGPT 내 인터랙티브 맵 표시  
3. **매물 목록**: 여러 주택이 지도에 표시됨

![](https://velog.velcdn.com/images/euisuk-chung/post/cc06221e-d8b8-4e5d-a855-01ea8f2afd7b/image.png)

**뷰 전환: 인라인 → 전체화면**

인라인 지도가 작아서 보기 어려운 경우:

* 특정 주택 클릭 → 전체화면 열기
* Zillow의 **대부분 기능이 ChatGPT에 임베딩**됨
* 투어 요청, 저장, 공유 등 일반적인 Zillow 액션 가능

![](https://velog.velcdn.com/images/euisuk-chung/post/61da0c5a-347b-4cbf-825a-ff11e920cfe8/image.png)

**자연어 필터링**

> 👤 **사용자**: "Filter this to just the three bedroom homes with a yard"

전체화면 상태에서:

* 새 인스턴스 생성 없이 **기존 앱이 업데이트**됨
* 데이터가 실시간으로 필터링됨
* ChatGPT 메시지가 앱 위에 오버레이로 표시

![](https://velog.velcdn.com/images/euisuk-chung/post/66536bce-8b53-47c2-b7f3-766a49a2d049/image.png)

### 컨텍스트 기반 질문

특정 주택을 확대한 후:

> 👤 **사용자**: "How close is this to a dog park?"

Zillow 앱이 현재 사용자가 보고 있는 주택 정보를 ChatGPT에 노출하므로:

* ChatGPT는 **어떤 주택인지 정확히 인식**
* Zillow 컨텍스트와 웹 검색 도구를 **조합**
* 해당 주택과 가까운 개 공원 정보 제공
* 다른 도구(예: 대출 계산기) 호출 가능

![](https://velog.velcdn.com/images/euisuk-chung/post/4257c13d-7232-4227-b3f6-1e0f489ba458/image.png)

이는 Apps SDK 경험이 얼마나 **동적**이고 **컨텍스트 인식적**인지 보여주는 완벽한 사례입니다.

---

Launch Partners - 출시 파트너 소개
---------------------------

데모에서 본 앱들과 추가 파트너들이 **오늘부터 ChatGPT에서 이용 가능**합니다:

### 확정된 파트너

* **Booking.com**: 여행 및 숙박 예약
* **Canva**: 디자인 및 창작 도구
* **Coursera**: 교육 콘텐츠
* **Expedia**: 여행 플랫폼
* **Figma**: 디자인 협업
* **Spotify**: 음악 플레이리스트
* **Zillow**: 부동산 검색

### 예정된 파트너 (곧 추가될 예정)

* **AllTrails**: 하이킹·러닝·자전거 등 야외 활동 경로 탐색 플랫폼
* **DoorDash**: 음식 배달 및 로컬 상점 배송 서비스
* **Khan Academy**: 무료 온라인 교육 플랫폼 (수학, 과학, 인문 등)
* **Instacart**: 식료품 장보기 및 배달 서비스
* **Peloton**: 홈 피트니스 및 운동 콘텐츠 제공
* **OpenTable**: 레스토랑 예약 플랫폼
* **Target**: 미국 대형 리테일 유통업체
* **thefork**: 레스토랑 예약 플랫폼 (Tripadvisor 계열)
* **Tripadvisor**: 여행 후기 및 예약 플랫폼
* **Thumbtack**: 지역 기반 전문가·서비스 연결 플랫폼 (예: 수리, 청소, 과외 등)
* **Uber**: 차량 호출 및 배달 서비스

![](https://velog.velcdn.com/images/euisuk-chung/post/7a2daee1-2bf8-4698-9f7b-069c65b5ff15/image.png)

### 향후 계획

**개발자용 Apps SDK**

* 프리뷰로 오늘부터 사용 가능
* 조기 액세스를 통한 피드백 수집
* 개발자와 함께 구축

**올해 말 출시 예정**

* 개발자가 앱을 제출하여 심사 및 게시 가능
* 앱 디렉토리 출시: 사용자가 탐색 가능
* 대화 내 발견 외에도 디렉토리를 통한 탐색 지원

### 앱 노출 및 추천 기준

**Developer Guidelines** (오늘 초안 공개):

* 기본 표준을 충족한 모든 앱은 등록 자격 있음
* **더 높은 표준**을 충족한 앱은 더 돋보이게 표시:
  + 디렉토리 내 우선 노출
  + 대화 중 추천 앱으로 제안

**수익화**

* 곧 더 많은 정보 공개 예정
* 개발자 피드백을 듣고 싶어함

Sam Altman은 **"이것은 개발자와 ChatGPT 사용자 모두에게 흥미진진한 새 장이 될 것"**이라며 마무리했습니다.

---

Building Agents - 에이전트 개발의 현실
-----------------------------

![](https://velog.velcdn.com/images/euisuk-chung/post/5e100c4c-e2cf-41f0-9bc9-3fdad048f3bd/image.png)

### AI의 진화: Ask → Do

AI는 "질문하는 시스템"에서 "여러 일을 해주는 시스템"으로 진화하고 있습니다.

이것이 **에이전트(Agents)**입니다:

**에이전트의 정의**

* **컨텍스트**(Context): 상황 이해
* **도구**(Tools): 실행 능력
* **신뢰**(Trust): 안전한 자율 실행

이 세 가지를 갖춘 소프트웨어가 작업을 대신 수행합니다.

### 에이전트 개발의 현실적 어려움

에이전트에 대한 열기는 뜨겁지만, **실제 프로덕션에 배포되는 에이전트는 극소수**입니다.

그 이유는 바로:

**1. 시작점 불명확**

* 어디서부터 시작해야 할지 모름
* 어떤 프레임워크를 신뢰해야 할지 불확실

**2. 많은 작업량**

* **오케스트레이션**: 여러 단계의 워크플로우 조정
* **평가 루프**(Eval loops): 성능 측정 및 개선
* **도구 연결**: 외부 시스템과 통합
* **UI 구축**: 사용자 인터페이스 개발

**3. 불확실성**

* 아이디어가 작동할지 알기도 전에 각 레이어가 복잡성을 추가

### OpenAI가 본 기회

수천 개 팀과 대화한 결과:

* 에이전트로 업무 방식을 재구상하려는 **엄청난 에너지** 존재
* 기회는 **매우 현실적**임
* OpenAI가 할 일: **에이전트를 더 쉽게 만들 수 있게 하기**

---

AgentKit - 프로덕션 에이전트를 위한 통합 플랫폼
-------------------------------

> **에이전트 개발의 기술적 과제**  
> 프로덕션 환경에서 에이전트 배포가 어려운 이유는 다층적 복잡성 때문입니다.
>
> * **오케스트레이션**(orchestration)은 다중 도구 호출 및 의사결정 흐름을 관리해야 합니다.
> * **평가 루프**(eval loops)를 통해 에이전트 행동의 정확성과 안정성을 검증해야 합니다.
> * 또한 내부 시스템 및 외부 API와의 안전한 **도구 연결**(tool connection), 그리고 에이전트와 사용자 간 효과적인 **UI 구현**까지 고려해야 합니다.

---

### AgentKit Launch - 통합 에이전트 플랫폼

AgentKit는 이러한 각 계층에 대한 솔루션을 제공하는 종합 플랫폼입니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/b777d153-4338-4d8b-b5ee-9211819c701b/image.png)

#### AgentKit 소개

> **아이디어에서 에이전트까지 훨씬 빠르게**

* AgentKit는 OpenAI 플랫폼에서 제공되는 **완전한 빌딩 블록 세트**입니다:

**설계 목적**

* 에이전트를 **프로토타입에서 프로덕션**까지 이동
* 에이전틱 워크플로우를 **구축, 배포, 최적화**
* **더 빠르고, 훨씬 적은 마찰**로

**대상 사용자**

* 개인 개발자부터 대기업까지
* 모든 사람이 큰 가치를 얻을 것

---

### Agent Builder - 비주얼 워크플로우 설계

![](https://velog.velcdn.com/images/euisuk-chung/post/9aabae66-a0b9-482c-80a8-baa743666a8a/image.png)

#### Agent Builder의 핵심 개념

* **빠른 비주얼 방식**으로:

  + 로직 단계 설계
  + 흐름 테스트
  + 아이디어 배포
* **기술적 기반**

  + 수십만 개발자가 이미 사용 중인 **Responses API** 기반
  + 플랫폼 경험이 있다면 **익숙한 기초**

#### 노드 기반 아키텍처

왼쪽 패널에서 사용 가능한 **공통 빌딩 블록**:

**1. Agent 노드**

* LLM 기반 의사결정 단위
* 각 노드마다 특화된 지시사항 부여 가능

**2. Tools 노드**

* 파일 검색
* 외부 API 호출
* 데이터베이스 쿼리

**3. If/Else 노드**

* 조건부 로직
* 분류 결과에 따른 라우팅

**4. Human-in-the-Loop**

* 중요한 결정에 사람 개입
* 승인 프로세스 구현

**5. Guardrails**

* 안전장치 및 검증
* PII(개인 식별 정보) 마스킹, 환각 방지, 콘텐츠 모더레이션

이 패턴들은 OpenAI가 에이전트를 구축하며 **학습한 공통 패턴**을 추출한 것입니다.

---

### ChatKit - 임베드 가능한 대화 인터페이스

![](https://velog.velcdn.com/images/euisuk-chung/post/650f8968-5022-4329-b652-df51f5d6fdf6/image.png)

#### ChatKit의 역할

**훌륭한 채팅 경험을 자신의 앱에 바로 가져오기**

ChatKit는:

* **간단하고 임베드 가능한** 채팅 인터페이스
* 자신만의 스타일로 **커스터마이징** 가능
* 브랜드 적용 가능
* **제품 고유의 가치**에 집중

#### 에이전트 워크플로우와의 통합

Agent Builder에서 설계한 워크플로우를 ChatKit를 통해 실행하면:

* 각 에이전트 노드를 거치며 채팅 작동
* 도구 호출을 포함하여
* **최적의 응답** 형성

> 이는 복잡한 에이전트 워크플로우를 사용자에게는 **하나의 일관된 대화 경험**으로 제공합니다.

---

### Evals for Agents - 에이전트 성능 평가

![](https://velog.velcdn.com/images/euisuk-chung/post/8e9a1126-eb51-49b9-91a4-23f86706e4e9/image.png)

#### 에이전트 평가의 필요성

에이전트를 프로덕션에 배포하기 전, 성능과 안정성을 체계적으로 검증하는 것이 필수적입니다. AgentKit는 에이전트 특화 평가 도구를 제공하여 각 의사결정 단계를 분석하고, 문제점을 조기에 발견하며, 지속적인 개선을 가능하게 합니다.

#### 에이전트 전용 평가 기능

**1. Trace Grading (트레이스 등급 평가)**

에이전트의 **실행 과정 전체를 추적하고 평가**하는 기능입니다:

* **단계별 의사결정 분석**: 각 Agent 노드에서 어떤 판단을 내렸는지 상세히 기록
* **도구 호출 검증**: 어떤 도구를 언제, 왜 호출했는지 추적
* **라우팅 경로 확인**: If/Else 노드에서의 분기 결정이 적절했는지 평가
* **오류 지점 식별**: 문제가 발생한 정확한 노드와 시점 파악

*예를 들어, 고객 지원 에이전트가 잘못된 답변을 제공했다면, Trace Grading을 통해 어느 노드에서 잘못된 정보를 검색했는지, 또는 어떤 조건 분기가 잘못 작동했는지 정확히 파악할 수 있습니다.*

**2. Datasets (데이터셋 관리)**

**노드별 테스트 케이스**를 체계적으로 관리하는 기능입니다:

* **개별 노드 평가**: 전체 워크플로우가 아닌 특정 Agent 노드만 독립적으로 테스트
* **입력-출력 쌍 관리**: 각 노드에 대한 예상 입력과 기대 출력을 데이터셋으로 구축
* **회귀 테스트**: 프롬프트나 로직 변경 후 기존 성능이 유지되는지 자동 검증
* **엣지 케이스 커버리지**: 드문 상황이나 예외 케이스에 대한 체계적 테스트

*예를 들어, "세션 검색 에이전트"에 대해 100개의 다양한 질문 데이터셋을 준비하고, 프롬프트 수정 전후의 정확도를 비교 측정할 수 있습니다.*

**3. Automated Prompt Optimization (자동 프롬프트 최적화)**

**데이터 기반으로 프롬프트를 자동 개선**하는 기능입니다:

* **성능 지표 기반 최적화**: 정확도, 응답 시간, 도구 호출 효율성 등을 측정하여 프롬프트 개선
* **A/B 테스트 자동화**: 여러 프롬프트 변형을 동시에 테스트하고 최적 버전 선택
* **반복 실험 간소화**: 수동으로 프롬프트를 조정하는 대신 시스템이 자동으로 실험
* **베스트 프랙티스 발견**: 실제 사용 데이터에서 효과적인 지시사항 패턴 추출

*이는 LLM의 비결정적 특성을 고려하여, 통계적으로 유의미한 성능 향상을 달성하는 프롬프트를 찾아냅니다.*

**4. External Model Evaluation (외부 모델 평가)**

**벤더 중립적 평가 환경**을 제공합니다:

* **OpenAI Evals 플랫폼 활용**: 동일한 평가 인프라 사용
* **타사 모델 테스트**: GPT 외에도 Claude, Gemini 등 다른 LLM 성능 비교
* **공정한 벤치마크**: 동일한 데이터셋과 기준으로 모델 간 객관적 비교
* **모델 선택 최적화**: 비용, 속도, 정확도를 고려한 최적 모델 조합 발견

*예를 들어, 간단한 분류 작업에는 저렴한 모델을, 복잡한 추론 작업에는 고성능 모델을 배치하는 전략을 데이터 기반으로 수립할 수 있습니다.*

---

### Connector Registry - 안전한 데이터 연결

![](https://velog.velcdn.com/images/euisuk-chung/post/ef1f3eb1-972b-4d28-bc33-528b743bfb75/image.png)

#### 에이전트를 위한 데이터 액세스

에이전트는 데이터에 접근해야 작동합니다. **OpenAI Connector Registry**는:

**안전한 연결 관리**

* 내부 도구와 에이전트 연결
* 서드파티 시스템 통합
* **Admin Control Panel**을 통한 중앙 관리

**보안 및 제어**

* 모든 것을 **안전하게** 유지
* **통제 하에** 운영
* 엔터프라이즈급 권한 관리

---

### 실제 구현 사례

#### Albertsons - 매장 운영 에이전트

**Albertsons 소개**

* 미국 전역 **2,000개 이상**의 식료품 매장 운영
* 매주 **3,700만 명** 쇼핑
* 각 매장은 작은 경제 시스템

**매장 관리자의 일상적 의사결정**

매장 관리 시에는 끊임없는 결정이 필요합니다:

* 프로모션 기획
* 제품 믹스 조정
* 디스플레이 배치
* 벤더 관리 등.

**AgentKit로 구축한 솔루션**

![](https://velog.velcdn.com/images/euisuk-chung/post/c7e85376-1ef3-403a-94c9-dcc2c4202d7a/image.png)

**문제 상황 정의**:

> 아이스크림 매출이 예상치 못하게 **32% 감소**

**기존 프로세스**:

* 보고서 작성
* 스프레드시트 분석
* 여러 차례 회의
* 긴 시간 소요

**에이전트 활용 프로세스**:

![](https://velog.velcdn.com/images/euisuk-chung/post/aca9d12b-880c-441e-8366-c98d80c8ba5a/image.png)

1. **직원이 질문**: "무슨 일이 일어나고 있나요?"
2. **에이전트가 전체 컨텍스트 분석**:

   * 계절성(Seasonality)
   * 과거 트렌드(Historical trends)
   * 외부 요인(External factors)
3. **권장사항 제시**:

   * 디스플레이 조정 시기
   * 지역 광고 실행 제안

> **결과**: 복잡한 의사결정 프로세스가 **즉각적인 대화형 권장사항**으로 단순화됩니다.

---

#### HubSpot - 고객 지원 에이전트

**HubSpot과 Breeze**

* **HubSpot**: 전 세계 수십만 조직이 사용하는 고객 플랫폼
* **Breeze**: HubSpot의 AI 도구
* AgentKit의 **Custom Response Widget** 활용하여 Breeze 응답 개선

![](https://velog.velcdn.com/images/euisuk-chung/post/977cd6fb-c6b1-437f-8011-dce1cf73087b/image.png)

**실제 사례: Luma Plants**

> **고객 질문**: "애리조나에서 식물이 잘 자라지 않는 이유는?"

**Breeze Assistant의 처리 과정**:

1. **자체 지식베이스 검색**

   * 내부 식물 관리 문서 검색
2. **지역별 처리 방법 조회**

   * 애리조나의 **저습도** 환경에 적합한 솔루션 찾기
3. **정책 세부사항 통합**

   * 회사 정책 및 보증 정보 포함
4. **종합 응답 생성**

   * 여러 정보 소스를 하나로 통합
   * **다중 솔루션 제시**
   * 구체적 **권장사항** 포함

**AgentKit - 활용 파트너 목록**

![](https://velog.velcdn.com/images/euisuk-chung/post/6f37c9e8-1ac4-4a77-ab93-80ac7ed50440/image.png)

---

Live Agent Demo - 라이브 에이전트 데모 시작
--------------------------------

Christina(Platform Experience 팀)가 무대에 올라 **AgentKit가 개발자들이 그 어느 때보다 빠르게 에이전트를 만들도록 돕는 방법**을 시연했습니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/86c1dc77-dd97-41b9-bc4c-71eb6d5216da/image.png)

### 데모 시나리오 설정

**기존 DevDay 웹사이트**:

* 모든 참석자가 접근 가능
* 오늘 일정을 보여주는 정적 페이지
* 하지만 단순히 정보만 표시

**목표**:

* 실제로 사용자를 **도와주는** 페이지로 만들기
* 사용자와 가장 관련 있는 세션으로 **안내**
* "우리는 OpenAI입니다. DevDay 사이트에 AI가 있어야 합니다!"

### 도전 과제

**8분 타이머 시작**:

* AgentKit로 구동되는 에이전트 구축
* DevDay 사이트 내부에 배포
* **모든 것을 라이브로, 청중 앞에서**

> Christina: "에이전트 구축이 얼마나 어려운지 들었으니, 이것은 도전이 될 것입니다."

무대에 카운트다운 타이머가 표시되며 본격적인 데모가 시작됩니다. ㅎㄷㄷ

### Building "Ask Froge" - "Froge에게 물어보기" 에이전트 구축

**시작: Workflow Builder**

Christina는 **OpenAI 플랫폼의 Workflow Builder**에서 시작합니다.

**코드 대신 비주얼 와이어링**:

* 노드를 시각적으로 연결
* 복잡한 워크플로우를 **쉽고 시각적으로** 모델링
* 에이전트 구축에서 배운 **공통 패턴** 사용

![](https://velog.velcdn.com/images/euisuk-chung/post/7f96d606-7bc8-4022-99e6-a5f6ace656ac/image.png)

**Phase 1: 메시지 분류기**

**목표**: 들어오는 질문 유형 판별

**구조**:  
1. **Classifier Agent 노드** 추가

* 세션 정보 질문인지
* DevDay 일반 정보 질문인지 구분

![](https://velog.velcdn.com/images/euisuk-chung/post/07dd2013-f105-4fde-b75a-c18da293cf8e/image.png)

2. **If/Else 노드** 추가
   * 분류 결과에 따라 행동 라우팅
   * 적절한 전문 에이전트로 전달

![](https://velog.velcdn.com/images/euisuk-chung/post/438fe9a1-9ca7-4f9d-94e1-1e5b5ce597d8/image.png)

**Phase 2: Session Agent 생성**

* **Session Agent 노드 설정**:

  ![](https://velog.velcdn.com/images/euisuk-chung/post/ff677d51-9c3f-4337-a8ee-3257c4993ae9/image.png)

  1. **이름 지정**: "Session Agent"
  2. **컨텍스트 부여**:

     + "세션 정보 가져오기"에 대한 지시사항
     + 에이전트의 역할 명확히 정의
  3. **도구 추가**:

     + 세션 정보가 담긴 문서 업로드
     + 파일명: "session"
     + 이 파일에 모든 필요 정보 포함

**Phase 3: 커스텀 위젯 생성**

![](https://velog.velcdn.com/images/euisuk-chung/post/de5f9f04-e8ae-4fcc-9ad0-ae25a3ec1d4b/image.png)

**목표**: 일정을 **재미있고 시각적으로** 표시

**Widget Builder로 이동**:

* 이미 "Froge 101" 클래스용 세션 위젯 디자인 완료
* 위젯 다운로드
* Session Agent에 **출력 형식**으로 첨부

![](https://velog.velcdn.com/images/euisuk-chung/post/0f14d5d9-d9f9-4e83-901a-1df945ba9e92/image.png)

**Preview 확인**:

* 위젯이 제대로 추가되었는지 확인
* Session Agent 완성

**Phase 4: DevDay Agent 생성**

* **또 다른 Agent 노드 추가**:

  ![](https://velog.velcdn.com/images/euisuk-chung/post/6a80254c-dd82-476a-bf87-204364b03c6d/image.png)

  1. **이름**: "DevDay Agent"
  2. **컨텍스트 설정**:

     + 일반적인 DevDay 정보 제공
     + **Froge 스타일로 말하기** - 브랜드 톤 적용
  3. **파일 추가**:

     + DevDay 전체 정보가 담긴 파일
     + 파일명: "devday"
     + 첨부 완료
  4. **If/Else 노드에 연결**:

     + 일반 정보 질문 시 이 에이전트로 라우팅

**Phase 5: Guardrails 추가**

* **가드레일의 중요성**:
  + 에이전트 구축에서 **신뢰**는 가장 중요
  + 가드레일이 그 확신을 제공
  + 다음을 방지:
    - 환각(Hallucinations)
    - 부적절한 콘텐츠
    - PII(개인 식별 정보) 노출

![](https://velog.velcdn.com/images/euisuk-chung/post/21b5131d-c5b5-43af-b504-3eb21afff8fa/image.png)

* **PII Guardrail 설정**:
  1. **미리 구축된 가드레일** 선택
  2. **Name 포함**: 검증을 위해 이름 처리 활성화
  3. **워크플로우 시작 부분에 연결**
     + Froge가 PII로부터 보호받도록
  4. **추가 에이전트 노드**로 엣지 케이스 처리
     + Froge 스타일로 말하기 설정
     + 컨텍스트 제거

![](https://velog.velcdn.com/images/euisuk-chung/post/2a0f01a3-44c2-4f2d-a94c-238aad6d6849/image.png)

> ~~흠 저거 User로 하는거 아니지 않나..?~~

---

### Previewing the Agent - 에이전트 미리보기

![](https://velog.velcdn.com/images/euisuk-chung/post/784e65ce-af6c-41a0-8e23-efdbfd555991/image.png)

**출력 구성**

* 최종 사용자에게 표시될 내용 결정:
  + **파일 검색 소스 끄기**:
    - 내부용이므로 사용자에게 노출 불필요
    - 깔끔한 사용자 경험 제공

![](https://velog.velcdn.com/images/euisuk-chung/post/bdf3cf47-d625-4dc8-b255-a4d591b7102e/image.png)

**Agent Builder에서 미리보기**

> **테스트 질문**: "What session should I attend to learn more about building agents?"

* **에이전트 실행 과정**:
  1. ✅ 가드레일 체크
  2. 🔍 방금 추가한 세션 파일에서 정보 검색
  3. 🎨 커스텀 위젯 사용하여 결과 표시
  4. ✨ "Orchestrating Agents at Scale" 세션(11:15) 추천
  5. 🐸 "Ribbit" 등 Froge 스타일 포함

![](https://velog.velcdn.com/images/euisuk-chung/post/dc687746-9ec9-4b63-a7de-9c331aa5c4b5/image.png)

---

### Publishing the Agent - 에이전트 배포

### 평가(Evals)에 대한 언급

> Christina: "아직 하지 않은 한 가지는 **전체 평가(Evals)** 세트입니다."

**정상적인 프로세스**:

* 플랫폼에서 직접 평가 실행 가능
* 라이브 배포 전 예상대로 작동하는지 확인

> 시간상 문제로 이건 SKIP

### 배포 실행

**배포 버튼 클릭**:

1. **이름 지정**: "Ask Froge"
2. **Publish 클릭**
3. **완료**: 프로덕션에 완전히 배포된 에이전트!

**결과물**:

* ✅ **Workflow ID**: 직접 실행 가능한 ID 생성됨
* 📦 프로덕션 환경에 배포됨

### 코드 vs. 플랫폼 선택

Agent Builder에서 배포하면:

* Workflow ID가 자동 생성됨: wf\_68e3d4ad25e08190909e417982f295e20d191e9e4
* Current version: version="1" (버전 관리도 가능)

그리고 화면에 두 가지 통합 방법이 제시됩니다:

* 탭 1: ChatKit (No-code 방식)
  + "Follow the ChatKit quickstart"
  + 위에서 받은 Workflow ID를 복사해서 제품에 임베드
  + 간단한 SDK 통합

![](https://velog.velcdn.com/images/euisuk-chung/post/4263aa28-1c47-484d-ad7d-232fea50de92/image.png)

* 탭 2: Agents SDK (Code 방식)
  + 더 세밀한 제어가 필요할 때
  + 직접 코드로 커스터마이징

![](https://velog.velcdn.com/images/euisuk-chung/post/70fbf1e9-88f6-4856-aa92-ebbb8a17ef8d/image.png)

### 사이트 통합 시작

**1. 세션 생성 함수 구현**:

![](https://velog.velcdn.com/images/euisuk-chung/post/fa7a9399-6f5d-4977-ba42-0ed3091c4076/image.png)

방금 배포한 워크플로우 ID를 사용하여 ChatKit 세션을 생성합니다.

```
    body: JSON.stringify({
      workflow: { id: "wf_88e3d4aad25e08190909e417982f295e20d191e944312370a" },
      user: deviceId,
    }),
  });
```

**2. ChatKit React 컴포넌트 설정**:

![](https://velog.velcdn.com/images/euisuk-chung/post/764c8d14-5532-4d3f-8110-1e55808c0ef7/image.png)

시각적 커스터마이징으로 Froge 브랜드 스타일을 적용합니다.

```
import { ChatKit, useChatKit } from "../lib/chatkit-react";

export const FrogeChat = () => {
  const chatKit = useChatKit({
    api: {
      getClientSecret,
    },
    header: {
      title: {
        text: "Ask Froge",
      },
    ...
```

**3. App 컴포넌트에 통합**:

![](https://velog.velcdn.com/images/euisuk-chung/post/38c93918-5302-419f-8c82-3ec1f686527b/image.png)

DevDay 웹사이트의 전체 레이아웃을 구성하고, `BottomSheet` 컴포넌트 안에 `FrogeChat`을 배치하여 **하단에서 슬라이드업되는 채팅 인터페이스를 완성**합니다.

```
export default function App() {
  return (
    <div className="pb-sm px-sm gap-2xl mx-auto flex max-w-[620px] touch-pan-y flex-col overflow-x-hidden overscroll-x-none">
      <AnimatedFroge />
      <LeadLinks />
      <Directory />
      <BottomSheet>
        <FrogeChat /> //여기에 선언!
      </BottomSheet>
    </div>
  );
}
```

**4. 링크 추가**:

![](https://velog.velcdn.com/images/euisuk-chung/post/31a3c9a8-5a3f-49ab-82b0-50cb88b4f263/image.png)

사이트 상단에 "Ask Froge" 접근 가능한 인터페이스 구성이 완료됩니다.

```
export default function LeadLinks() {
  return (
    <>
      <Rive src={animationURL} className="mx-auto h-64 w-64" />
      <div className="gap-4xs flex flex-col items-start">
        <a className="text-primary-100" href="https://openai.com">
          Download the entire day <span className="text-[#328FF2]">↓</span>
        </a>
        
          className="text-primary-100"
          href="https://discord.verify.openai.com/devday"
        >
          DevDay 2025 Discord <span className="text-[#54CA31]">↗</span>
        </a>
      </div>
    </>
  );
}
```

### 라이브 테스트

**사이트 새로고침**:

* 🐸 "Ask Froge" 버튼이 나타남

![](https://velog.velcdn.com/images/euisuk-chung/post/e6864bea-10dc-43a7-9281-8855fcc1dbc7/image.png)

* 화면 하단에서 채팅창 올라옴

![](https://velog.velcdn.com/images/euisuk-chung/post/0200f271-b8df-4e06-bc93-f4140e89d05b/image.png)

> **테스트 질문**: "What session should I attend to learn about building agents?"

* **에이전트 실행 flow**:
  + ✅ 가드레일 체크
  + 🏷️ 메시지 분류
  + 📄 파일 검색 도구에서 정보 가져오기
  + 🎨 위젯 사용하여 표시
  + 💡 "Orchestrating Agents at Scale" 추천
  + 🐸 계속 Froge 스타일로 "ribbit" 말하기

---

The Future of Software - 소프트웨어의 미래
----------------------------------

### AI가 가져오는 변화

**가장 흥미진진한 일 중 하나**:

* AI로 인해 **소프트웨어 작성 방식**이 변화하는 새 시대 진입
* 누구나 아이디어만 있으면:
  + 자신을 위한 앱 제작
  + 가족을 위한 앱 제작
  + 커뮤니티를 위한 앱 제작

![](https://velog.velcdn.com/images/euisuk-chung/post/31102f0e-38bf-4920-bc73-2f9f4a6aadb9/image.png)

> (참고) **Abundant Software의 의미**

**기존 시대: Scarcity (희소성)**

* 소프트웨어 개발자는 제한적
* 만들 수 있는 앱의 수는 한정적
* 개발 비용과 시간이 많이 듦
* 결과: 소수의 범용 앱만 존재 (모두가 같은 앱 사용)

**AI 시대: Abundance (풍요)**

* 누구나 개발자가 될 수 있음
* 아이디어만 있으면 즉시 구현 가능
* 개발 비용과 시간이 극적으로 감소
* 결과: 무한에 가까운 맞춤형 앱 탄생

### 실제 사례들

**1. 일본의 89세 퇴직자**

* ChatGPT 도움으로 **스스로 코딩 학습**
* 노인 사용자를 위한 **11개 iPhone 앱** 제작
* 평생의 지혜를 다른 사람들이 더 독립적으로 살 수 있도록 돕는 도구로 전환

![](https://velog.velcdn.com/images/euisuk-chung/post/d02f8322-bbdb-4931-b7bf-a65e015189b1/image.png)

**2. 스페인의 Pau Garcia와 Domestic Data Streamers**

* 사람들이 **추억과 다시 연결**되도록 지원
* 사용 기술:
  + ChatGPT
  + 이미지 생성
  + Sora (비디오 생성)

![](https://velog.velcdn.com/images/euisuk-chung/post/24027685-54d2-4d36-b10b-94c859dca0a0/image.png)

**3. 애리조나 주립대(ASU) 의대생** 🏥

* 의사로서 해야 할 **어려운 인간적 대화** 연습 필요
* **가상 환자 앱** 제작
  + OpenAI 모델 활용
  + 시도하고, 실패하고, 개선 가능
  + 실제 진료실 들어가기 전 연습

![](https://velog.velcdn.com/images/euisuk-chung/post/b219a519-1bbc-4c76-bc1a-20587ecdefda/image.png)

**4. 프랑스 베르사유 궁전** 🇫🇷

* 방문객이 이제 궁전과 **대화** 가능
* Realtime API 사용
* **예술 및 조각품과 실시간 토론**
* 역사가 대화가 됨

![](https://velog.velcdn.com/images/euisuk-chung/post/07e943e1-a963-483d-9e77-97f6a89c4935/image.png)

### 핵심 메시지

Sam: "사람들이 만들고 있는 것을 보는 것은 정말 멋집니다."

이것이 바로 OpenAI가 개발자에게 **더 빠르게 구축할 수 있는 더 많은 도구**를 제공하는 데 열정적인 이유입니다.

---

Codex Update - Codex 업데이트
-------------------------

### Codex의 진화

**올해 초 출시**:

* **Codex**의 연구 프리뷰 런칭
* OpenAI의 소프트웨어 엔지니어링 에이전트
* 개발자와 **함께 작동**하도록 설계
* 소프트웨어 생성 속도 향상

**이후 성장**:

* Codex는 훨씬 더 **유능한 협력자**로 성장
* 코딩하는 **모든 곳에서 작동**:
  + IDE (통합 개발 환경)
  + Terminal (터미널)
  + GitHub
  + Cloud (클라우드)

### 통합된 경험

**ChatGPT 계정으로 모든 것 연결**:

* 작업을 이 도구들 간 **원활하게 이동** 가능
* 일관된 워크플로우

### 새로운 기능들

Sam: "우리는 Codex에 대한 **수많은 새 기능**을 출시했습니다."

다음 섹션에서 자세히 설명될 예정.

---

### GPT-5-Codex Model - 특화된 코딩 모델

**GPT-5-Codex**:

* Codex에서 실행되는 **새 모델**
* GPT-5의 특별 버전
* **에이전틱 코딩을 위해 의도적으로 훈련**됨

**핵심 역량**:

1. **코드 리팩토링 (Code Refactoring)**

   * 대규모 코드베이스 재구조화
   * 레거시 코드 현대화
2. **코드 리뷰 (Code Review)**

   * 심층적인 분석
   * 시니어 엔지니어 수준의 피드백
3. **동적 사고 시간 조정**

   * 작업 복잡도를 **동적으로 인식**
   * 복잡한 작업에는 더 많이 "생각"
   * 간단한 작업은 빠르게 처리

**개발자 반응**

* **사용자 증가**:

  + 개발자들이 **새 모델을 사랑**함
  + Codex 사용량 **급격히 증가**
* **주요 지표**: **Daily Messages** (일일 메시지 수)

  + 개발자가 Codex와 매일 나누는 작업 및 대화 수
  + 8월 초 이후: **10배 증가** 📈

### 모델 성장

**GPT-5-Codex는 가장 빠르게 성장하는 모델 중 하나**:

* 출시 이후: **40조 토큰 이상** 제공
* OpenAI 역사상 빠른 채택률

### OpenAI 내부 사용

**Codex는 내부 빌드 과정 전반에 존재**:

1. **모든 신규 코드**:

   * 오늘날 OpenAI에서 작성되는 거의 모든 신규 코드
   * Codex 사용자로부터 나옴
2. **생산성 향상**:

   * Codex를 사용하는 엔지니어
   * 주당 **70% 더 많은 Pull Request** 완료
3. **코드 리뷰**:

   * 거의 모든 OpenAI PR이 **Codex 리뷰**를 거침
   * **매우 시니어 엔지니어**에게서도 기대하기 어려운 깊이

---

Codex GA Announcement - Codex 정식 출시
-----------------------------------

### 정식 버전 출시

**오늘부터**:

* Codex가 **연구 프리뷰에서 벗어남**
* **공식적으로 GA (Generally Available)** 🎉

### 확장: 개인에서 팀으로

**기존 상황**:

* Codex는 이미 개인 개발자들에게 많은 견인력(traction)
* 하지만 더 많은 것을 할 수 있음

**새로운 목표**:

* 엔지니어링 **팀**에게 Codex를 더욱 유용하게
* 팀 단위 협업 지원

---

### 엔지니어링 팀을 위한 새로운 기능 추가!

![](https://velog.velcdn.com/images/euisuk-chung/post/5f277f2a-9231-4d29-a1e5-59855a862313/image.png)

1. **Slack Integration 🔔**

   * **가장 많이 요청된 기능**:

     + Slack에서 직접 Codex에게 질문
     + 코드 작성 요청 가능
     + **팀 대화에서 바로** 작동
   * **사용 사례**:

     + 팀원 간 기술 논의 중 즉시 코드 생성
     + 팀 채널에서 직접 문제 해결
     + 비동기 협업 강화
2. **Codex SDK 🛠️**

   * **팀 워크플로우 확장 및 자동화**:
     + Codex를 팀의 고유한 프로세스에 맞게 조정
     + 자동화 파이프라인 구축
     + CI/CD 통합 가능
3. **엔터프라이즈 관리 기능 📊**

   * **환경 제어 (Environment Controls)**:

     + 어떤 리소스에 접근 가능한지 관리
     + 보안 정책 적용
   * **모니터링 (Monitoring)**:

     + Codex 사용 패턴 추적
     + 성능 지표 확인
   * **분석 대시보드 (Analytics Dashboards)**:

     + 팀 생산성 측정
     + ROI 계산
     + 사용 트렌드 파악

---

### Codex Adoption Examples - Codex 채택 사례

**사용자 범위**:

1. **주말 사이드 프로젝트 개발자** 👨‍💻

   * 개인적인 실험
   * 취미 프로젝트
2. **고성장 스타트업** 🚀

   * Cursor
   * Windsurf
   * Vercel
   * GPT-5로 소프트웨어 작성 및 배포 방식 변화
3. **글로벌 엔터프라이즈** 🏢

   * 대규모 조직

**Cisco 사례**

* **Cisco의 Codex 배포**:
  + **전체 엔지니어링 조직**에 Codex 롤아웃
  + 세계적 규모의 기술 기업

**성과**:

1. **코드 리뷰 속도**: **50% 더 빠름** ⚡

   * 리뷰 프로세스 대폭 단축
   * 병목 현상 해소
2. **프로젝트 타임라인**: **수 주 → 수 일** 📅

   * 평균 프로젝트 기간 극적으로 감소
   * 출시 속도 대폭 향상

이는 대규모 조직에서도 Codex가 실질적 영향을 미칠 수 있음을 보여줍니다.

---

Codex 라이브 데모 - 실시간 소프트웨어 구축
---------------------------

### 1. 초기 설정 - 컨트롤 패널 구축

#### 사전 작업

Romain은 일찍이 Codex CLI에게 간단한 컨트롤 패널 인터페이스를 만들어달라고 요청했습니다.

**요청 내용**:

* 카메라 피드 표시
* 몇 가지 컨트롤 버튼
* 빠른 스케치 기반으로 생성

![](https://velog.velcdn.com/images/euisuk-chung/post/4de80345-3d7c-459d-83af-8156ace66029/image.png)

**추가 작업**:

* Figma 브랜딩 추가
* 디자인에 완벽하게 맞게 렌더링

![](https://velog.velcdn.com/images/euisuk-chung/post/f39ee0c9-5aca-4207-8ab2-68bda8427738/image.png)

시작할 기본 인터페이스 준비가 완료되었습니다.

---

### 2. 카메라 제어 구현

#### 예상치 못한 질문

![](https://velog.velcdn.com/images/euisuk-chung/post/7e3d2af9-9f31-4a22-bb06-73668f2f5590/image.png)

Romain은 솔직히 어떻게 시작해야 할지 몰랐다고 고백합니다. 카메라용 C++ SDK가 있다는 것만 알고 있었고, Codex가 아마 JavaScript로 번역하려 할 것이라고 생각했습니다.

#### 1단계: 카메라 제어 방법 문의

> How to control a Sony FR7 camera?

![](https://velog.velcdn.com/images/euisuk-chung/post/a48525b5-a1e7-4701-b350-58286a3edec3/image.png)

#### 2단계: 전체 제어 스택 구축 요청

> Please scaffold a VISCA control stack from scratch for a Sony FR7 camera. Create a `visca-backend` service that speaks VISCA over TCP 52381 using env vars VISCA\_HOST and VISCA\_PORT, exposes /api/status plus /api/ptz/\*, and runs via `npm run visca:dev` on <http://localhost:5000>. Add the supporting root scripts, implement frontend server actions and a reusable hook, and wire camera controls. Remember to honor busy/disabled states while calling the camera API.

**요청 내용 해설**:

* `Node.js` 기반 VISCA 제어 스택 구축
* 백엔드 서비스: TCP 통신으로 카메라와 연결
* API 엔드포인트: 상태 확인 및 PTZ(Pan-Tilt-Zoom) 제어
* 프론트엔드 연결: 서버 액션과 재사용 가능한 훅
* 상태 관리: 카메라 busy/disabled 상태 고려

![](https://velog.velcdn.com/images/euisuk-chung/post/c98658bc-7093-4b16-a0c1-089be80269fb/image.png)

#### Codex의 놀라운 작업

Romain은 Codex가 데모하기 점점 어려워지고 있다고 말합니다. 왜냐하면 큰 리팩토링 작업에 **7시간 이상** 연속 작업 가능하고, 제대로 완수하기 때문입니다.

#### 구현 결과

![](https://velog.velcdn.com/images/euisuk-chung/post/e3e2bc21-0bc8-413b-b90e-45fbc99fd86f/image.png)

VS Code로 전환하면 Codex CLI가 만든 파일들을 확인할 수 있습니다. **Node 서버**가 구축되었고, **VISCA 프로토콜**이 완벽하게 구현되었습니다.

**프로토콜 학습의 놀라움**:

이 프로토콜을 배우는 데 걸렸을 시간을 상상해보라고 Romain은 말합니다. **VISCA 프로토콜**은 30년 이상 된 프로토콜로, 매우 특수한 헤더를 전송해야 하며 이 카메라 전용입니다. Codex는 프로토콜을 자동으로 학습하고, 정확한 헤더를 식별하여, 올바르게 구현했습니다.

#### 실제 테스트

**카메라 제어 성공**:

* 컨트롤 패널에서 카메라 ON
* 컨트롤 테스트
* 인터페이스에서 성공적인 카메라 제어
* 실시간으로 카메라가 움직임

---

### 3. Xbox 컨트롤러 통합

#### 새로운 도전

더 나은 무언가를 할 수 있을 것 같았습니다. Romain은 일찍 백스테이지에서 Xbox 컨트롤러를 발견했고, 시도해볼 만한 것이라고 생각했습니다.

#### IDE에서 라이브 작업 전송

![](https://velog.velcdn.com/images/euisuk-chung/post/d5039523-5f28-4174-9f33-dbcd6b85dc2d/image.png)

> Wire up a wireless controller to control the camera

#### Codex의 실시간 작업 과정

화면에 표시되는 것:

**1. 계획 수립 (Making a plan)**:

* Codex가 전략을 세움
* 무엇을 해야 할지 결정

**2. 파일 탐색 (Exploring files)**:

* 기존 코드베이스 분석
* 어디에 연결해야 할지 파악

**3. 게임패드 연결 방법 파악**:

* Gamepad API 사용법 이해
* 카메라 제어와 매핑

#### Context의 중요성

IDE의 핵심 개념은 **Context**입니다. 프롬프트가 짧을 수 있는 이유는 Codex가 의도를 이해하고, 최근 사용한 파일을 확인하며, 그에 따라 조정하기 때문입니다. 사용자가 작업 중인 파일, 프로젝트 구조, 관련 종속성을 자동으로 인식합니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/4115261f-6a6c-4040-9f58-fdabbc4e5f51/image.png)

#### 작업 완료 및 테스트

Task 2는 완료까지 약 1분 소요되며 백그라운드에서 계속 진행됩니다. Xbox 컨트롤러로 카메라를 제어할 수 있는지 테스트한 결과, 작동에 성공했습니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/51272e5b-efd5-47dd-a8db-cb48048365ad/image.png)

#### Codex의 자율적 판단

정말 멋진 점은 어떤 버튼이 무엇을 해야 하는지 명시하지 않았는데도, Codex가 조이스틱이 좋은 아이디어라는 것을 알아내고 카메라 pan/tilt에 자연스럽게 매핑했다는 것입니다.

---

### 4. 조명 시스템 제어 - Cloud Codex 활용

#### 음성 인터페이스 구상

Romain은 흥미로운 인터페이스 중 하나는 **음성(voice)**이라고 생각했습니다. 시간을 절약하기 위해 Codex에게 **Realtime API 통합**, **Agent SDK 연결**, 그리고 화면 하단의 점에 **앱 통합**을 미리 요청했습니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/ae06708a-5973-40a3-b37f-1a2ff3baf2a7/image.png)

#### MCP 서버 생성 - Cloud Codex 활용

Romain은 데모에서 더 인상적인 작업을 보여줄 수 있을지 고민하던 중, 주변에 있던 조명 시스템에 주목했습니다. 그는 이 조명을 제어하는 MCP 서버를 직접 만들어보기로 했습니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/c40e50c2-a388-4313-bbd6-4b959d60d044/image.png)

**Cloud Codex 프롬프트**:

```
Build a new MCP server for the ENTTEC S-Play lighting system.

Use the S-Play REST API docs from https://github.com/ENTTEC/SplayApi. For instance, it looks like POST <host>/api with `{ command: 8 }` fetches playlists and `{ command: 0, playlist_id }` starts one (controller host provided via SPLAY_HOST).

Implement an Express ESM server that exposes:
 - GET /sse – open an SSEServerTransport session for MCP traffic
 - POST /messages?sessionId= – feed messages back into the active session
 - GET /health – return { name, version, host, playlistCount }

Register MCP tools `enttec_set_target` (host string + optional autoRefresh), `enttec_refresh_playlists`, and one dynamic `enttec_play_id` per cached playlist so that ...
```

#### 로컬 적용

VS Code로 복귀하여 Cloud Codex에서 작업한 내용을 확인할 수 있습니다. **Apply 버튼**을 클릭하면 MCP 서버의 모든 변경사항이 로컬에 적용되고, 종속성 설치가 시작되며 준비가 완료됩니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/5914b49e-bd08-4701-a875-fe6e7ebc3474/image.png)

---

### 5. 음성 제어 데모

#### 통합 테스트

Romain은 본격적인 통합 테스트를 위해 음성 모드를 켜고, Codex가 음성 명령을 인식하여 조명을 정상적으로 제어하는지 시연을 진행하였습니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/aa0cc644-5213-4455-8a29-4c6b42e5e5ea/image.png)

#### 대화 시작

> Romain: Hello.

**AI**: "Hi there, I can hear you loud and clear. Let me know what you need."

#### 카메라 확인

> Romain: What do you see on camera?

**AI**: "I see a large audience in front of you with rows of attendees seated and ready. The room is well lit and the crowd fills the space."

AI가 카메라 피드를 실시간으로 분석하여 상황을 이해하고 설명합니다.

#### 조명 제어 명령

> Romain: Could you shine the lights towards the audience?

**AI**: "I've just lit up the audience with a nice bright light to be perfectly highlighted now."

객석에 조명이 비추며 실시간으로 조명 시스템 제어에 성공했습니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/274e1689-6fc6-44d4-9f0f-8d8b6a0d6f6f/image.png)

#### 청중 인사

> Romain: Can you greet everyone here in the room now?

**AI**: "Hello, amazing developers at Fort Mason! We're so excited to have you here for an incredible day."

조명 상태를 인식하고, 장소 정보(Fort Mason)를 활용하며, 적절한 인사말을 생성하는 다층적 처리가 이루어졌습니다.

#### 정상 복귀

> Cool. All right. Let's go back to normal now.

AI가 조명을 정상 상태로 복원합니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/7ac8ae84-57bb-479d-a824-238afdf25dd6/image.png)

---

### 6. Codex SDK 실시간 리프로그래밍

Romain은 마지막 시연에서 Codex SDK가 가진 **진짜 잠재력**을 보여주기로 했습니다.  
그는 음성으로 Codex에게 요청합니다:

> Romain: “Could you ask Codex to show a credits overlay like at the end of a movie but the cast is the attendees?”

곧바로 Codex는 React 앱 내부에서 필요한 컴포넌트를 생성하고, 모든 개발자 참석자 명단을 자동으로 불러와 영화 엔딩 크레딧처럼 화면 상단에 오버레이를 띄우기 시작합니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/2c90df84-845b-4bbc-98fb-487744f917af/image.png)

#### 실시간 앱 재프로그래밍

여기서 중요한 포인트는 **Codex SDK**가 추가된 순간부터 이 앱이 **“실시간으로 재프로그래밍(reprogram)”** 가능한 상태가 되었다는 것입니다.

Romain이 설명합니다:

> “When I sent a task to the voice agent it also added Codex SDK as a tool. That means now, on the fly, I can reprogram this app in real time and adapt it to user needs or any feedback they have.”

즉, Codex SDK는 단순 API 호출이 아니라 **앱 내에서 바로 에이전트를 실행·수정할 수 있는 SDK**이기 때문에, 이미 실행 중인 React 앱의 코드베이스를 탐색하고 필요한 부분을 패치해 오버레이나 새로운 기능을 추가할 수 있었습니다.

> (참고) Codex SDK의 역할 요약
>
> * **에이전트 임베딩(Agent Embedding)**: Codex SDK를 앱에 추가하면, 앱 내부에서 Codex 에이전트가 직접 코드베이스를 읽고 수정 가능.
> * **실시간 컨텍스트 파악**: 현재 열려 있는 React 컴포넌트와 상태를 파악하여 필요한 기능을 정확히 추가.
> * **동적 툴링(Dynamic Tooling)**: MCP 서버, REST API, WebSocket, UI 컴포넌트 생성 등 다양한 액션을 에이전트가 실행.
> * **음성 모드 결합**: Realtime Voice API와 Codex SDK가 결합해, 음성 명령만으로도 앱을 업데이트하거나 새로운 기능을 시연 가능.

#### 사진 촬영 & 카운트다운

> “Great. In the meantime, could you start a countdown and take a photo of all of us?”

Codex는 즉시 카운트다운 UI를 추가하고, 카메라를 제어하여 청중의 사진을 촬영합니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/ed5dc75f-721f-4c51-9719-041b1058c7f7/image.png)

조명과 카메라 제어, 그리고 엔딩 크레딧까지—모든 작업이 음성 명령으로 즉석에서 구현되었습니다.

![](https://velog.velcdn.com/images/euisuk-chung/post/3dc865fa-d9aa-420e-bc55-33bd4edbe881/image.png)

> (추가 설명) Romain은 마지막으로 이렇게 강조합니다:  
> “We took voice, we took devices around us, a sketch, and turned all of this into workable software. All that, without having to write any code by hand.”

* 이 말은 **Codex SDK가 소프트웨어 엔지니어링의 미래**를 보여준다는 메시지입니다.
* 사용자는 가장 복잡한 아이디어와 문제를 제시하면 되고, Codex SDK가 실시간으로 이를 실행 가능한 소프트웨어로 만들어냅니다.

---

Transition to Models - 모델 업데이트로 전환
----------------------------------

![](https://velog.velcdn.com/images/euisuk-chung/post/eeab1e11-6056-4727-9d35-14e37e0fb4b5/image.png)

### GPT-5 출시 (2024년 8월)

**훈련 목적**:

* **에이전트 조정**(steering agents)에 정말 뛰어나도록
* **엔드투엔드 코딩**에 탁월하도록
* **선도적인 코딩 스타트업들**이 이를 채택하고 사용 중

![](https://velog.velcdn.com/images/euisuk-chung/post/a4f2ca42-22bf-4a5b-82df-55f5e4b3e3a8/image.png)

이들은 GPT-5를 사용하여:

* 소프트웨어가 **작성되고 배포되는 방식**을 변화
* 각자의 앱에서 혁신적 경험 제공

---

### GPT-5 Pro API - GPT-5 Pro API 출시

![](https://velog.velcdn.com/images/euisuk-chung/post/2c4d0651-fefa-410a-93f2-f0a0744842cc/image.png)

* **GPT-5 Pro** 발표
* OpenAI가 출시한 **가장 지능적인 모델**

![](https://velog.velcdn.com/images/euisuk-chung/post/bd85447d-6dad-4fb3-82b7-e3630211b56d/image.png)

> <https://platform.openai.com/docs/models/gpt-5-pro>

**GPT-5 Pro가 탁월한 영역**:

* **개발자 지원**:

  + 정말 **어려운 작업**(really hard tasks)
  + 복잡한 도메인
* **특화 도메인**:

  + **금융**(Finance)
  + **법률**(Legal)
  + **의료**(Healthcare)
* **추천 환경**:

  + 높은 정확도(high accuracy)
  + 깊은 추론(depth of reasoning)

---

### GPT-Realtime-Mini Launch - GPT-Realtime-Mini 출시

![](https://velog.velcdn.com/images/euisuk-chung/post/2ef8d16c-fe27-4884-8be5-38734afaec41/image.png)

**새로운 음성 모델 API 출시**:

* **GPT-Realtime-Mini**
* 더 작고 저렴한 버전

![](https://velog.velcdn.com/images/euisuk-chung/post/a5c26d37-6191-486c-b2b5-ed8bbd32bea6/image.png)

> <https://platform.openai.com/docs/models/gpt-4o-mini-realtime-preview>

* (참고) 2개월 전 출시한 **GPT-4o Realtime**의 소형 버전

![](https://velog.velcdn.com/images/euisuk-chung/post/371ae2a2-f83e-4378-85b6-b59a6012d9cf/image.png)

> <https://platform.openai.com/docs/models/gpt-4o-realtime-preview>

**특징**  
1. **동일한 품질**:

* **같은 음성 품질**
* **같은 표현력**(expressiveness)

2. **비용 효율**:
   * **70% 저렴**

---

### Sora 2 API - Sora 2 API 프리뷰

> "오늘 우리는 API에서 **Sora 2의 프리뷰**를 출시합니다."

![](https://velog.velcdn.com/images/euisuk-chung/post/1c7ad9ff-9f8f-4caf-8364-b21d6ccc8b9f/image.png)

> <https://platform.openai.com/docs/models/sora-2>

**가격 정보**  
![](https://velog.velcdn.com/images/euisuk-chung/post/6a7d7044-6946-45ad-abfa-a6cb3628d995/image.png)

> <https://platform.openai.com/docs/models/sora-2>

### Sora 2의 주요 개선사항

> 모델의 **제어 가능성**(controllability)

**상세한 지시사항**이 가능해졌습니다.:

* 구체적인 요청 가능
* 지시를 **유지**하면서

**결과 품질**이 좋아졌습니다.:

* **스타일화**됨(stylized)
* **정확**함(accurate)
* **구도 잡힘**(composed)

**다양한 Exand View**가 가능.

* **iPhone 뷰** (좁은 화면)로 시작  
  ![](https://velog.velcdn.com/images/euisuk-chung/post/65593e70-95c7-4663-b94b-18b0b9565738/image.png)
* Sora에게 프롬프트로 "Make it a wide shot"이라고 요청시,

  + 영화 같은 광각 장면으로 변환이 가능  
    ![](https://velog.velcdn.com/images/euisuk-chung/post/835912c9-0784-41bd-b678-845e622172cd/image.png)

**영상-사운드 페어링** 기능의 강화:

* **단순한 음성이 아니라**:
  + **풍부한 사운드스케이프** (Rich soundscapes)
  + **앰비언트 오디오** (Ambient audio)
  + **동기화된 효과음** (Synchronized effects)

![](https://velog.velcdn.com/images/euisuk-chung/post/b4b0a410-6d7c-47e6-9ad2-55cb2691c57c/image.png)

---

Mattel Partnership - Mattel 파트너십
--------------------------------

![](https://velog.velcdn.com/images/euisuk-chung/post/7a05a5a8-d51e-43a7-b212-ba222707b7ce/image.png)

> 마텔 주식회사, 미국 캘리포니아주 엘세군도에 본사를 둔 장난감 및 게임 제조업체

### 디자인 프로세스 혁신

![](https://velog.velcdn.com/images/euisuk-chung/post/8fa1e6ac-1525-492b-8bdb-4b5777348da6/image.png)

**기존 프로세스**:

* 아이디어 → 스케치 → 프로토타입 → 제작
* 각 단계마다 시간 소요

**Sora 2 활용**:

* **스케치로 시작**
* **초기 컨셉**을
* **실제로 볼 수 있고 공유할 수 있는 것**으로 변환

---

Event Closing - 행사 마무리
----------------------

### 빌딩 아이디어 제공

Sam: "오늘이 여러분에게 **만들 새로운 것들에 대한 몇 가지 아이디어**를 주었기를 바랍니다."

### OpenAI의 비전

**플랫폼으로서의 OpenAI**:

"OpenAI가 **이 새로운 빌딩 시대**를 위한 **훌륭한 플랫폼**이 되기를 원합니다."

### 미래 전망

Sam: "일이 **정말 믿을 수 없을 정도로** 될 것입니다. **꽤 빨리**."

**의미**:

* 빠른 발전 속도
* 곧 놀라운 가능성들
* 기대할 만한 미래

---

Conclusion
----------

OpenAI DevDay 2025는 AI 개발의 새로운 시대를 여는 중요한 전환점이었습니다. 주요 발표 내용을 요약하면:

### 핵심 발표 요약 (TL;DR)

**1. Apps SDK - ChatGPT 앱 생태계**

* ChatGPT 내에서 완전한 앱 구축 가능
* 8억 명 이상의 사용자에게 즉시 도달
* Coursera, Canva, Zillow 등 주요 파트너 참여

**2. AgentKit - 에이전트 개발 혁신**

* 비주얼 워크플로우 빌더로 에이전트 설계 간소화
* ChatKit으로 임베드 가능한 대화 인터페이스 제공
* Albertsons, HubSpot 등 실제 기업 사례 검증

**3. Codex GA - 소프트웨어 작성의 패러다임 전환**

* GPT-5-Codex 모델로 70% 생산성 향상
* Slack 통합, SDK, Admin 도구 등 팀 기능 추가
* 정식 출시로 프로덕션 환경 준비 완료

**4. 새로운 API 모델들**

* GPT-5 Pro: 금융, 법률, 의료 등 고난도 작업용
* Sora 2: 비디오 + 사운드스케이프 생성
* GPT-Realtime-Mini: 70% 저렴한 음성 모델

### 개발자에게 주는 의미

이번 DevDay는 단순한 기능 업데이트가 아니라, **소프트웨어 개발 방식의 근본적 변화**를 보여줍니다:

* **시간 압축**: 몇 달 걸리던 작업이 몇 분으로
* **진입 장벽 소멸**: 거대한 팀 없이도 좋은 아이디어만으로 구축 가능
* **AI 협업**: AI가 단순 도구가 아닌 팀원으로 진화

OpenAI의 비전은 명확합니다: "AI를 모든 사람에게 유용하게 만드는 것."  
그리고 그 미래는 이미 시작되었습니다.

후... 엄청난 것들이 많아서 정리가 오래 걸렸는데요 :)  
읽어주셔서 감사합니다!!